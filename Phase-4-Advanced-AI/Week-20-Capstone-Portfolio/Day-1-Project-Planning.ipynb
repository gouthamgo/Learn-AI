{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìò Day 1: Project Planning & Portfolio Setup\n",
    "\n",
    "**üéØ Goal:** Plan your capstone AI project and set up a professional portfolio\n",
    "\n",
    "**‚è±Ô∏è Time:** 120-150 minutes\n",
    "\n",
    "**üåü Why This Matters for AI (2024-2025):**\n",
    "- Your portfolio is THE most important tool for landing AI/ML roles\n",
    "- Recruiters spend 6 seconds scanning - projects make you stand out\n",
    "- 85% of AI hiring managers prioritize portfolio over degrees\n",
    "- A single impressive project beats 10 tutorials on your resume\n",
    "- GitHub is where AI talent is discovered - it's your professional storefront\n",
    "- Capstone projects demonstrate end-to-end skills employers need\n",
    "\n",
    "**What You'll Learn Today:**\n",
    "1. **Choose the perfect capstone project** that showcases your skills\n",
    "2. **Plan project scope** to avoid common pitfalls\n",
    "3. **Develop data collection strategies** for real-world datasets\n",
    "4. **Set up professional GitHub portfolio** following industry best practices\n",
    "5. **Create project documentation** that impresses recruiters\n",
    "6. **Build a project roadmap** with realistic timelines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-capstone",
   "metadata": {},
   "source": [
    "## üéØ Why a Capstone Project?\n",
    "\n",
    "**The difference between learning AI and landing an AI job is your portfolio!**\n",
    "\n",
    "### üìä The Reality of AI Hiring (2024-2025):\n",
    "\n",
    "**What recruiters want to see:**\n",
    "- ‚úÖ **End-to-end projects**: Data ‚Üí Model ‚Üí Deployment\n",
    "- ‚úÖ **Real-world applications**: Solves actual problems\n",
    "- ‚úÖ **Clean code**: Readable, documented, organized\n",
    "- ‚úÖ **GitHub presence**: Active commits, good README\n",
    "- ‚úÖ **Modern tech stack**: 2024-2025 tools (Transformers, RAG, etc.)\n",
    "\n",
    "**What they DON'T care about:**\n",
    "- ‚ùå Tutorial projects everyone does (Iris, Titanic, MNIST)\n",
    "- ‚ùå Jupyter notebooks with no structure\n",
    "- ‚ùå Projects without README or documentation\n",
    "- ‚ùå Code that doesn't run\n",
    "- ‚ùå Outdated tech stack (TensorFlow 1.x, etc.)\n",
    "\n",
    "### üíº What Makes a Great Capstone Project?\n",
    "\n",
    "**The IMPACT Framework:**\n",
    "\n",
    "**I**nteresting - Solves a real problem you care about  \n",
    "**M**odern - Uses 2024-2025 AI techniques  \n",
    "**P**rofessional - Clean code, documentation, deployment  \n",
    "**A**ccessible - Clear README, reproducible results  \n",
    "**C**omprehensive - Shows multiple skills  \n",
    "**T**estable - Includes validation, metrics, examples  \n",
    "\n",
    "### üåü Project Complexity Levels:\n",
    "\n",
    "**Level 1: Beginner (Good for First Project)**\n",
    "- Single model (classification/regression)\n",
    "- Pre-processed dataset\n",
    "- Basic deployment (Streamlit)\n",
    "- **Example:** Sentiment analysis on movie reviews\n",
    "\n",
    "**Level 2: Intermediate (Portfolio Worthy)**\n",
    "- Multiple models or complex architecture\n",
    "- Custom data collection/processing\n",
    "- Web deployment + API\n",
    "- **Example:** RAG chatbot for company docs\n",
    "\n",
    "**Level 3: Advanced (Job-Landing)**\n",
    "- Novel approach or combination\n",
    "- Large-scale data pipeline\n",
    "- Production-ready deployment\n",
    "- **Example:** Multi-modal AI (CV + NLP)\n",
    "\n",
    "### üé® Top Project Categories (2024-2025):\n",
    "\n",
    "**üî• HOT - These get attention:**\n",
    "1. **LLM Applications**: RAG systems, chatbots, agents\n",
    "2. **Computer Vision**: Object detection, image generation\n",
    "3. **Multi-Modal AI**: Combining text + images + audio\n",
    "4. **Healthcare AI**: Medical image analysis, diagnosis support\n",
    "5. **Recommendation Systems**: Personalization at scale\n",
    "\n",
    "**‚úÖ SOLID - These show fundamentals:**\n",
    "6. **Time Series Forecasting**: Stock, weather, sales\n",
    "7. **NLP Applications**: Summarization, translation, extraction\n",
    "8. **Anomaly Detection**: Fraud, cybersecurity, quality control\n",
    "9. **Reinforcement Learning**: Game AI, optimization\n",
    "10. **AutoML**: Automated model selection and tuning\n",
    "\n",
    "Let's plan YOUR project!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choosing-project",
   "metadata": {},
   "source": [
    "## üéØ Choosing Your Capstone Project\n",
    "\n",
    "**3-Step Process to Pick the Perfect Project**\n",
    "\n",
    "### Step 1: Find Your Intersection\n",
    "\n",
    "**The Sweet Spot:**\n",
    "```\n",
    "        Your Interests\n",
    "             ‚à©\n",
    "      Your Skills\n",
    "             ‚à©\n",
    "     Job Market Demand\n",
    "             ‚Üì\n",
    "    YOUR PERFECT PROJECT\n",
    "```\n",
    "\n",
    "**Questions to ask yourself:**\n",
    "1. What problems do I encounter in daily life?\n",
    "2. What industries am I interested in?\n",
    "3. What AI skills do I want to showcase?\n",
    "4. What tech stack do I want to learn?\n",
    "5. How much time do I have? (1 week? 1 month?)\n",
    "\n",
    "### Step 2: Validate Your Idea\n",
    "\n",
    "**Use this checklist:**\n",
    "\n",
    "‚úÖ **Data Availability**: Can I get the data I need?  \n",
    "‚úÖ **Scope**: Can I complete it in my timeframe?  \n",
    "‚úÖ **Uniqueness**: Is it different from common tutorials?  \n",
    "‚úÖ **Demonstrable**: Can I show it in action?  \n",
    "‚úÖ **Explainable**: Can I explain it in interviews?  \n",
    "‚úÖ **Extensible**: Can I add features later?  \n",
    "\n",
    "### Step 3: Scope It Right\n",
    "\n",
    "**Common mistakes:**\n",
    "- ‚ùå Too ambitious: \"Build GPT-5\" (impossible)\n",
    "- ‚ùå Too simple: \"Iris classification\" (boring)\n",
    "- ‚ùå Too vague: \"Make something with AI\" (unfocused)\n",
    "\n",
    "**Sweet spot formula:**\n",
    "```\n",
    "1 Core Feature (MVP)\n",
    "+\n",
    "2-3 Nice-to-Have Features\n",
    "+\n",
    "Professional Presentation\n",
    "=\n",
    "Portfolio-Worthy Project\n",
    "```\n",
    "\n",
    "### üåü Project Ideas by Interest:\n",
    "\n",
    "**Healthcare:**\n",
    "- Medical image classification (X-rays, skin lesions)\n",
    "- Symptom checker chatbot with RAG\n",
    "- Drug interaction predictor\n",
    "- Mental health sentiment analyzer\n",
    "\n",
    "**Finance:**\n",
    "- Stock price prediction with sentiment analysis\n",
    "- Fraud detection system\n",
    "- Personal finance advisor chatbot\n",
    "- Credit risk assessment\n",
    "\n",
    "**E-commerce:**\n",
    "- Product recommendation engine\n",
    "- Review sentiment analyzer\n",
    "- Visual search (find similar products)\n",
    "- Price optimization predictor\n",
    "\n",
    "**Social Good:**\n",
    "- Fake news detector\n",
    "- Wildlife conservation (animal detection)\n",
    "- Disaster response (damage assessment)\n",
    "- Accessibility tools (image-to-text for blind)\n",
    "\n",
    "**Content/Media:**\n",
    "- News summarizer with RAG\n",
    "- Video highlights generator\n",
    "- Music recommendation system\n",
    "- Content moderation system\n",
    "\n",
    "**Tech/Developer Tools:**\n",
    "- Code documentation generator\n",
    "- Bug predictor\n",
    "- Code review assistant\n",
    "- API testing automation\n",
    "\n",
    "**Choose what YOU'RE passionate about - that enthusiasm shows in interviews!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project-brainstorm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Project Brainstorming Tool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"üé® PROJECT BRAINSTORMING WORKSHEET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define project ideas with different attributes\n",
    "project_ideas = {\n",
    "    'Project Name': [\n",
    "        'Medical Image Classifier',\n",
    "        'RAG Customer Support Bot',\n",
    "        'Stock Sentiment Analyzer',\n",
    "        'Multi-Modal Product Search',\n",
    "        'Fake News Detector',\n",
    "        'AI Code Reviewer',\n",
    "        'Recipe Recommendation System',\n",
    "        'Real Estate Price Predictor'\n",
    "    ],\n",
    "    'Difficulty': ['Intermediate', 'Advanced', 'Intermediate', 'Advanced', \n",
    "                   'Intermediate', 'Advanced', 'Beginner', 'Intermediate'],\n",
    "    'Tech Stack': ['CNN, PyTorch', 'LLM, RAG, Vector DB', 'NLP, APIs, Time Series',\n",
    "                   'CV + NLP, Embeddings', 'Transformers, NLP', 'LLM, Code Analysis',\n",
    "                   'Collaborative Filtering', 'ML, Feature Engineering'],\n",
    "    'Time (weeks)': [2, 3, 2, 4, 2, 3, 1, 2],\n",
    "    'Hot in 2024-25': ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No'],\n",
    "    'Data Availability': ['Good', 'Medium', 'Good', 'Medium', 'Good', 'Good', 'Good', 'Good']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(project_ideas)\n",
    "\n",
    "print(\"\\nüìä Sample Project Ideas:\\n\")\n",
    "display(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° How to use this:\\n\")\n",
    "print(\"1. Review the project ideas above\")\n",
    "print(\"2. Note which ones align with your interests\")\n",
    "print(\"3. Consider difficulty vs. your current skill level\")\n",
    "print(\"4. Check if you can commit the required time\")\n",
    "print(\"5. Verify data availability for your chosen idea\")\n",
    "print(\"\\nüéØ Pro Tip: Start with 'Intermediate' for your first portfolio project!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project-scorecard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Evaluation Scorecard\n",
    "\n",
    "def evaluate_project_idea(project_name, scores):\n",
    "    \"\"\"\n",
    "    Evaluate your project idea across key dimensions\n",
    "    \n",
    "    scores: dict with keys:\n",
    "        - data_availability (1-5): How easy to get data?\n",
    "        - personal_interest (1-5): How interested are you?\n",
    "        - market_demand (1-5): Is it relevant to jobs?\n",
    "        - technical_fit (1-5): Match with your skills?\n",
    "        - uniqueness (1-5): How unique is it?\n",
    "        - time_feasible (1-5): Can you finish it?\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä PROJECT EVALUATION SCORECARD\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nProject: {project_name}\\n\")\n",
    "    \n",
    "    criteria = [\n",
    "        ('Data Availability', 'data_availability', 'üìÅ'),\n",
    "        ('Personal Interest', 'personal_interest', '‚ù§Ô∏è'),\n",
    "        ('Market Demand', 'market_demand', 'üíº'),\n",
    "        ('Technical Fit', 'technical_fit', 'üîß'),\n",
    "        ('Uniqueness', 'uniqueness', '‚≠ê'),\n",
    "        ('Time Feasible', 'time_feasible', '‚è∞')\n",
    "    ]\n",
    "    \n",
    "    total_score = 0\n",
    "    max_score = 0\n",
    "    \n",
    "    for name, key, emoji in criteria:\n",
    "        score = scores.get(key, 0)\n",
    "        total_score += score\n",
    "        max_score += 5\n",
    "        \n",
    "        # Visual representation\n",
    "        stars = '‚≠ê' * score + '‚òÜ' * (5 - score)\n",
    "        print(f\"{emoji} {name:20s}: {stars} ({score}/5)\")\n",
    "    \n",
    "    percentage = (total_score / max_score) * 100\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"\\nüéØ Overall Score: {total_score}/{max_score} ({percentage:.1f}%)\\n\")\n",
    "    \n",
    "    # Recommendation\n",
    "    if percentage >= 80:\n",
    "        print(\"‚úÖ EXCELLENT CHOICE! This project is well-suited for you.\")\n",
    "    elif percentage >= 60:\n",
    "        print(\"üëç GOOD PROJECT! Consider addressing lower-scoring areas.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  RECONSIDER: This project may have significant challenges.\")\n",
    "    \n",
    "    # Specific recommendations\n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    if scores.get('data_availability', 0) < 3:\n",
    "        print(\"   - Data availability is low. Research data sources first!\")\n",
    "    if scores.get('time_feasible', 0) < 3:\n",
    "        print(\"   - Time feasibility is low. Consider reducing scope.\")\n",
    "    if scores.get('uniqueness', 0) < 3:\n",
    "        print(\"   - Uniqueness is low. Add a creative twist to stand out!\")\n",
    "    if scores.get('personal_interest', 0) < 3:\n",
    "        print(\"   - Interest is low. Choose something you're passionate about!\")\n",
    "    \n",
    "    return percentage\n",
    "\n",
    "# Example evaluation\n",
    "print(\"\\nüìù EXAMPLE: Evaluating 'RAG Customer Support Bot'\\n\")\n",
    "\n",
    "example_scores = {\n",
    "    'data_availability': 4,  # Can use public docs or create own\n",
    "    'personal_interest': 5,  # Very interested in LLMs\n",
    "    'market_demand': 5,      # RAG is HOT in 2024-2025\n",
    "    'technical_fit': 4,      # Have learned transformers and RAG\n",
    "    'uniqueness': 4,         # Can customize for specific domain\n",
    "    'time_feasible': 4       # 2-3 weeks is doable\n",
    "}\n",
    "\n",
    "score = evaluate_project_idea(\"RAG Customer Support Bot\", example_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüéØ YOUR TURN: Use this function to evaluate YOUR project idea!\")\n",
    "print(\"\\nTo evaluate your idea:\")\n",
    "print(\"\"\"\n",
    "my_scores = {\n",
    "    'data_availability': 4,\n",
    "    'personal_interest': 5,\n",
    "    'market_demand': 5,\n",
    "    'technical_fit': 3,\n",
    "    'uniqueness': 4,\n",
    "    'time_feasible': 4\n",
    "}\n",
    "\n",
    "evaluate_project_idea(\"My Project Name\", my_scores)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-planning",
   "metadata": {},
   "source": [
    "## üìã Project Planning & Scoping\n",
    "\n",
    "**Planning = 20% of time, saves 80% of headaches!**\n",
    "\n",
    "### üéØ The Project Planning Framework\n",
    "\n",
    "**1. Define Your MVP (Minimum Viable Project)**\n",
    "\n",
    "Ask yourself:\n",
    "- What's the CORE feature that demonstrates value?\n",
    "- What's the simplest version that works?\n",
    "- What can I cut and add later?\n",
    "\n",
    "**Example: RAG Chatbot**\n",
    "- ‚úÖ MVP: Answer questions from 10 documents\n",
    "- ‚è≥ Later: Add 1000s of documents\n",
    "- ‚è≥ Later: Add chat history\n",
    "- ‚è≥ Later: Add multi-user support\n",
    "\n",
    "**2. Break Down into Phases**\n",
    "\n",
    "**Phase 1: Data & Exploration (Week 1)**\n",
    "- Collect/prepare data\n",
    "- Exploratory data analysis\n",
    "- Baseline model\n",
    "\n",
    "**Phase 2: Model Development (Week 2)**\n",
    "- Build main model\n",
    "- Evaluate performance\n",
    "- Iterate and improve\n",
    "\n",
    "**Phase 3: Deployment & Documentation (Week 3)**\n",
    "- Deploy (Streamlit/Gradio/FastAPI)\n",
    "- Write README\n",
    "- Create demo video\n",
    "\n",
    "**3. Set Success Criteria**\n",
    "\n",
    "**Technical Metrics:**\n",
    "- Accuracy > 85%\n",
    "- Response time < 2 seconds\n",
    "- Works on test set\n",
    "\n",
    "**Portfolio Metrics:**\n",
    "- Clean, documented code\n",
    "- Professional README\n",
    "- Working demo\n",
    "- Video walkthrough\n",
    "\n",
    "### üìä Project Scope Template\n",
    "\n",
    "**Use this for ANY project:**\n",
    "\n",
    "```markdown\n",
    "# Project: [NAME]\n",
    "\n",
    "## üéØ Goal\n",
    "[One sentence: What problem does this solve?]\n",
    "\n",
    "## üìä Data\n",
    "- Source: [Where will you get data?]\n",
    "- Size: [How much data?]\n",
    "- Format: [CSV, JSON, images, text?]\n",
    "\n",
    "## ü§ñ Approach\n",
    "- Model: [What architecture?]\n",
    "- Tools: [PyTorch, HuggingFace, etc.]\n",
    "- Deployment: [Streamlit, FastAPI, etc.]\n",
    "\n",
    "## ‚úÖ MVP Features\n",
    "1. [Core feature 1]\n",
    "2. [Core feature 2]\n",
    "3. [Core feature 3]\n",
    "\n",
    "## üé® Nice-to-Have\n",
    "- [Feature 4]\n",
    "- [Feature 5]\n",
    "\n",
    "## üìÖ Timeline\n",
    "- Week 1: Data + EDA\n",
    "- Week 2: Modeling\n",
    "- Week 3: Deployment + Docs\n",
    "\n",
    "## üéØ Success Criteria\n",
    "- Technical: [Metrics]\n",
    "- Portfolio: [Deliverables]\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Common Pitfalls to Avoid\n",
    "\n",
    "**1. Scope Creep**\n",
    "- ‚ùå Problem: Keep adding features, never finish\n",
    "- ‚úÖ Solution: Stick to MVP, add features AFTER deployment\n",
    "\n",
    "**2. Perfect Model Syndrome**\n",
    "- ‚ùå Problem: Spend weeks tuning from 85% to 87%\n",
    "- ‚úÖ Solution: 85% is fine! Focus on presentation\n",
    "\n",
    "**3. Tutorial Hell**\n",
    "- ‚ùå Problem: Follow tutorial exactly, no originality\n",
    "- ‚úÖ Solution: Use tutorials for reference, add YOUR twist\n",
    "\n",
    "**4. No Documentation**\n",
    "- ‚ùå Problem: Great code, terrible README\n",
    "- ‚úÖ Solution: Document as you go, not at the end\n",
    "\n",
    "**5. Can't Demo**\n",
    "- ‚ùå Problem: Works on your laptop only\n",
    "- ‚úÖ Solution: Deploy early, test on other machines\n",
    "\n",
    "### üéØ The 70-20-10 Rule\n",
    "\n",
    "**Allocate your time wisely:**\n",
    "- **70%**: Core functionality (model works!)\n",
    "- **20%**: Polish & deployment (looks professional)\n",
    "- **10%**: Documentation & demo (tells the story)\n",
    "\n",
    "**Most beginners do:**\n",
    "- 90% modeling, 10% everything else ‚ùå\n",
    "\n",
    "**You should do:**\n",
    "- 70% modeling, 30% making it portfolio-worthy ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Timeline Generator\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_project_timeline(project_name, start_date, duration_weeks=3):\n",
    "    \"\"\"\n",
    "    Create a project timeline with milestones\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìÖ PROJECT TIMELINE: {project_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Define phases\n",
    "    phases = [\n",
    "        {\n",
    "            'phase': 'Week 1: Data & Foundation',\n",
    "            'tasks': [\n",
    "                'Data collection & cleaning',\n",
    "                'Exploratory Data Analysis (EDA)',\n",
    "                'Baseline model',\n",
    "                'Initial GitHub repo setup'\n",
    "            ],\n",
    "            'deliverables': 'Clean dataset, EDA notebook, baseline metrics'\n",
    "        },\n",
    "        {\n",
    "            'phase': 'Week 2: Model Development',\n",
    "            'tasks': [\n",
    "                'Implement main model architecture',\n",
    "                'Training & hyperparameter tuning',\n",
    "                'Model evaluation & validation',\n",
    "                'Error analysis & improvements'\n",
    "            ],\n",
    "            'deliverables': 'Trained model, evaluation metrics, saved checkpoints'\n",
    "        },\n",
    "        {\n",
    "            'phase': 'Week 3: Deployment & Polish',\n",
    "            'tasks': [\n",
    "                'Build demo interface (Streamlit/Gradio)',\n",
    "                'Write comprehensive README',\n",
    "                'Create requirements.txt & setup',\n",
    "                'Record demo video',\n",
    "                'Final testing & debugging'\n",
    "            ],\n",
    "            'deliverables': 'Deployed app, README, demo video, clean repo'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    \n",
    "    for i, phase in enumerate(phases):\n",
    "        week_start = start + timedelta(weeks=i)\n",
    "        week_end = week_start + timedelta(days=6)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìç {phase['phase']}\")\n",
    "        print(f\"   Dates: {week_start.strftime('%b %d')} - {week_end.strftime('%b %d, %Y')}\")\n",
    "        print(f\"\\n   ‚úÖ Tasks:\")\n",
    "        for task in phase['tasks']:\n",
    "            print(f\"      ‚Ä¢ {task}\")\n",
    "        print(f\"\\n   üì¶ Deliverables: {phase['deliverables']}\")\n",
    "    \n",
    "    completion_date = start + timedelta(weeks=duration_weeks)\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"\\nüéâ Project Completion: {completion_date.strftime('%B %d, %Y')}\")\n",
    "    print(f\"\\nüí° Pro Tips:\")\n",
    "    print(f\"   ‚Ä¢ Commit to GitHub daily\")\n",
    "    print(f\"   ‚Ä¢ Document as you go, not at the end\")\n",
    "    print(f\"   ‚Ä¢ Test your code on a different machine\")\n",
    "    print(f\"   ‚Ä¢ Get feedback from peers early\")\n",
    "    print(f\"   ‚Ä¢ Don't aim for perfection - aim for completion!\")\n",
    "\n",
    "# Example usage\n",
    "create_project_timeline(\n",
    "    project_name=\"AI Customer Support RAG Chatbot\",\n",
    "    start_date=\"2025-01-01\",\n",
    "    duration_weeks=3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüéØ Use this timeline as a template for YOUR project!\")\n",
    "print(\"\\nModify the start_date to match when you begin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-collection",
   "metadata": {},
   "source": [
    "## üìä Data Collection Strategies\n",
    "\n",
    "**Your model is only as good as your data!**\n",
    "\n",
    "### üéØ Data Sources for AI Projects\n",
    "\n",
    "**1. Public Datasets (Best for Starting)**\n",
    "\n",
    "**Kaggle** - https://kaggle.com/datasets\n",
    "- ‚úÖ 100,000+ datasets\n",
    "- ‚úÖ Clean, well-documented\n",
    "- ‚úÖ Competition data\n",
    "- üí° Great for: Most ML tasks\n",
    "\n",
    "**HuggingFace Datasets** - https://huggingface.co/datasets\n",
    "- ‚úÖ NLP-focused\n",
    "- ‚úÖ Easy to load (1 line of code)\n",
    "- ‚úÖ Pre-processed\n",
    "- üí° Great for: NLP, text classification\n",
    "\n",
    "**UCI ML Repository** - https://archive.ics.uci.edu/ml\n",
    "- ‚úÖ Classic datasets\n",
    "- ‚úÖ Well-cited\n",
    "- ‚úÖ Documentation\n",
    "- üí° Great for: Traditional ML\n",
    "\n",
    "**Google Dataset Search** - https://datasetsearch.research.google.com\n",
    "- ‚úÖ Search engine for datasets\n",
    "- ‚úÖ Academic sources\n",
    "- üí° Great for: Finding niche data\n",
    "\n",
    "**Government Data**\n",
    "- data.gov (US)\n",
    "- data.gov.uk (UK)\n",
    "- open.canada.ca (Canada)\n",
    "- üí° Great for: Social impact projects\n",
    "\n",
    "**Computer Vision:**\n",
    "- ImageNet - image classification\n",
    "- COCO - object detection\n",
    "- Open Images - multi-label\n",
    "- Roboflow - custom vision data\n",
    "\n",
    "**2. Web Scraping (For Custom Data)**\n",
    "\n",
    "**Libraries:**\n",
    "```python\n",
    "# BeautifulSoup - HTML parsing\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Scrapy - Full framework\n",
    "import scrapy\n",
    "\n",
    "# Selenium - JavaScript-heavy sites\n",
    "from selenium import webdriver\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Web Scraping Ethics:**\n",
    "- ‚úÖ Check robots.txt\n",
    "- ‚úÖ Respect rate limits\n",
    "- ‚úÖ Use APIs when available\n",
    "- ‚ùå Don't scrape private data\n",
    "- ‚ùå Don't overload servers\n",
    "\n",
    "**3. APIs (Best for Real-Time Data)**\n",
    "\n",
    "**Free APIs:**\n",
    "- Twitter API - social media\n",
    "- Reddit API - discussions\n",
    "- News API - news articles\n",
    "- Financial APIs - stock data\n",
    "- Weather APIs - climate data\n",
    "\n",
    "**4. Create Your Own Dataset**\n",
    "\n",
    "**Labeling Tools:**\n",
    "- Label Studio - multi-modal annotation\n",
    "- Roboflow - computer vision\n",
    "- Prodigy - NLP annotation\n",
    "\n",
    "**Crowdsourcing:**\n",
    "- Amazon Mechanical Turk\n",
    "- Scale AI\n",
    "- Labelbox\n",
    "\n",
    "### üìã Data Quality Checklist\n",
    "\n",
    "**Before using ANY dataset:**\n",
    "\n",
    "‚úÖ **Size**: Enough examples? (Minimum: 1000+ for most tasks)  \n",
    "‚úÖ **Balance**: Are classes balanced?  \n",
    "‚úÖ **Quality**: Missing values? Errors? Outliers?  \n",
    "‚úÖ **Relevance**: Matches your problem?  \n",
    "‚úÖ **License**: Can you use it? Commercial OK?  \n",
    "‚úÖ **Bias**: Any demographic/sample bias?  \n",
    "‚úÖ **Freshness**: Is data recent enough?  \n",
    "\n",
    "### üéØ Data Collection Strategy by Project Type\n",
    "\n",
    "**Image Classification:**\n",
    "1. Search Kaggle/ImageNet\n",
    "2. If not found, use Google Images API\n",
    "3. Supplement with custom photos\n",
    "4. Augment to increase size\n",
    "\n",
    "**NLP/Text:**\n",
    "1. Check HuggingFace Datasets\n",
    "2. Use Twitter/Reddit API\n",
    "3. Web scrape news/blogs\n",
    "4. Generate synthetic data (GPT)\n",
    "\n",
    "**Time Series:**\n",
    "1. Financial data (Yahoo Finance)\n",
    "2. Government data (data.gov)\n",
    "3. IoT sensors\n",
    "4. Web APIs\n",
    "\n",
    "**Tabular:**\n",
    "1. Kaggle competitions\n",
    "2. UCI repository\n",
    "3. Industry-specific sources\n",
    "4. Synthetic data generation\n",
    "\n",
    "### üí° Pro Tips:\n",
    "\n",
    "1. **Start small**: Get 100 examples working before collecting 100,000\n",
    "2. **Version control**: Track data versions (DVC, Git LFS)\n",
    "3. **Document sources**: Note where every piece came from\n",
    "4. **Test/Train split FIRST**: Prevent data leakage\n",
    "5. **Augmentation**: Use data augmentation to expand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-sources-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source Examples and Code Snippets\n",
    "\n",
    "print(\"üìä DATA COLLECTION CODE EXAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example 1: Loading HuggingFace Dataset\n",
    "print(\"\\n1Ô∏è‚É£ HUGGINGFACE DATASETS\\n\")\n",
    "print(\"\"\"\n",
    "# Install: pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load IMDB sentiment dataset (25,000 movie reviews)\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "print(f\"Train size: {len(dataset['train'])}\")\n",
    "print(f\"Test size: {len(dataset['test'])}\")\n",
    "print(f\"Example: {dataset['train'][0]}\")\n",
    "\n",
    "# Other popular datasets:\n",
    "# - 'squad': Question answering\n",
    "# - 'glue': Text classification benchmarks\n",
    "# - 'common_voice': Speech recognition\n",
    "# - 'imagenet-1k': Image classification\n",
    "\"\"\")\n",
    "\n",
    "# Example 2: Kaggle API\n",
    "print(\"\\n2Ô∏è‚É£ KAGGLE API\\n\")\n",
    "print(\"\"\"\n",
    "# Install: pip install kaggle\n",
    "# Setup: Download API key from kaggle.com/settings\n",
    "\n",
    "import kaggle\n",
    "\n",
    "# Download competition data\n",
    "kaggle.api.competition_download_files(\n",
    "    'titanic',\n",
    "    path='./data'\n",
    ")\n",
    "\n",
    "# Search for datasets\n",
    "datasets = kaggle.api.dataset_list(search='stock prices')\n",
    "for dataset in datasets[:5]:\n",
    "    print(dataset.ref)\n",
    "\n",
    "# Download specific dataset\n",
    "kaggle.api.dataset_download_files(\n",
    "    'username/dataset-name',\n",
    "    path='./data',\n",
    "    unzip=True\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Example 3: Web Scraping\n",
    "print(\"\\n3Ô∏è‚É£ WEB SCRAPING\\n\")\n",
    "print(\"\"\"\n",
    "# Install: pip install beautifulsoup4 requests\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_news_headlines(url):\n",
    "    # Add headers to avoid blocking\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (compatible; MyBot/1.0)'\n",
    "    }\n",
    "    \n",
    "    # Get webpage\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract headlines (adjust selectors for your site)\n",
    "    headlines = []\n",
    "    for h2 in soup.find_all('h2', class_='headline'):\n",
    "        headlines.append(h2.text.strip())\n",
    "    \n",
    "    return headlines\n",
    "\n",
    "# Use with rate limiting!\n",
    "# time.sleep(1)  # Be respectful to servers\n",
    "\n",
    "‚ö†Ô∏è ALWAYS:\n",
    "- Check robots.txt\n",
    "- Add delays between requests\n",
    "- Use official APIs when available\n",
    "\"\"\")\n",
    "\n",
    "# Example 4: API Usage\n",
    "print(\"\\n4Ô∏è‚É£ API DATA COLLECTION\\n\")\n",
    "print(\"\"\"\n",
    "# Example: NewsAPI (get API key from newsapi.org)\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_news_data(api_key, query, days=7):\n",
    "    url = 'https://newsapi.org/v2/everything'\n",
    "    \n",
    "    params = {\n",
    "        'q': query,\n",
    "        'apiKey': api_key,\n",
    "        'language': 'en',\n",
    "        'sortBy': 'publishedAt',\n",
    "        'pageSize': 100\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    articles = []\n",
    "    for article in data.get('articles', []):\n",
    "        articles.append({\n",
    "            'title': article['title'],\n",
    "            'description': article['description'],\n",
    "            'content': article['content'],\n",
    "            'published': article['publishedAt']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# Other free APIs:\n",
    "# - Reddit: reddit.com/dev/api\n",
    "# - Twitter: developer.twitter.com\n",
    "# - GitHub: docs.github.com/rest\n",
    "# - Weather: openweathermap.org/api\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Data Collection Best Practices:\")\n",
    "print(\"\\n1. Start with public datasets when possible\")\n",
    "print(\"2. Always check licenses and terms of use\")\n",
    "print(\"3. Version control your data (use DVC or Git LFS)\")\n",
    "print(\"4. Document data sources and collection methods\")\n",
    "print(\"5. Validate data quality before modeling\")\n",
    "print(\"6. Be ethical - respect privacy and rate limits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "github-portfolio",
   "metadata": {},
   "source": [
    "## üêô Setting Up Your GitHub Portfolio\n",
    "\n",
    "**Your GitHub is your AI resume - make it shine!**\n",
    "\n",
    "### üéØ Why GitHub Matters\n",
    "\n",
    "**Recruiters check GitHub for:**\n",
    "- ‚úÖ Code quality\n",
    "- ‚úÖ Project organization\n",
    "- ‚úÖ Documentation skills\n",
    "- ‚úÖ Commit frequency\n",
    "- ‚úÖ Collaboration ability\n",
    "\n",
    "**85% of tech recruiters review GitHub profiles!**\n",
    "\n",
    "### üìÅ Repository Structure (Best Practices)\n",
    "\n",
    "**Perfect Project Structure:**\n",
    "```\n",
    "my-ai-project/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ README.md              ‚≠ê Most important file!\n",
    "‚îú‚îÄ‚îÄ requirements.txt       üì¶ Dependencies\n",
    "‚îú‚îÄ‚îÄ setup.py              üîß Installation\n",
    "‚îú‚îÄ‚îÄ .gitignore            üö´ Ignore junk files\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ data/                 üìä Data files\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/              (original data)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ processed/        (clean data)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ README.md         (data documentation)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ notebooks/            üìì Jupyter notebooks\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 01-eda.ipynb\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 02-modeling.ipynb\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 03-evaluation.ipynb\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ src/                  üêç Source code\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ predict.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ models/               ü§ñ Saved models\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ tests/                ‚úÖ Unit tests\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_model.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ app/                  üåê Web app (if applicable)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ docs/                 üìö Documentation\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ architecture.md\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ api.md\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ assets/               üñºÔ∏è Images for README\n",
    "    ‚îú‚îÄ‚îÄ demo.gif\n",
    "    ‚îî‚îÄ‚îÄ results.png\n",
    "```\n",
    "\n",
    "### üìù The Perfect README Template\n",
    "\n",
    "**Your README should answer:**\n",
    "1. What does this do?\n",
    "2. Why is it useful?\n",
    "3. How do I use it?\n",
    "4. How does it work?\n",
    "5. What are the results?\n",
    "\n",
    "**README Template:**\n",
    "```markdown\n",
    "# ü§ñ Project Name\n",
    "\n",
    "[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)]\n",
    "[![License](https://img.shields.io/badge/License-MIT-green.svg)]\n",
    "\n",
    "> One-line description of what this does\n",
    "\n",
    "![Demo](assets/demo.gif)\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "Brief description (2-3 sentences):\n",
    "- What problem does this solve?\n",
    "- How does it solve it?\n",
    "- What makes it unique?\n",
    "\n",
    "## ‚ú® Features\n",
    "\n",
    "- ‚úÖ Feature 1\n",
    "- ‚úÖ Feature 2\n",
    "- ‚úÖ Feature 3\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.9+\n",
    "- pip\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Clone the repository\n",
    "git clone https://github.com/username/project.git\n",
    "cd project\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Usage\n",
    "\n",
    "```python\n",
    "# Example code showing how to use\n",
    "from src.model import MyModel\n",
    "\n",
    "model = MyModel()\n",
    "result = model.predict(data)\n",
    "```\n",
    "\n",
    "## üìä Results\n",
    "\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "| Accuracy | 94.5% |\n",
    "| F1 Score | 0.92 |\n",
    "\n",
    "![Results](assets/results.png)\n",
    "\n",
    "## üèóÔ∏è Architecture\n",
    "\n",
    "Brief explanation of how it works:\n",
    "1. Data preprocessing\n",
    "2. Model architecture\n",
    "3. Training process\n",
    "\n",
    "## üìÅ Project Structure\n",
    "\n",
    "```\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ src/          # Source code\n",
    "‚îú‚îÄ‚îÄ data/         # Datasets\n",
    "‚îú‚îÄ‚îÄ models/       # Trained models\n",
    "‚îî‚îÄ‚îÄ notebooks/    # Jupyter notebooks\n",
    "```\n",
    "\n",
    "## üîÆ Future Improvements\n",
    "\n",
    "- [ ] Add feature X\n",
    "- [ ] Improve performance\n",
    "- [ ] Deploy to cloud\n",
    "\n",
    "## üìù License\n",
    "\n",
    "MIT License - see LICENSE file\n",
    "\n",
    "## üë§ Author\n",
    "\n",
    "**Your Name**\n",
    "- GitHub: [@username](https://github.com/username)\n",
    "- LinkedIn: [Profile](https://linkedin.com/in/username)\n",
    "- Email: your.email@example.com\n",
    "\n",
    "## üôè Acknowledgments\n",
    "\n",
    "- Dataset from [Source]\n",
    "- Inspired by [Paper/Project]\n",
    "```\n",
    "\n",
    "### üé® GitHub Profile Tips\n",
    "\n",
    "**1. Create a Profile README**\n",
    "- Create repo: `username/username`\n",
    "- Add README.md (shows on your profile!)\n",
    "- Include: Bio, skills, featured projects\n",
    "\n",
    "**2. Pin Your Best Projects**\n",
    "- Pin 6 repositories\n",
    "- Choose diverse projects\n",
    "- Prioritize recent, complete work\n",
    "\n",
    "**3. Commit Consistently**\n",
    "- Green squares matter!\n",
    "- Commit regularly (even small updates)\n",
    "- Shows dedication and activity\n",
    "\n",
    "**4. Use Topics/Tags**\n",
    "- Add relevant tags: `machine-learning`, `pytorch`, `nlp`\n",
    "- Makes projects discoverable\n",
    "- Shows up in search\n",
    "\n",
    "**5. Add Badges**\n",
    "- Build status (if you have CI/CD)\n",
    "- Python version\n",
    "- License\n",
    "- Makes it look professional\n",
    "\n",
    "### ‚ö†Ô∏è Common GitHub Mistakes\n",
    "\n",
    "**‚ùå Don't:**\n",
    "- Upload 100s of tutorial repos (looks like tutorial hell)\n",
    "- Commit passwords/API keys (.gitignore them!)\n",
    "- Have empty or poorly documented projects\n",
    "- Use vague names (\"project1\", \"ai-stuff\")\n",
    "- Upload massive files (>100MB) without Git LFS\n",
    "\n",
    "**‚úÖ Do:**\n",
    "- 5-10 QUALITY projects > 100 tutorials\n",
    "- Clear, descriptive names\n",
    "- Professional README for each\n",
    "- Regular commits showing progress\n",
    "- Include demo GIFs/images\n",
    "\n",
    "### üéØ GitHub Portfolio Checklist\n",
    "\n",
    "**Profile:**\n",
    "- [ ] Professional profile picture\n",
    "- [ ] Complete bio with interests\n",
    "- [ ] Profile README with featured work\n",
    "- [ ] LinkedIn/email links\n",
    "\n",
    "**Each Project:**\n",
    "- [ ] Clear, descriptive name\n",
    "- [ ] Comprehensive README\n",
    "- [ ] requirements.txt\n",
    "- [ ] .gitignore configured\n",
    "- [ ] Demo GIF or screenshots\n",
    "- [ ] Clean, organized structure\n",
    "- [ ] License file\n",
    "- [ ] Runs on other machines\n",
    "\n",
    "**Overall:**\n",
    "- [ ] 3-6 pinned projects\n",
    "- [ ] Green commit squares\n",
    "- [ ] Recent activity (< 1 month)\n",
    "- [ ] Diverse projects (CV, NLP, ML, etc.)\n",
    "- [ ] At least 1 deployed project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "github-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Repository Setup Script\n",
    "\n",
    "print(\"üêô GITHUB PROJECT SETUP GUIDE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "### STEP 1: Initialize Git Repository\n",
    "\n",
    "```bash\n",
    "# In your project directory\n",
    "cd my-ai-project\n",
    "\n",
    "# Initialize git\n",
    "git init\n",
    "\n",
    "# Create .gitignore\n",
    "cat > .gitignore << EOL\n",
    "# Python\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*.so\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    ".venv/\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints\n",
    "\n",
    "# Data (large files)\n",
    "data/raw/*\n",
    "!data/raw/.gitkeep\n",
    "*.csv\n",
    "*.h5\n",
    "*.pkl\n",
    "\n",
    "# Models (large files)\n",
    "models/*.pth\n",
    "models/*.h5\n",
    "!models/.gitkeep\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "\n",
    "# OS\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# Environment\n",
    ".env\n",
    "*.key\n",
    "*.secret\n",
    "EOL\n",
    "\n",
    "# Initial commit\n",
    "git add .\n",
    "git commit -m \"Initial commit: Project structure\"\n",
    "```\n",
    "\n",
    "### STEP 2: Create GitHub Repository\n",
    "\n",
    "```bash\n",
    "# Option 1: Via GitHub CLI (gh)\n",
    "gh repo create my-ai-project --public --source=. --remote=origin\n",
    "gh repo edit --description \"Brief project description\"\n",
    "gh repo edit --add-topic machine-learning,python,ai\n",
    "\n",
    "# Option 2: Manual\n",
    "# 1. Go to github.com and click \"New Repository\"\n",
    "# 2. Name it (same as local folder)\n",
    "# 3. Don't initialize with README (you have one)\n",
    "# 4. Copy the commands shown:\n",
    "\n",
    "git remote add origin https://github.com/username/my-ai-project.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "### STEP 3: Create requirements.txt\n",
    "\n",
    "```bash\n",
    "# Auto-generate from current environment\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "# OR manually create with only necessary packages:\n",
    "cat > requirements.txt << EOL\n",
    "numpy>=1.24.0\n",
    "pandas>=2.0.0\n",
    "scikit-learn>=1.3.0\n",
    "torch>=2.0.0\n",
    "transformers>=4.30.0\n",
    "matplotlib>=3.7.0\n",
    "seaborn>=0.12.0\n",
    "streamlit>=1.25.0\n",
    "EOL\n",
    "```\n",
    "\n",
    "### STEP 4: Create Professional README\n",
    "\n",
    "Use the template from the previous section!\n",
    "\n",
    "### STEP 5: Add Shields/Badges\n",
    "\n",
    "Go to shields.io and create badges:\n",
    "\n",
    "```markdown\n",
    "![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)\n",
    "![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)\n",
    "![License](https://img.shields.io/badge/License-MIT-green.svg)\n",
    "```\n",
    "\n",
    "### STEP 6: Commit Workflow\n",
    "\n",
    "```bash\n",
    "# Make changes to code...\n",
    "\n",
    "# Check status\n",
    "git status\n",
    "\n",
    "# Add specific files\n",
    "git add src/model.py README.md\n",
    "\n",
    "# OR add all changes\n",
    "git add .\n",
    "\n",
    "# Commit with meaningful message\n",
    "git commit -m \"Add: CNN model architecture\"\n",
    "\n",
    "# Push to GitHub\n",
    "git push origin main\n",
    "```\n",
    "\n",
    "### COMMIT MESSAGE BEST PRACTICES:\n",
    "\n",
    "Use prefixes:\n",
    "- Add: New feature\n",
    "- Fix: Bug fix\n",
    "- Update: Modify existing feature\n",
    "- Docs: Documentation only\n",
    "- Refactor: Code restructure\n",
    "- Test: Add tests\n",
    "\n",
    "Examples:\n",
    "‚úÖ \"Add: RAG system with FAISS vector database\"\n",
    "‚úÖ \"Fix: Image preprocessing pipeline memory leak\"\n",
    "‚úÖ \"Update: Improve model accuracy to 94%\"\n",
    "‚ùå \"updates\"\n",
    "‚ùå \"fixed stuff\"\n",
    "‚ùå \"asdfasdf\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Quick Setup Script:\")\n",
    "print(\"\"\"\n",
    "# Copy this to setup.sh and run: bash setup.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Create project structure\n",
    "mkdir -p data/{raw,processed} notebooks src models tests app docs assets\n",
    "\n",
    "# Create __init__.py files\n",
    "touch src/__init__.py tests/__init__.py\n",
    "\n",
    "# Create .gitkeep for empty directories\n",
    "touch data/raw/.gitkeep data/processed/.gitkeep models/.gitkeep\n",
    "\n",
    "# Create README template\n",
    "echo \"# My AI Project\" > README.md\n",
    "echo \"## Overview\" >> README.md\n",
    "echo \"TODO: Add project description\" >> README.md\n",
    "\n",
    "# Initialize git\n",
    "git init\n",
    "\n",
    "echo \"‚úÖ Project structure created!\"\n",
    "echo \"Next steps:\"\n",
    "echo \"1. Edit README.md\"\n",
    "echo \"2. Create requirements.txt\"\n",
    "echo \"3. git add . && git commit -m 'Initial commit'\"\n",
    "echo \"4. Create GitHub repo and push\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "project-template",
   "metadata": {},
   "source": [
    "## üé® Real AI Example: Complete Project Template\n",
    "\n",
    "**A production-ready template you can use for ANY AI project!**\n",
    "\n",
    "### üì¶ Complete Project: Sentiment Analysis API\n",
    "\n",
    "**Overview:**\n",
    "- **What**: REST API for sentiment analysis\n",
    "- **Why**: Demonstrates end-to-end ML pipeline\n",
    "- **Tech**: Transformers, FastAPI, Docker\n",
    "- **Deployment**: Ready for production\n",
    "\n",
    "**Project Structure:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Project Template Files\n",
    "\n",
    "print(\"üìÅ COMPLETE PROJECT TEMPLATE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThis template shows a production-ready AI project structure.\")\n",
    "print(\"Use this as a starting point for YOUR capstone project!\\n\")\n",
    "\n",
    "# File 1: Project README.md\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ FILE: README.md\")\n",
    "print(\"=\"*70)\n",
    "readme_content = \"\"\"\n",
    "# üé≠ Sentiment Analysis API\n",
    "\n",
    "[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)]\n",
    "[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)]\n",
    "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)]\n",
    "\n",
    "> Production-ready sentiment analysis API using BERT transformers\n",
    "\n",
    "![Demo](assets/demo.gif)\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "A RESTful API that analyzes sentiment (positive/negative/neutral) from text\n",
    "using state-of-the-art BERT models. Designed for production use with\n",
    "FastAPI, Docker, and comprehensive testing.\n",
    "\n",
    "### Features\n",
    "\n",
    "- ‚úÖ **High Accuracy**: 94% on IMDB dataset\n",
    "- ‚úÖ **Fast**: <100ms response time\n",
    "- ‚úÖ **Production Ready**: Docker, logging, error handling\n",
    "- ‚úÖ **Well Tested**: 90%+ code coverage\n",
    "- ‚úÖ **API Docs**: Auto-generated with FastAPI\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Option 1: Docker (Recommended)\n",
    "\n",
    "```bash\n",
    "docker-compose up\n",
    "# Visit http://localhost:8000/docs\n",
    "```\n",
    "\n",
    "### Option 2: Local Installation\n",
    "\n",
    "```bash\n",
    "# Clone repository\n",
    "git clone https://github.com/username/sentiment-api.git\n",
    "cd sentiment-api\n",
    "\n",
    "# Create virtual environment\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # Windows: venv\\\\Scripts\\\\activate\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run server\n",
    "uvicorn app.main:app --reload\n",
    "```\n",
    "\n",
    "### Usage\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/predict\",\n",
    "    json={\"text\": \"I love this product!\"}\n",
    ")\n",
    "\n",
    "print(response.json())\n",
    "# {\"sentiment\": \"positive\", \"confidence\": 0.98}\n",
    "```\n",
    "\n",
    "## üìä Performance\n",
    "\n",
    "| Dataset | Accuracy | F1 Score | Latency |\n",
    "|---------|----------|----------|----------|\n",
    "| IMDB    | 94.2%    | 0.94     | 87ms    |\n",
    "| Yelp    | 91.8%    | 0.92     | 92ms    |\n",
    "\n",
    "## üèóÔ∏è Architecture\n",
    "\n",
    "1. **Input**: Text via REST API\n",
    "2. **Preprocessing**: Tokenization with BERT tokenizer\n",
    "3. **Model**: Fine-tuned DistilBERT\n",
    "4. **Output**: Sentiment + confidence score\n",
    "\n",
    "## üìÅ Project Structure\n",
    "\n",
    "```\n",
    "sentiment-api/\n",
    "‚îú‚îÄ‚îÄ app/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI application\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model.py         # Model loading/inference\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ schemas.py       # Request/response schemas\n",
    "‚îú‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ training.ipynb   # Model training notebook\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_api.py      # API tests\n",
    "‚îú‚îÄ‚îÄ models/              # Saved models\n",
    "‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îú‚îÄ‚îÄ docker-compose.yml\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```\n",
    "\n",
    "## üîß Development\n",
    "\n",
    "```bash\n",
    "# Run tests\n",
    "pytest\n",
    "\n",
    "# Check coverage\n",
    "pytest --cov=app\n",
    "\n",
    "# Format code\n",
    "black app/ tests/\n",
    "\n",
    "# Lint\n",
    "flake8 app/ tests/\n",
    "```\n",
    "\n",
    "## üöÄ Deployment\n",
    "\n",
    "Deploy to your favorite platform:\n",
    "- AWS (EC2, Lambda, SageMaker)\n",
    "- Google Cloud (Cloud Run)\n",
    "- Azure (Container Instances)\n",
    "- Heroku, Railway, Render\n",
    "\n",
    "## üìù API Documentation\n",
    "\n",
    "Visit `/docs` for interactive API documentation (Swagger UI)\n",
    "\n",
    "## üîÆ Future Enhancements\n",
    "\n",
    "- [ ] Multi-language support\n",
    "- [ ] Emotion detection (joy, anger, etc.)\n",
    "- [ ] Batch prediction endpoint\n",
    "- [ ] Model versioning\n",
    "- [ ] Caching layer (Redis)\n",
    "\n",
    "## üë§ Author\n",
    "\n",
    "**Your Name**\n",
    "- Portfolio: https://yourportfolio.com\n",
    "- LinkedIn: [linkedin.com/in/yourname](https://linkedin.com/in/yourname)\n",
    "- Email: your.email@example.com\n",
    "\n",
    "## üìÑ License\n",
    "\n",
    "MIT License - see [LICENSE](LICENSE) for details\n",
    "\"\"\"\n",
    "print(readme_content)\n",
    "\n",
    "# File 2: requirements.txt\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ FILE: requirements.txt\")\n",
    "print(\"=\"*70)\n",
    "requirements = \"\"\"\n",
    "# Core\n",
    "fastapi==0.100.0\n",
    "uvicorn[standard]==0.23.0\n",
    "pydantic==2.0.0\n",
    "\n",
    "# ML\n",
    "torch==2.0.1\n",
    "transformers==4.30.0\n",
    "scikit-learn==1.3.0\n",
    "\n",
    "# Utilities\n",
    "python-dotenv==1.0.0\n",
    "requests==2.31.0\n",
    "\n",
    "# Development\n",
    "pytest==7.4.0\n",
    "pytest-cov==4.1.0\n",
    "black==23.7.0\n",
    "flake8==6.0.0\n",
    "\"\"\"\n",
    "print(requirements)\n",
    "\n",
    "# File 3: Example API Code\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ FILE: app/main.py\")\n",
    "print(\"=\"*70)\n",
    "api_code = '''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import pipeline\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Sentiment Analysis API\",\n",
    "    description=\"Analyze sentiment of text using BERT\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Load model at startup\n",
    "@app.on_event(\"startup\")\n",
    "async def load_model():\n",
    "    global sentiment_analyzer\n",
    "    logger.info(\"Loading sentiment model...\")\n",
    "    sentiment_analyzer = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    logger.info(\"Model loaded successfully!\")\n",
    "\n",
    "# Request/Response models\n",
    "class TextInput(BaseModel):\n",
    "    text: str\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"text\": \"I absolutely love this product!\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class SentimentOutput(BaseModel):\n",
    "    text: str\n",
    "    sentiment: str\n",
    "    confidence: float\n",
    "\n",
    "# Endpoints\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Sentiment Analysis API\",\n",
    "        \"docs\": \"/docs\",\n",
    "        \"health\": \"/health\"\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/predict\", response_model=SentimentOutput)\n",
    "async def predict_sentiment(input_data: TextInput):\n",
    "    \"\"\"\n",
    "    Predict sentiment of input text\n",
    "    \n",
    "    Returns:\n",
    "    - sentiment: positive or negative\n",
    "    - confidence: probability (0-1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not input_data.text or len(input_data.text.strip()) == 0:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=\"Text cannot be empty\"\n",
    "            )\n",
    "        \n",
    "        # Run inference\n",
    "        result = sentiment_analyzer(input_data.text)[0]\n",
    "        \n",
    "        return SentimentOutput(\n",
    "            text=input_data.text,\n",
    "            sentiment=result[\"label\"].lower(),\n",
    "            confidence=round(result[\"score\"], 4)\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction error: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=\"Internal server error\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "print(api_code)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n‚úÖ This is a COMPLETE, production-ready template!\")\n",
    "print(\"\\nüéØ To use this template:\")\n",
    "print(\"   1. Copy the structure to your project\")\n",
    "print(\"   2. Customize for your specific use case\")\n",
    "print(\"   3. Replace sentiment model with YOUR model\")\n",
    "print(\"   4. Update README with your details\")\n",
    "print(\"   5. Deploy and add to portfolio!\")\n",
    "print(\"\\nüí° This template demonstrates:\")\n",
    "print(\"   ‚úì Clean code organization\")\n",
    "print(\"   ‚úì Professional documentation\")\n",
    "print(\"   ‚úì REST API with FastAPI\")\n",
    "print(\"   ‚úì Error handling\")\n",
    "print(\"   ‚úì Production-ready structure\")\n",
    "print(\"   ‚úì Easy deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercises\n",
    "\n",
    "**Plan YOUR capstone project!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "### Exercise 1: Project Proposal\n",
    "\n",
    "**Task:** Create a detailed project proposal for your capstone\n",
    "\n",
    "**Complete the following template:**\n",
    "\n",
    "```markdown\n",
    "# Project Proposal: [Your Project Name]\n",
    "\n",
    "## 1. Problem Statement\n",
    "What problem are you solving? Why does it matter?\n",
    "\n",
    "## 2. Solution Approach\n",
    "How will you solve it? What techniques will you use?\n",
    "\n",
    "## 3. Data Sources\n",
    "Where will you get data? How much? What format?\n",
    "\n",
    "## 4. Technical Stack\n",
    "- Programming Language:\n",
    "- ML Framework:\n",
    "- Deployment:\n",
    "- Tools:\n",
    "\n",
    "## 5. MVP Features\n",
    "List 3 core features for your MVP:\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\n",
    "## 6. Success Metrics\n",
    "How will you measure success?\n",
    "- Technical metrics:\n",
    "- Portfolio metrics:\n",
    "\n",
    "## 7. Timeline\n",
    "- Week 1:\n",
    "- Week 2:\n",
    "- Week 3:\n",
    "\n",
    "## 8. Potential Challenges\n",
    "What obstacles might you face? How will you overcome them?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PROJECT PROPOSAL HERE\n",
    "\n",
    "# Fill in your project details\n",
    "my_project = {\n",
    "    'name': '',\n",
    "    'problem': '',\n",
    "    'solution': '',\n",
    "    'data_source': '',\n",
    "    'tech_stack': [],\n",
    "    'mvp_features': [],\n",
    "    'timeline': {\n",
    "        'week_1': '',\n",
    "        'week_2': '',\n",
    "        'week_3': ''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print your proposal\n",
    "print(\"üìã MY PROJECT PROPOSAL\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nProject: {my_project['name']}\")\n",
    "print(f\"Problem: {my_project['problem']}\")\n",
    "# ... continue printing your proposal\n",
    "\n",
    "print(\"\\nTODO: Complete your project proposal above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### Exercise 2: GitHub Repository Setup\n",
    "\n",
    "**Task:** Set up a GitHub repository for your project\n",
    "\n",
    "**Steps:**\n",
    "1. Create a new GitHub repository\n",
    "2. Clone it locally\n",
    "3. Create the proper directory structure\n",
    "4. Write a README (use the template)\n",
    "5. Add .gitignore\n",
    "6. Make your first commit\n",
    "7. Push to GitHub\n",
    "\n",
    "**Checklist:**\n",
    "- [ ] Repository created on GitHub\n",
    "- [ ] Proper folder structure\n",
    "- [ ] README.md with template\n",
    "- [ ] .gitignore configured\n",
    "- [ ] requirements.txt created\n",
    "- [ ] First commit made\n",
    "- [ ] Pushed to GitHub\n",
    "- [ ] Repository is public\n",
    "- [ ] Added description and topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "## üéâ Key Takeaways\n",
    "\n",
    "**Congratulations! You've learned how to plan a professional AI project!**\n",
    "\n",
    "### 1Ô∏è‚É£ **Project Selection**\n",
    "   - ‚úÖ Choose projects at the intersection of interest, skills, and demand\n",
    "   - ‚úÖ Use the IMPACT framework to evaluate ideas\n",
    "   - ‚úÖ Validate feasibility before starting\n",
    "   - **Remember:** One great project > ten mediocre ones\n",
    "\n",
    "### 2Ô∏è‚É£ **Project Planning**\n",
    "   - ‚úÖ Define clear MVP with core features\n",
    "   - ‚úÖ Break into phases (data, modeling, deployment)\n",
    "   - ‚úÖ Set realistic timelines\n",
    "   - ‚úÖ Avoid scope creep and perfect model syndrome\n",
    "   - **Remember:** 70% function, 20% polish, 10% docs\n",
    "\n",
    "### 3Ô∏è‚É£ **Data Strategy**\n",
    "   - ‚úÖ Start with public datasets (Kaggle, HuggingFace)\n",
    "   - ‚úÖ Use APIs for real-time data\n",
    "   - ‚úÖ Web scraping as last resort (ethically!)\n",
    "   - ‚úÖ Validate data quality before modeling\n",
    "   - **Remember:** Your model is only as good as your data\n",
    "\n",
    "### 4Ô∏è‚É£ **GitHub Portfolio**\n",
    "   - ‚úÖ Treat GitHub as your professional resume\n",
    "   - ‚úÖ Use proper project structure\n",
    "   - ‚úÖ Write comprehensive READMEs\n",
    "   - ‚úÖ Commit regularly with meaningful messages\n",
    "   - ‚úÖ Pin best projects, add topics/badges\n",
    "   - **Remember:** Recruiters spend 6 seconds - make it count!\n",
    "\n",
    "### 5Ô∏è‚É£ **Professional Presentation**\n",
    "   - ‚úÖ Include demo GIFs/screenshots\n",
    "   - ‚úÖ Show results and metrics\n",
    "   - ‚úÖ Document setup instructions\n",
    "   - ‚úÖ Add future improvements section\n",
    "   - **Remember:** Presentation matters as much as code\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Action Items for Tomorrow (Day 2)\n",
    "\n",
    "**Before Day 2, complete these tasks:**\n",
    "\n",
    "1. **Finalize Project Idea**\n",
    "   - Choose your capstone project\n",
    "   - Complete project scorecard (>70% score)\n",
    "   - Write project proposal\n",
    "\n",
    "2. **Set Up Infrastructure**\n",
    "   - Create GitHub repository\n",
    "   - Set up project structure\n",
    "   - Write initial README\n",
    "   - Configure .gitignore\n",
    "\n",
    "3. **Gather Data**\n",
    "   - Identify data sources\n",
    "   - Download/access sample data\n",
    "   - Verify data quality\n",
    "   - Plan data pipeline\n",
    "\n",
    "4. **Create Timeline**\n",
    "   - Define weekly milestones\n",
    "   - Set specific deadlines\n",
    "   - Buffer for unexpected issues\n",
    "\n",
    "**Tomorrow (Day 2), we'll:**\n",
    "- Build the end-to-end ML pipeline\n",
    "- Implement our multi-model project\n",
    "- Follow code organization best practices\n",
    "- Create professional documentation\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "**Project Inspiration:**\n",
    "- Kaggle Competitions: https://kaggle.com/competitions\n",
    "- Papers with Code: https://paperswithcode.com\n",
    "- Awesome ML Projects: https://github.com/ml-tooling/best-of-ml-python\n",
    "\n",
    "**GitHub Best Practices:**\n",
    "- GitHub Guides: https://guides.github.com\n",
    "- Readme Template: https://github.com/othneildrew/Best-README-Template\n",
    "- Badges: https://shields.io\n",
    "\n",
    "**Data Sources:**\n",
    "- Kaggle Datasets: https://kaggle.com/datasets\n",
    "- HuggingFace: https://huggingface.co/datasets\n",
    "- Google Dataset Search: https://datasetsearch.research.google.com\n",
    "- Awesome Public Datasets: https://github.com/awesomedata/awesome-public-datasets\n",
    "\n",
    "**Project Management:**\n",
    "- Notion Templates: https://notion.so/templates\n",
    "- Trello: https://trello.com\n",
    "- GitHub Projects: Built into GitHub\n",
    "\n",
    "---\n",
    "\n",
    "**üí¨ Final Thought:**\n",
    "\n",
    "*\"The best time to start your capstone project was yesterday. The second best time is now. Don't wait for the perfect idea - start with a good one and make it great through iteration. Your portfolio is your career - invest in it!\"*\n",
    "\n",
    "**üöÄ Ready to build? Let's go! Tomorrow we start coding your capstone project!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
