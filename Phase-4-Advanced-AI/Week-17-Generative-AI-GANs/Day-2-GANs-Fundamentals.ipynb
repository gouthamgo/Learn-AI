{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìò Day 2: GANs Fundamentals\n",
    "\n",
    "**üéØ Goal:** Master Generative Adversarial Networks (GANs) - the revolutionary approach to AI generation\n",
    "\n",
    "**‚è±Ô∏è Time:** 90-120 minutes\n",
    "\n",
    "**üåü Why This Matters for AI:**\n",
    "- GANs revolutionized generative AI in 2014 (Ian Goodfellow)\n",
    "- Behind realistic face generation (StyleGAN, This Person Does Not Exist)\n",
    "- Powers DeepFakes, image-to-image translation, super-resolution\n",
    "- Foundation for many modern generative models\n",
    "- Used in art, gaming, fashion, medical imaging, and more\n",
    "- Critical for understanding modern AI creativity (2024-2025)\n",
    "- Yann LeCun called GANs \"the most interesting idea in ML in the last 10 years\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gans-intro",
   "metadata": {},
   "source": [
    "## ü§ñ What are GANs?\n",
    "\n",
    "**GAN = Two Neural Networks Playing a Game**\n",
    "\n",
    "### The Concept:\n",
    "\n",
    "**Real-World Analogy: Art Forger vs Art Critic**\n",
    "\n",
    "Imagine two people:\n",
    "1. **Forger (Generator):** Tries to create fake paintings that look real\n",
    "2. **Detective (Discriminator):** Tries to tell real paintings from fakes\n",
    "\n",
    "**The Competition:**\n",
    "- Forger gets better at creating realistic fakes\n",
    "- Detective gets better at spotting fakes\n",
    "- They push each other to improve!\n",
    "- Eventually: Forger creates indistinguishable fakes\n",
    "\n",
    "### In AI:\n",
    "\n",
    "```\n",
    "         Random Noise\n",
    "              ‚Üì\n",
    "        GENERATOR (G)\n",
    "       \"The Forger\"\n",
    "              ‚Üì\n",
    "         Fake Image\n",
    "              ‚Üì\n",
    "      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "      ‚îÇ              ‚îÇ\n",
    "  Real Images   Fake Images\n",
    "      ‚îÇ              ‚îÇ\n",
    "      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚Üì\n",
    "     DISCRIMINATOR (D)\n",
    "      \"The Detective\"\n",
    "             ‚Üì\n",
    "    \"Real or Fake?\"\n",
    "    (Probability)\n",
    "```\n",
    "\n",
    "### The Two Networks:\n",
    "\n",
    "**Generator (G):**\n",
    "- **Input:** Random noise (e.g., 100 random numbers)\n",
    "- **Goal:** Create realistic fake images\n",
    "- **Training:** Fool the discriminator\n",
    "- **Success:** When discriminator can't tell real from fake\n",
    "\n",
    "**Discriminator (D):**\n",
    "- **Input:** Real images OR fake images from G\n",
    "- **Goal:** Classify real vs fake\n",
    "- **Training:** Correctly identify fakes\n",
    "- **Success:** High accuracy on real/fake classification\n",
    "\n",
    "### üéØ The Adversarial Game:\n",
    "\n",
    "**Minimax Game Theory:**\n",
    "```\n",
    "Generator: Minimize log(1 - D(G(z)))  ‚Üê Make fakes look real\n",
    "Discriminator: Maximize log(D(x)) + log(1 - D(G(z)))  ‚Üê Classify correctly\n",
    "```\n",
    "\n",
    "**In Simple Terms:**\n",
    "- **D wants:** P(real|real image) = 1, P(real|fake image) = 0\n",
    "- **G wants:** P(real|fake image) = 1 (fool the discriminator!)\n",
    "- **Result:** Arms race ‚Üí increasingly realistic generations\n",
    "\n",
    "### üåü Real-World Examples (2024-2025):\n",
    "\n",
    "**GAN Applications:**\n",
    "- üé® **This Person Does Not Exist:** StyleGAN generates fake faces\n",
    "- üéÆ **Gaming:** Generate realistic textures, characters\n",
    "- üëó **Fashion:** Create new clothing designs (Stitch Fix)\n",
    "- üè• **Medical:** Augment training data (rare diseases)\n",
    "- üé¨ **DeepFakes:** Face swapping (ethical concerns!)\n",
    "- üì∏ **Super-Resolution:** Enhance image quality (NVIDIA DLSS)\n",
    "- üé® **Art:** AI-generated artwork (Artbreeder)\n",
    "\n",
    "### Why GANs > VAEs (for some tasks):\n",
    "\n",
    "| Aspect | VAE | GAN |\n",
    "|--------|-----|-----|\n",
    "| **Image Quality** | Good | Excellent (sharper) |\n",
    "| **Training** | Stable | Unstable (challenging) |\n",
    "| **Generation** | Smooth | Diverse |\n",
    "| **Mode Collapse** | No | Yes (problem) |\n",
    "| **Best For** | Reconstruction | Generation |\n",
    "\n",
    "Let's build a GAN from scratch! üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from IPython.display import Image, display, clear_output\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Make plots beautiful\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"Let's create realistic images with GANs! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generator-architecture",
   "metadata": {},
   "source": [
    "## üé® The Generator Network\n",
    "\n",
    "**Generator = Noise ‚Üí Image**\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "**Input:** Random noise vector (latent vector)\n",
    "- Example: 100 random numbers from N(0,1)\n",
    "- Think of it as \"DNA\" for the image\n",
    "\n",
    "**Process:**\n",
    "```\n",
    "Random Noise (100 numbers)\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 128 neurons\n",
    "    ‚Üì\n",
    "LeakyReLU Activation\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 256 neurons\n",
    "    ‚Üì\n",
    "LeakyReLU + BatchNorm\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 512 neurons\n",
    "    ‚Üì\n",
    "LeakyReLU + BatchNorm\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 784 (28√ó28)\n",
    "    ‚Üì\n",
    "Tanh (output in [-1, 1])\n",
    "    ‚Üì\n",
    "Generated Image\n",
    "```\n",
    "\n",
    "### Key Design Choices:\n",
    "\n",
    "**1. LeakyReLU (not ReLU):**\n",
    "- Allows small negative gradients\n",
    "- Prevents \"dead neurons\"\n",
    "- Better gradient flow in GANs\n",
    "\n",
    "**2. BatchNorm:**\n",
    "- Stabilizes training\n",
    "- Normalizes layer outputs\n",
    "- Critical for GAN convergence\n",
    "\n",
    "**3. Tanh Output:**\n",
    "- Output range: [-1, 1]\n",
    "- Matches normalized image range\n",
    "- Better than Sigmoid for images\n",
    "\n",
    "### üéØ What Generator Learns:\n",
    "\n",
    "**Training Process:**\n",
    "- Random noise ‚Üí blurry blob (early)\n",
    "- Random noise ‚Üí digit-like shape (middle)\n",
    "- Random noise ‚Üí realistic digit (late)\n",
    "\n",
    "**Latent Space Semantics:**\n",
    "- Different noise vectors ‚Üí different digits\n",
    "- Similar vectors ‚Üí similar images\n",
    "- Can interpolate smoothly!\n",
    "\n",
    "Let's implement the Generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generator-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, output_dim=784):\n",
    "        \"\"\"\n",
    "        Generator: Noise ‚Üí Image\n",
    "        \n",
    "        Args:\n",
    "            latent_dim: Dimension of random noise input\n",
    "            output_dim: Output size (28*28 = 784 for MNIST)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: 100 ‚Üí 128\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 2: 128 ‚Üí 256\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 3: 256 ‚Üí 512\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Layer 4: 512 ‚Üí 784\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Generate image from noise\n",
    "        \n",
    "        Args:\n",
    "            z: Random noise (batch_size, latent_dim)\n",
    "        \n",
    "        Returns:\n",
    "            Generated image (batch_size, 784)\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "# Create Generator\n",
    "latent_dim = 100\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "\n",
    "print(\"‚úÖ Generator Network Created!\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(generator)\n",
    "\n",
    "# Test generator\n",
    "test_noise = torch.randn(1, latent_dim).to(device)\n",
    "test_output = generator(test_noise)\n",
    "\n",
    "print(f\"\\nüß™ Generator Test:\")\n",
    "print(f\"  Input (noise): {test_noise.shape}\")\n",
    "print(f\"  Output (image): {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min():.2f}, {test_output.max():.2f}]\")\n",
    "print(f\"\\nüí° Random noise ‚Üí 784 numbers (28√ó28 image)!\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in generator.parameters())\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discriminator-architecture",
   "metadata": {},
   "source": [
    "## üîç The Discriminator Network\n",
    "\n",
    "**Discriminator = Binary Classifier (Real vs Fake)**\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "**Input:** Image (28√ó28 = 784 pixels)\n",
    "- Can be real (from dataset)\n",
    "- Can be fake (from generator)\n",
    "\n",
    "**Process:**\n",
    "```\n",
    "Image (784 pixels)\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 512 neurons\n",
    "    ‚Üì\n",
    "LeakyReLU + Dropout (0.3)\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 256 neurons\n",
    "    ‚Üì\n",
    "LeakyReLU + Dropout (0.3)\n",
    "    ‚Üì\n",
    "Linear Layer ‚Üí 1 neuron\n",
    "    ‚Üì\n",
    "Sigmoid ‚Üí Probability\n",
    "    ‚Üì\n",
    "Output: P(Real)\n",
    "```\n",
    "\n",
    "### Key Design Choices:\n",
    "\n",
    "**1. Dropout:**\n",
    "- Prevents overfitting\n",
    "- Discriminator shouldn't memorize!\n",
    "- Forces robust features\n",
    "\n",
    "**2. LeakyReLU:**\n",
    "- Better gradient flow than ReLU\n",
    "- Standard in GAN discriminators\n",
    "\n",
    "**3. No BatchNorm:**\n",
    "- Discriminator often works better without it\n",
    "- Avoids batch dependencies\n",
    "\n",
    "**4. Sigmoid Output:**\n",
    "- Binary classification\n",
    "- P(Real) = 1 ‚Üí real image\n",
    "- P(Real) = 0 ‚Üí fake image\n",
    "\n",
    "### üéØ What Discriminator Learns:\n",
    "\n",
    "**Early Training:**\n",
    "- Easily spots fakes (generator is bad)\n",
    "- 100% accuracy\n",
    "\n",
    "**Mid Training:**\n",
    "- Generator improves\n",
    "- Discriminator learns subtle features\n",
    "- ~70-80% accuracy\n",
    "\n",
    "**Late Training:**\n",
    "- Generator creates realistic images\n",
    "- Discriminator struggles (~50% accuracy)\n",
    "- Success! (Can't tell real from fake)\n",
    "\n",
    "### The Balance:\n",
    "\n",
    "**Too Strong Discriminator:**\n",
    "- Generator can't learn (gradients vanish)\n",
    "- No improvement\n",
    "\n",
    "**Too Weak Discriminator:**\n",
    "- Generator doesn't get useful feedback\n",
    "- Poor quality generations\n",
    "\n",
    "**Goal:** Keep them balanced! ‚öñÔ∏è\n",
    "\n",
    "Let's implement the Discriminator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discriminator-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=784):\n",
    "        \"\"\"\n",
    "        Discriminator: Image ‚Üí Real/Fake\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Input size (28*28 = 784 for MNIST)\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: 784 ‚Üí 512\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 2: 512 ‚Üí 256\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 3: 256 ‚Üí 1\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Classify image as real or fake\n",
    "        \n",
    "        Args:\n",
    "            x: Image (batch_size, 784)\n",
    "        \n",
    "        Returns:\n",
    "            Probability of being real (batch_size, 1)\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "# Create Discriminator\n",
    "discriminator = Discriminator(input_dim=784).to(device)\n",
    "\n",
    "print(\"‚úÖ Discriminator Network Created!\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(discriminator)\n",
    "\n",
    "# Test discriminator\n",
    "test_image = torch.randn(1, 784).to(device)\n",
    "test_prediction = discriminator(test_image)\n",
    "\n",
    "print(f\"\\nüß™ Discriminator Test:\")\n",
    "print(f\"  Input (image): {test_image.shape}\")\n",
    "print(f\"  Output (probability): {test_prediction.shape}\")\n",
    "print(f\"  Prediction: {test_prediction.item():.4f}\")\n",
    "print(f\"  Interpretation: {test_prediction.item():.1%} chance of being real\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\nüí° The discriminator is a binary classifier!\")\n",
    "print(\"   Output close to 1 ‚Üí Real image\")\n",
    "print(\"   Output close to 0 ‚Üí Fake image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Dataset\n",
    "\n",
    "# Transform: Normalize to [-1, 1] to match Generator output\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Scale to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(\"‚úÖ MNIST Dataset Loaded!\")\n",
    "print(f\"\\nTraining samples: {len(train_dataset):,}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "fig.suptitle('üìä Real MNIST Digits (Training Data)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(16):\n",
    "    ax = axes[i // 8, i % 8]\n",
    "    img, label = train_dataset[i]\n",
    "    # Denormalize for visualization\n",
    "    img = img * 0.5 + 0.5\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {label}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Goal: Generate digits that look like these!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-gans",
   "metadata": {},
   "source": [
    "## üéÆ Training GANs: The Adversarial Game\n",
    "\n",
    "**Training Process = Alternating Optimization**\n",
    "\n",
    "### Training Loop:\n",
    "\n",
    "**For each batch:**\n",
    "\n",
    "**Step 1: Train Discriminator**\n",
    "```python\n",
    "# 1a. Train on REAL images\n",
    "real_images ‚Üí Discriminator ‚Üí Should output ~1\n",
    "loss_real = -log(D(real))\n",
    "\n",
    "# 1b. Train on FAKE images\n",
    "noise ‚Üí Generator ‚Üí fake_images\n",
    "fake_images ‚Üí Discriminator ‚Üí Should output ~0\n",
    "loss_fake = -log(1 - D(G(noise)))\n",
    "\n",
    "# Total discriminator loss\n",
    "loss_D = loss_real + loss_fake\n",
    "```\n",
    "\n",
    "**Step 2: Train Generator**\n",
    "```python\n",
    "# Generate fakes\n",
    "noise ‚Üí Generator ‚Üí fake_images\n",
    "\n",
    "# Try to fool discriminator\n",
    "fake_images ‚Üí Discriminator ‚Üí Want output ~1!\n",
    "loss_G = -log(D(G(noise)))\n",
    "```\n",
    "\n",
    "### Key Training Insights:\n",
    "\n",
    "**1. Discriminator Trains Twice:**\n",
    "- Once on real images (label=1)\n",
    "- Once on fake images (label=0)\n",
    "- Learns to distinguish real from fake\n",
    "\n",
    "**2. Generator Goal:**\n",
    "- Make D(fake) = 1 (fool the discriminator!)\n",
    "- Pushes generated images toward realism\n",
    "\n",
    "**3. No Direct Comparison:**\n",
    "- Generator never sees real images!\n",
    "- Only gets feedback from discriminator\n",
    "- This is why training is tricky\n",
    "\n",
    "### Loss Functions:\n",
    "\n",
    "**Binary Cross Entropy (BCE):**\n",
    "```\n",
    "BCE(y, ≈∑) = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]\n",
    "\n",
    "For Discriminator:\n",
    "  Real: y=1, minimize -log(D(real))\n",
    "  Fake: y=0, minimize -log(1 - D(fake))\n",
    "\n",
    "For Generator:\n",
    "  Want D(fake) ‚âà 1, minimize -log(D(G(z)))\n",
    "```\n",
    "\n",
    "### üéØ Training Dynamics:\n",
    "\n",
    "**Ideal Scenario:**\n",
    "```\n",
    "Epoch 1:  D_loss ‚Üì, G_loss ‚Üë (D learning fast)\n",
    "Epoch 5:  D_loss ‚Üî, G_loss ‚Üì (G catching up)\n",
    "Epoch 10: D_loss ‚Üî, G_loss ‚Üî (Balanced!)\n",
    "Epoch 20: Both converge (Nash equilibrium)\n",
    "```\n",
    "\n",
    "**What We Want:**\n",
    "- D accuracy ‚Üí ~50% (can't tell real from fake)\n",
    "- G generates realistic images\n",
    "- Losses stabilize (not oscillate wildly)\n",
    "\n",
    "### üåü Why This Works:\n",
    "\n",
    "**Game Theory:**\n",
    "- Two-player minimax game\n",
    "- Nash equilibrium: Neither can improve\n",
    "- At equilibrium: G generates perfect fakes\n",
    "\n",
    "**In Practice:**\n",
    "- Rarely reach perfect equilibrium\n",
    "- But get very realistic results!\n",
    "- This is what powers StyleGAN, etc.\n",
    "\n",
    "Let's implement GAN training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-gan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAN\n",
    "\n",
    "def train_gan(generator, discriminator, train_loader, epochs=20):\n",
    "    \"\"\"\n",
    "    Train GAN with alternating optimization\n",
    "    \"\"\"\n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Optimizers (separate for G and D)\n",
    "    lr = 0.0002\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Labels\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "    \n",
    "    # Training history\n",
    "    history = {'G_loss': [], 'D_loss': [], 'D_real': [], 'D_fake': []}\n",
    "    \n",
    "    # Fixed noise for visualization\n",
    "    fixed_noise = torch.randn(64, latent_dim).to(device)\n",
    "    \n",
    "    print(\"üöÄ Training GAN...\\n\")\n",
    "    print(\"The Generator and Discriminator will compete!\")\n",
    "    print(\"Goal: Generator creates realistic digits that fool Discriminator\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_G_loss = 0\n",
    "        epoch_D_loss = 0\n",
    "        epoch_D_real = 0\n",
    "        epoch_D_fake = 0\n",
    "        \n",
    "        for batch_idx, (real_images, _) in enumerate(train_loader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(-1, 784).to(device)\n",
    "            \n",
    "            # ===========================\n",
    "            # Train Discriminator\n",
    "            # ===========================\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Train on REAL images\n",
    "            labels_real = torch.full((batch_size, 1), real_label, device=device)\n",
    "            output_real = discriminator(real_images)\n",
    "            loss_D_real = criterion(output_real, labels_real)\n",
    "            \n",
    "            # Train on FAKE images\n",
    "            noise = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            labels_fake = torch.full((batch_size, 1), fake_label, device=device)\n",
    "            output_fake = discriminator(fake_images.detach())  # Detach to avoid training G\n",
    "            loss_D_fake = criterion(output_fake, labels_fake)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            loss_D = loss_D_real + loss_D_fake\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ===========================\n",
    "            # Train Generator\n",
    "            # ===========================\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fakes and try to fool discriminator\n",
    "            labels_real = torch.full((batch_size, 1), real_label, device=device)  # Want D(fake) = 1!\n",
    "            output = discriminator(fake_images)  # Don't detach - we want gradients!\n",
    "            loss_G = criterion(output, labels_real)\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            epoch_G_loss += loss_G.item()\n",
    "            epoch_D_loss += loss_D.item()\n",
    "            epoch_D_real += output_real.mean().item()\n",
    "            epoch_D_fake += output_fake.mean().item()\n",
    "        \n",
    "        # Average losses\n",
    "        avg_G_loss = epoch_G_loss / len(train_loader)\n",
    "        avg_D_loss = epoch_D_loss / len(train_loader)\n",
    "        avg_D_real = epoch_D_real / len(train_loader)\n",
    "        avg_D_fake = epoch_D_fake / len(train_loader)\n",
    "        \n",
    "        history['G_loss'].append(avg_G_loss)\n",
    "        history['D_loss'].append(avg_D_loss)\n",
    "        history['D_real'].append(avg_D_real)\n",
    "        history['D_fake'].append(avg_D_fake)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"  G_loss: {avg_G_loss:.4f} | D_loss: {avg_D_loss:.4f}\")\n",
    "        print(f\"  D(real): {avg_D_real:.4f} | D(fake): {avg_D_fake:.4f}\")\n",
    "        print(f\"  {'='*66}\")\n",
    "        \n",
    "        # Visualize generated images every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_samples = generator(fixed_noise).cpu()\n",
    "                fake_samples = fake_samples.view(-1, 1, 28, 28)\n",
    "                # Denormalize\n",
    "                fake_samples = fake_samples * 0.5 + 0.5\n",
    "                \n",
    "                fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "                fig.suptitle(f'üé® Generated Digits - Epoch {epoch+1}', \n",
    "                           fontsize=16, fontweight='bold')\n",
    "                \n",
    "                for i in range(32):\n",
    "                    ax = axes[i // 8, i % 8]\n",
    "                    ax.imshow(fake_samples[i].squeeze(), cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the GAN!\n",
    "history = train_gan(generator, discriminator, train_loader, epochs=20)\n",
    "\n",
    "print(\"\\n‚úÖ GAN Training Complete!\")\n",
    "print(\"\\nüí° Watch how the generated digits improved over epochs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Dynamics\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Losses\n",
    "axes[0].plot(history['G_loss'], label='Generator Loss', linewidth=2, marker='o')\n",
    "axes[0].plot(history['D_loss'], label='Discriminator Loss', linewidth=2, marker='s')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('üìâ Generator vs Discriminator Loss', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Discriminator Outputs\n",
    "axes[1].plot(history['D_real'], label='D(real)', linewidth=2, marker='o', color='green')\n",
    "axes[1].plot(history['D_fake'], label='D(fake)', linewidth=2, marker='s', color='red')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', label='Target (0.5)')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Discriminator Output', fontsize=12)\n",
    "axes[1].set_title('üìä Discriminator Performance', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Accuracy Metric\n",
    "accuracy = [(r + (1-f))/2 for r, f in zip(history['D_real'], history['D_fake'])]\n",
    "axes[2].plot(accuracy, linewidth=2, marker='o', color='purple')\n",
    "axes[2].axhline(y=0.5, color='gray', linestyle='--', label='Perfect GAN (50%)')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Discriminator Accuracy', fontsize=12)\n",
    "axes[2].set_title('üéØ Discriminator Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Training Analysis:\")\n",
    "print(\"\\n1. Loss Curves:\")\n",
    "print(\"   - G and D losses should be relatively balanced\")\n",
    "print(\"   - If D_loss ‚Üí 0: Discriminator too strong (mode collapse risk)\")\n",
    "print(\"   - If G_loss ‚Üí 0: Generator fooling discriminator perfectly!\")\n",
    "\n",
    "print(\"\\n2. Discriminator Outputs:\")\n",
    "print(\"   - D(real) should stay near 1 (correctly identifies real)\")\n",
    "print(\"   - D(fake) should rise toward 0.5 (fakes getting better!)\")\n",
    "print(\"   - When both near 0.5: GAN converged (can't tell real from fake)\")\n",
    "\n",
    "print(\"\\n3. Accuracy:\")\n",
    "print(f\"   - Final accuracy: {accuracy[-1]:.1%}\")\n",
    "print(\"   - Target: ~50% (discriminator can't distinguish)\")\n",
    "print(f\"   - Status: {'‚úÖ Well trained!' if 0.4 <= accuracy[-1] <= 0.6 else '‚ö†Ô∏è May need more training'}\")\n",
    "\n",
    "print(\"\\nüí° These dynamics show the 'adversarial game' in action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-ai-example",
   "metadata": {},
   "source": [
    "## üåü Real AI Example: MNIST Digit Generation\n",
    "\n",
    "**Task:** Generate new handwritten digits that don't exist in the dataset\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "**Data Augmentation (2024-2025):**\n",
    "- üè• **Medical Imaging:** Generate synthetic patient data (privacy-preserving!)\n",
    "- üöó **Autonomous Driving:** Create rare scenarios (accidents, bad weather)\n",
    "- üî¨ **Drug Discovery:** Generate molecular structures\n",
    "- üìä **Finance:** Synthetic transactions for fraud detection training\n",
    "\n",
    "**Creative Applications:**\n",
    "- üéÆ **Gaming:** Generate unique textures, characters, levels\n",
    "- üé® **Art:** AI-generated artwork (Artbreeder, NightCafe)\n",
    "- üëó **Fashion:** Design new clothing patterns (Stitch Fix)\n",
    "- üè† **Architecture:** Generate building designs\n",
    "\n",
    "**Industry Use Cases:**\n",
    "- **NVIDIA:** GauGAN (landscape generation for designers)\n",
    "- **Adobe:** Photoshop neural filters\n",
    "- **Disney:** Facial animation, deepfakes for movies\n",
    "- **Google:** BigGAN for high-resolution images\n",
    "\n",
    "Let's generate new digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-digits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate New Digits\n",
    "\n",
    "def generate_new_digits(generator, n_samples=64):\n",
    "    \"\"\"\n",
    "    Generate completely new digits from random noise\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sample random noise\n",
    "        noise = torch.randn(n_samples, latent_dim).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        generated = generator(noise).cpu()\n",
    "        generated = generated.view(-1, 1, 28, 28)\n",
    "        # Denormalize\n",
    "        generated = generated * 0.5 + 0.5\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(16, 16))\n",
    "    fig.suptitle('‚ú® GAN-Generated Handwritten Digits (Never Seen Before!)', \n",
    "                 fontsize=18, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        ax = axes[i // 8, i % 8]\n",
    "        ax.imshow(generated[i].squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüé® What Just Happened?\")\n",
    "    print(\"  1. Sampled 64 random noise vectors\")\n",
    "    print(\"  2. Generator transformed noise ‚Üí realistic digits\")\n",
    "    print(\"  3. These digits DON'T exist in the training data!\")\n",
    "    print(\"  4. Generator CREATED new data from scratch\")\n",
    "    \n",
    "    print(\"\\nüí° This is Generative AI in Action!\")\n",
    "    print(\"  - Same principle as DALL-E creating images from text\")\n",
    "    print(\"  - Or StyleGAN creating photorealistic faces\")\n",
    "    print(\"  - Or Sora generating videos\")\n",
    "\n",
    "generate_new_digits(generator, n_samples=64)\n",
    "\n",
    "print(\"\\nüåü From MNIST to Modern AI:\")\n",
    "print(\"\\nüìä Evolution of GANs (2014-2025):\")\n",
    "print(\"  2014: Original GAN paper (Goodfellow et al.)\")\n",
    "print(\"  2016: DCGAN (deep convolutional GAN)\")\n",
    "print(\"  2018: StyleGAN (photorealistic faces)\")\n",
    "print(\"  2019: StyleGAN2 (even better quality)\")\n",
    "print(\"  2020: StyleGAN3 (alias-free generation)\")\n",
    "print(\"  2024: GANs + Diffusion models dominate generative AI\")\n",
    "\n",
    "print(\"\\nüéØ Real Applications Today:\")\n",
    "print(\"  - This Person Does Not Exist: StyleGAN-generated faces\")\n",
    "print(\"  - NVIDIA GauGAN: Sketch ‚Üí photorealistic landscape\")\n",
    "print(\"  - Artbreeder: Blend and evolve images\")\n",
    "print(\"  - DeepFaceLab: High-quality face swapping\")\n",
    "print(\"  - Medical imaging: Generate rare disease examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latent-space-interpolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Interpolation\n",
    "\n",
    "def interpolate_digits(generator, n_steps=10):\n",
    "    \"\"\"\n",
    "    Smoothly interpolate between two random digits\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sample two random noise vectors\n",
    "        z1 = torch.randn(1, latent_dim).to(device)\n",
    "        z2 = torch.randn(1, latent_dim).to(device)\n",
    "        \n",
    "        # Interpolate\n",
    "        interpolations = []\n",
    "        for alpha in np.linspace(0, 1, n_steps):\n",
    "            z = alpha * z2 + (1 - alpha) * z1\n",
    "            generated = generator(z).cpu()\n",
    "            generated = generated.view(1, 28, 28)\n",
    "            # Denormalize\n",
    "            generated = generated * 0.5 + 0.5\n",
    "            interpolations.append(generated)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, n_steps, figsize=(20, 2))\n",
    "    fig.suptitle('üåà Latent Space Interpolation: Morphing One Digit into Another', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        axes[i].imshow(interpolations[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Step {i+1}', fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüé® Latent Space Magic:\")\n",
    "    print(\"  - Started with random noise vector A\")\n",
    "    print(\"  - Smoothly transitioned to random noise vector B\")\n",
    "    print(\"  - Each intermediate step is a valid digit!\")\n",
    "    print(\"  - Shows that latent space is CONTINUOUS and MEANINGFUL\")\n",
    "    \n",
    "    print(\"\\nüåü Real-World Applications:\")\n",
    "    print(\"  - Face morphing: Smoothly age a person\")\n",
    "    print(\"  - Style transfer: Gradually change artistic style\")\n",
    "    print(\"  - Video generation: Create smooth transitions\")\n",
    "    print(\"  - Drug discovery: Explore molecular variations\")\n",
    "\n",
    "# Run interpolation multiple times\n",
    "for _ in range(3):\n",
    "    interpolate_digits(generator, n_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gan-challenges",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è GAN Training Challenges\n",
    "\n",
    "**GANs are HARD to train! Here's why:**\n",
    "\n",
    "### 1. Mode Collapse üîÑ\n",
    "\n",
    "**Problem:**\n",
    "- Generator produces limited variety\n",
    "- Example: Only generates \"3\"s and \"7\"s, ignores other digits\n",
    "- Happens when G finds \"easy\" way to fool D\n",
    "\n",
    "**Why it happens:**\n",
    "- G discovers that certain outputs always fool D\n",
    "- Stops exploring other possibilities\n",
    "- Collapses to generating same few samples\n",
    "\n",
    "**Solutions:**\n",
    "- Minibatch discrimination\n",
    "- Feature matching\n",
    "- Use Wasserstein GAN (WGAN)\n",
    "- Unrolled GAN\n",
    "\n",
    "### 2. Vanishing Gradients üìâ\n",
    "\n",
    "**Problem:**\n",
    "- D becomes too good ‚Üí gradients to G vanish\n",
    "- G can't learn (no useful feedback)\n",
    "\n",
    "**Why it happens:**\n",
    "- When D is perfect, log(1-D(G(z))) saturates\n",
    "- Gradient becomes nearly zero\n",
    "\n",
    "**Solutions:**\n",
    "- Use non-saturating loss: -log(D(G(z))) instead\n",
    "- Label smoothing (use 0.9 instead of 1.0)\n",
    "- Wasserstein loss\n",
    "\n",
    "### 3. Training Instability üé¢\n",
    "\n",
    "**Problem:**\n",
    "- Losses oscillate wildly\n",
    "- No clear convergence\n",
    "- Hard to know when to stop\n",
    "\n",
    "**Why it happens:**\n",
    "- G and D are constantly adapting to each other\n",
    "- Moving target problem\n",
    "- Sensitive to hyperparameters\n",
    "\n",
    "**Solutions:**\n",
    "- Careful learning rate selection\n",
    "- Use Adam optimizer with Œ≤1=0.5\n",
    "- Spectral normalization\n",
    "- Progressive growing (StyleGAN)\n",
    "\n",
    "### 4. Hyperparameter Sensitivity üéõÔ∏è\n",
    "\n",
    "**Problem:**\n",
    "- Small changes ‚Üí big impact\n",
    "- Different datasets need different settings\n",
    "- Hard to find good configuration\n",
    "\n",
    "**Critical hyperparameters:**\n",
    "- Learning rates (typically 0.0001-0.0002)\n",
    "- Batch size (larger is often better)\n",
    "- Architecture depth\n",
    "- Discriminator updates per generator update\n",
    "\n",
    "**Solutions:**\n",
    "- Follow established architectures (DCGAN guidelines)\n",
    "- Use proven hyperparameters\n",
    "- Extensive experimentation\n",
    "\n",
    "### üõ†Ô∏è Modern Solutions (2024-2025):\n",
    "\n",
    "**Improved GAN Variants:**\n",
    "- **Wasserstein GAN (WGAN):** Better loss function\n",
    "- **Progressive GAN:** Gradually increase resolution\n",
    "- **StyleGAN:** Disentangled latent space\n",
    "- **BigGAN:** Larger models, better quality\n",
    "- **Self-Attention GAN (SAGAN):** Better global coherence\n",
    "\n",
    "**Alternative Approaches:**\n",
    "- **Diffusion Models:** More stable training (Stable Diffusion)\n",
    "- **VAE-GAN Hybrid:** Combine best of both\n",
    "- **Flow-Based Models:** Exact likelihood\n",
    "\n",
    "### üí° Best Practices:\n",
    "\n",
    "```python\n",
    "# 1. Use DCGAN architecture guidelines\n",
    "# 2. LeakyReLU in discriminator\n",
    "# 3. BatchNorm in generator\n",
    "# 4. Adam optimizer with Œ≤1=0.5\n",
    "# 5. Label smoothing\n",
    "# 6. Add noise to discriminator inputs\n",
    "# 7. Monitor multiple metrics (not just loss)\n",
    "# 8. Visual inspection of generations\n",
    "```\n",
    "\n",
    "**Remember:** GANs are powerful but finicky! Patience and experimentation are key. üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercises\n",
    "\n",
    "Test your understanding of GANs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "### Exercise 1: Understanding the Adversarial Game\n",
    "\n",
    "**Scenario:** You're training a GAN and observe these discriminator outputs:\n",
    "\n",
    "```\n",
    "Epoch 1:  D(real) = 0.95, D(fake) = 0.05\n",
    "Epoch 10: D(real) = 0.90, D(fake) = 0.30\n",
    "Epoch 20: D(real) = 0.85, D(fake) = 0.55\n",
    "```\n",
    "\n",
    "**Questions:**\n",
    "1. What's happening at each epoch?\n",
    "2. Is the GAN training successfully?\n",
    "3. What would you expect at Epoch 30?\n",
    "4. What if D(fake) stayed at 0.05 for 20 epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution-1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìñ Click here for solution</summary>\n",
    "\n",
    "**Analysis:**\n",
    "\n",
    "**Epoch 1:**\n",
    "- D(real) = 0.95 ‚Üí Discriminator correctly identifies real (95% confident)\n",
    "- D(fake) = 0.05 ‚Üí Easily spots fakes (only 5% fooled)\n",
    "- **Status:** Generator is producing obvious fakes\n",
    "\n",
    "**Epoch 10:**\n",
    "- D(real) = 0.90 ‚Üí Still good at identifying real\n",
    "- D(fake) = 0.30 ‚Üí Generator improving! (30% fooled)\n",
    "- **Status:** Generator learning, creating better fakes\n",
    "\n",
    "**Epoch 20:**\n",
    "- D(real) = 0.85 ‚Üí Slightly less confident\n",
    "- D(fake) = 0.55 ‚Üí Generator fooling D more than half the time!\n",
    "- **Status:** Near equilibrium, good generation quality\n",
    "\n",
    "**Expected Epoch 30:**\n",
    "- D(real) ‚âà 0.80-0.85\n",
    "- D(fake) ‚âà 0.50-0.60\n",
    "- Converging to 0.5 (perfect GAN)\n",
    "\n",
    "**If D(fake) stayed at 0.05:**\n",
    "- **Problem:** Mode collapse or vanishing gradients\n",
    "- Generator not learning\n",
    "- Solutions:\n",
    "  - Reduce discriminator learning rate\n",
    "  - Add noise to discriminator inputs\n",
    "  - Try different architecture\n",
    "  - Use label smoothing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### Exercise 2: GAN vs VAE\n",
    "\n",
    "**Task:** For each application, choose GAN or VAE and explain why:\n",
    "\n",
    "1. Generate photorealistic faces\n",
    "2. Compress and reconstruct medical images\n",
    "3. Create diverse fashion designs\n",
    "4. Anomaly detection in manufacturing\n",
    "5. Generate high-resolution textures for games\n",
    "6. Smooth interpolation between images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution-2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìñ Click here for solution</summary>\n",
    "\n",
    "**Recommended Approaches:**\n",
    "\n",
    "**1. Photorealistic faces ‚Üí GAN**\n",
    "- Why: GANs produce sharper, more realistic images\n",
    "- Example: StyleGAN, This Person Does Not Exist\n",
    "- VAEs tend to be blurrier\n",
    "\n",
    "**2. Compress/reconstruct medical images ‚Üí VAE**\n",
    "- Why: Need exact reconstruction, stability\n",
    "- VAE better for reconstruction tasks\n",
    "- Can't risk artifacts from GAN\n",
    "\n",
    "**3. Diverse fashion designs ‚Üí GAN**\n",
    "- Why: Need high-quality, diverse outputs\n",
    "- GANs better for creative generation\n",
    "- Used by Stitch Fix, fashion companies\n",
    "\n",
    "**4. Anomaly detection ‚Üí VAE**\n",
    "- Why: VAE learns smooth latent space\n",
    "- Reconstruction error identifies anomalies\n",
    "- More stable than GAN for this task\n",
    "\n",
    "**5. High-res game textures ‚Üí GAN**\n",
    "- Why: Need sharp, detailed outputs\n",
    "- GANs excel at texture generation\n",
    "- Example: NVIDIA GauGAN, texture synthesis\n",
    "\n",
    "**6. Smooth interpolation ‚Üí VAE or GAN**\n",
    "- VAE: More guaranteed smooth space\n",
    "- GAN: Can work with careful training\n",
    "- **Best:** VAE for stability, StyleGAN for quality\n",
    "\n",
    "**General Rule:**\n",
    "- **Generation/Creation ‚Üí GAN** (better quality)\n",
    "- **Reconstruction/Compression ‚Üí VAE** (more stable)\n",
    "- **Hybrid tasks ‚Üí VAE-GAN** (best of both!)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3",
   "metadata": {},
   "source": [
    "### Exercise 3: Modify the GAN\n",
    "\n",
    "**Task:** Experiment with GAN architecture and training:\n",
    "\n",
    "**Try these modifications:**\n",
    "1. Change latent dimension (50, 100, 200)\n",
    "2. Add/remove layers in generator or discriminator\n",
    "3. Try different learning rates (0.0001, 0.0002, 0.0005)\n",
    "4. Experiment with different optimizers (SGD, RMSprop, Adam)\n",
    "5. Change discriminator update frequency (1x, 2x, 5x per generator update)\n",
    "\n",
    "**Questions:**\n",
    "- Which changes improve quality?\n",
    "- Which cause instability?\n",
    "- What patterns do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR EXPERIMENTS HERE\n",
    "\n",
    "# Example: Try different latent dimensions\n",
    "# generator_small = Generator(latent_dim=50).to(device)\n",
    "# generator_large = Generator(latent_dim=200).to(device)\n",
    "\n",
    "# Your experiments..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "**You just learned:**\n",
    "\n",
    "### 1. **What are GANs?**\n",
    "   - ‚úÖ Two neural networks in adversarial competition\n",
    "   - ‚úÖ Generator creates fakes, Discriminator detects them\n",
    "   - ‚úÖ Arms race ‚Üí increasingly realistic generations\n",
    "   - **Key insight:** Competition drives quality\n",
    "\n",
    "### 2. **Generator Network**\n",
    "   - ‚úÖ Transforms random noise ‚Üí realistic images\n",
    "   - ‚úÖ Architecture: Linear layers + LeakyReLU + BatchNorm\n",
    "   - ‚úÖ Learns meaningful latent space\n",
    "   - **Goal:** Fool the discriminator\n",
    "\n",
    "### 3. **Discriminator Network**\n",
    "   - ‚úÖ Binary classifier (real vs fake)\n",
    "   - ‚úÖ Architecture: Linear layers + LeakyReLU + Dropout\n",
    "   - ‚úÖ Provides feedback to generator\n",
    "   - **Goal:** Correctly classify real and fake\n",
    "\n",
    "### 4. **Training Process**\n",
    "   - ‚úÖ Alternating optimization (train D, then G)\n",
    "   - ‚úÖ Minimax game theory\n",
    "   - ‚úÖ Challenges: mode collapse, instability, vanishing gradients\n",
    "   - **Success:** When D can't distinguish real from fake\n",
    "\n",
    "### 5. **Real Applications (2024-2025)**\n",
    "   - üé® **StyleGAN:** Photorealistic face generation\n",
    "   - üéÆ **NVIDIA GauGAN:** Landscape from sketches\n",
    "   - üè• **Medical:** Synthetic training data\n",
    "   - üì∏ **Super-resolution:** Enhance image quality\n",
    "   - **Impact:** Foundation for creative AI\n",
    "\n",
    "### üåü GANs in Modern AI:\n",
    "\n",
    "**Evolution:**\n",
    "```\n",
    "2014: Original GAN\n",
    "  ‚Üì\n",
    "2016: DCGAN (convolutional)\n",
    "  ‚Üì\n",
    "2018: StyleGAN (photorealistic)\n",
    "  ‚Üì\n",
    "2020: StyleGAN2 (better quality)\n",
    "  ‚Üì\n",
    "2024: GANs + Diffusion models\n",
    "```\n",
    "\n",
    "**Why GANs Matter:**\n",
    "- First breakthrough in generative AI quality\n",
    "- Showed that adversarial training works\n",
    "- Inspired diffusion models and other approaches\n",
    "- Still state-of-the-art for many tasks\n",
    "\n",
    "### üìä GAN vs Other Methods:\n",
    "\n",
    "| Method | Quality | Stability | Training | Best For |\n",
    "|--------|---------|-----------|----------|----------|\n",
    "| **GAN** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Hard | Generation |\n",
    "| **VAE** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Easy | Reconstruction |\n",
    "| **Diffusion** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Medium | Text-to-image |\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You now understand:\n",
    "- How GANs create realistic images from noise\n",
    "- The adversarial training process\n",
    "- Why GANs revolutionized generative AI\n",
    "- How to build and train your own GAN!\n",
    "\n",
    "**Next:** Advanced generative models - Diffusion, StyleGAN, DALL-E! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "**Practice Exercises:**\n",
    "1. Train GAN on Fashion-MNIST or CIFAR-10\n",
    "2. Implement conditional GAN (control what digit to generate)\n",
    "3. Try DCGAN (deep convolutional GAN)\n",
    "4. Experiment with WGAN (Wasserstein loss)\n",
    "5. Build a simple image-to-image translation GAN\n",
    "\n",
    "**Coming Next:**\n",
    "- **Day 3:** Advanced Generative Models\n",
    "  - StyleGAN architecture\n",
    "  - Diffusion models (Stable Diffusion, DALL-E)\n",
    "  - Text-to-image generation\n",
    "  - Prompt engineering\n",
    "  - Using pre-trained models\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Deep Dive Resources:**\n",
    "- \"Generative Adversarial Networks\" (Goodfellow et al., 2014)\n",
    "- \"Unsupervised Representation Learning with DCGANs\" (Radford et al., 2016)\n",
    "- \"Progressive Growing of GANs\" (Karras et al., 2018)\n",
    "- \"A Style-Based Generator Architecture for GANs\" (StyleGAN)\n",
    "- Ian Goodfellow's GAN Tutorial (NIPS 2016)\n",
    "\n",
    "**üéÆ Try These:**\n",
    "- This Person Does Not Exist (thispersondoesnotexist.com)\n",
    "- Artbreeder (artbreeder.com)\n",
    "- NVIDIA GauGAN (gaugan.org/gaugan2)\n",
    "\n",
    "---\n",
    "\n",
    "*Remember: GANs are the foundation of modern generative AI. Master them, and you'll understand how AI creates!* üåü\n",
    "\n",
    "**üéØ You now know how machines compete to create!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
