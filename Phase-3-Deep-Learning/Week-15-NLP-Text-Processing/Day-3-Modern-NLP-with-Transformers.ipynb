{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Day 3: Modern NLP with Transformers\n",
    "\n",
    "**ğŸ¯ Goal:** Master Transformers, BERT, GPT, and HuggingFace for state-of-the-art NLP\n",
    "\n",
    "**â±ï¸ Time:** 120-150 minutes\n",
    "\n",
    "**ğŸŒŸ Why This Matters for AI:**\n",
    "- Transformers power ChatGPT, Claude, BERT, and all modern LLMs\n",
    "- HuggingFace is the GitHub of AI models - access 100,000+ pre-trained models\n",
    "- Pre-trained models save weeks of training time and millions in compute costs\n",
    "- Understanding Transformers is essential for 2024-2025 AI development\n",
    "- These techniques power RAG systems, chatbots, and AI assistants\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  The Transformer Revolution\n",
    "\n",
    "### ğŸ“Š Evolution of NLP:\n",
    "\n",
    "```\n",
    "2013-2017: RNN/LSTM Era\n",
    "â”œâ”€ Word2Vec, GloVe embeddings\n",
    "â”œâ”€ Sequence models (LSTMs, GRUs)\n",
    "â””â”€ Limited context, slow training\n",
    "\n",
    "2017-2018: Transformer Revolution\n",
    "â”œâ”€ \"Attention Is All You Need\" paper\n",
    "â”œâ”€ Self-attention mechanism\n",
    "â””â”€ Parallel processing, better context\n",
    "\n",
    "2018-2020: Pre-trained Model Era\n",
    "â”œâ”€ BERT (Bidirectional understanding)\n",
    "â”œâ”€ GPT-2 (Text generation)\n",
    "â””â”€ Transfer learning for NLP\n",
    "\n",
    "2020-2025: Large Language Model Era\n",
    "â”œâ”€ GPT-3, GPT-4 (175B+ parameters)\n",
    "â”œâ”€ ChatGPT, Claude, Gemini\n",
    "â”œâ”€ RAG systems, AI agents\n",
    "â””â”€ Multimodal models (GPT-4V, Gemini)\n",
    "```\n",
    "\n",
    "### ğŸ¯ Why Transformers Won:\n",
    "\n",
    "**Problems with RNNs/LSTMs:**\n",
    "- âŒ Sequential processing (slow)\n",
    "- âŒ Vanishing gradients\n",
    "- âŒ Limited context window\n",
    "- âŒ Difficult to parallelize\n",
    "\n",
    "**Transformer Advantages:**\n",
    "- âœ… Parallel processing (fast!)\n",
    "- âœ… Self-attention captures long-range dependencies\n",
    "- âœ… Scales to billions of parameters\n",
    "- âœ… Transfer learning (pre-train once, use everywhere)\n",
    "\n",
    "### ğŸ”‘ Key Innovation: Self-Attention\n",
    "\n",
    "**Self-Attention** allows each word to \"attend\" to all other words!\n",
    "\n",
    "```\n",
    "Sentence: \"The cat sat on the mat\"\n",
    "\n",
    "Without Attention (RNN):\n",
    "\"cat\" â†’ only sees \"The\" before it\n",
    "\n",
    "With Self-Attention (Transformer):\n",
    "\"cat\" â†’ attends to ALL words: [The, cat, sat, on, the, mat]\n",
    "       â†’ learns \"sat\" and \"mat\" are important context\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Transformer Architecture\n",
    "\n",
    "### ğŸ“ The Transformer Block:\n",
    "\n",
    "```\n",
    "Input: \"I love AI\"\n",
    "   â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Token Embeddings   â”‚  Convert words to vectors\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "   â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Positional Encoding â”‚  Add position information\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "   â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Self-Attention     â”‚  Words attend to each other\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "   â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Feed-Forward NN    â”‚  Process attended features\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "   â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Layer Norm         â”‚  Normalize activations\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "   â†“\n",
    "Output Representation\n",
    "```\n",
    "\n",
    "### ğŸ¯ Two Main Transformer Types:\n",
    "\n",
    "#### 1ï¸âƒ£ **BERT (Encoder-only)**\n",
    "- **Purpose**: Understanding text\n",
    "- **Training**: Masked Language Modeling\n",
    "- **Use Cases**: Classification, NER, Q&A, sentiment analysis\n",
    "- **Examples**: BERT, RoBERTa, DistilBERT\n",
    "\n",
    "```\n",
    "Input: \"The cat sat on the [MASK]\"\n",
    "BERT predicts: \"mat\" (understanding context)\n",
    "```\n",
    "\n",
    "#### 2ï¸âƒ£ **GPT (Decoder-only)**\n",
    "- **Purpose**: Generating text\n",
    "- **Training**: Next Token Prediction\n",
    "- **Use Cases**: Text generation, chatbots, code generation\n",
    "- **Examples**: GPT-2, GPT-3, GPT-4, ChatGPT\n",
    "\n",
    "```\n",
    "Input: \"The cat sat on the\"\n",
    "GPT generates: \"mat and purred loudly.\"\n",
    "```\n",
    "\n",
    "#### 3ï¸âƒ£ **T5 (Encoder-Decoder)**\n",
    "- **Purpose**: Text-to-text tasks\n",
    "- **Training**: Unified text-to-text framework\n",
    "- **Use Cases**: Translation, summarization, Q&A\n",
    "- **Examples**: T5, BART, mBART\n",
    "\n",
    "```\n",
    "Input: \"summarize: [long text]\"\n",
    "T5 generates: [concise summary]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install transformers torch datasets evaluate numpy pandas matplotlib seaborn scikit-learn --quiet\n",
    "\n",
    "print(\"âœ… Libraries installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    pipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"ğŸ“š Libraries loaded!\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤— Introduction to HuggingFace\n",
    "\n",
    "**HuggingFace** is the platform for AI models and datasets!\n",
    "\n",
    "### ğŸ¯ Why HuggingFace?\n",
    "\n",
    "**ğŸª Model Hub:**\n",
    "- 100,000+ pre-trained models\n",
    "- BERT, GPT, T5, LLaMA, Mistral, and more\n",
    "- Community-contributed models\n",
    "\n",
    "**ğŸ“¦ Easy to Use:**\n",
    "- Load models in 3 lines of code\n",
    "- Unified API for all models\n",
    "- Automatic downloads and caching\n",
    "\n",
    "**ğŸ”§ Production-Ready:**\n",
    "- Optimized for inference\n",
    "- Model quantization support\n",
    "- Deploy to various platforms\n",
    "\n",
    "**ğŸ’° Cost-Effective:**\n",
    "- Use pre-trained models (save training costs)\n",
    "- Fine-tune on your data (not train from scratch)\n",
    "- Community models are free!\n",
    "\n",
    "### ğŸ—ï¸ HuggingFace Components:\n",
    "\n",
    "```python\n",
    "# 1. Tokenizer: Converts text to tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 2. Model: The neural network\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 3. Pipeline: High-level API (easiest!)\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "```\n",
    "\n",
    "### ğŸ¯ Popular Models on HuggingFace:\n",
    "\n",
    "**Understanding (Classification, NER, Q&A):**\n",
    "- `bert-base-uncased`: Original BERT\n",
    "- `roberta-base`: Optimized BERT\n",
    "- `distilbert-base-uncased`: Faster, smaller BERT\n",
    "\n",
    "**Generation (Text, Code, Chat):**\n",
    "- `gpt2`: OpenAI GPT-2\n",
    "- `mistralai/Mistral-7B-v0.1`: Open LLM\n",
    "- `meta-llama/Llama-2-7b-chat-hf`: Meta's LLaMA\n",
    "\n",
    "**Summarization & Translation:**\n",
    "- `t5-small`, `t5-base`: Google T5\n",
    "- `facebook/bart-large-cnn`: Summarization\n",
    "- `Helsinki-NLP/opus-mt-en-es`: Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Quick Start: Using Pre-trained Models\n",
    "\n",
    "Let's see how easy it is to use state-of-the-art models with HuggingFace pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis Pipeline (uses pre-trained BERT)\n",
    "print(\"ğŸ¤– Loading Sentiment Analysis Pipeline...\\n\")\n",
    "sentiment_analyzer = pipeline('sentiment-analysis')\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"I absolutely love this product! It's amazing!\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"The product is okay, nothing special.\",\n",
    "    \"ChatGPT and Claude are revolutionizing AI!\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š Sentiment Analysis Results:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    result = sentiment_analyzer(sentence)[0]\n",
    "    print(f\"\\nğŸ“ Text: \\\"{sentence}\\\"\")\n",
    "    print(f\"ğŸ¯ Sentiment: {result['label']}\")\n",
    "    print(f\"ğŸ“Š Confidence: {result['score']:.2%}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… That's it! Pre-trained model working in 2 lines of code!\")\n",
    "print(\"ğŸ’¡ This is the power of HuggingFace and transfer learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition Pipeline\n",
    "print(\"ğŸ·ï¸ Loading NER Pipeline...\\n\")\n",
    "ner = pipeline('ner', aggregation_strategy='simple')\n",
    "\n",
    "text_ner = \"Apple CEO Tim Cook announced that the new iPhone 15 will be released in September 2024 in Cupertino, California. Google and Microsoft are also launching new AI products.\"\n",
    "\n",
    "print(f\"ğŸ“ Text: {text_ner}\\n\")\n",
    "print(\"ğŸ·ï¸ Detected Entities:\\n\")\n",
    "print(f\"{'Entity':<30} {'Type':<15} {'Score':<10}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "entities = ner(text_ner)\n",
    "for entity in entities:\n",
    "    print(f\"{entity['word']:<30} {entity['entity_group']:<15} {entity['score']:.2%}\")\n",
    "\n",
    "print(\"\\nâœ… Pre-trained NER model working perfectly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Generation Pipeline (GPT-2)\n",
    "print(\"âœï¸ Loading Text Generation Pipeline...\\n\")\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "prompt = \"Artificial intelligence is transforming\"\n",
    "\n",
    "print(f\"ğŸ“ Prompt: \\\"{prompt}\\\"\\n\")\n",
    "print(\"ğŸ¤– Generated Text:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "generated = generator(\n",
    "    prompt,\n",
    "    max_length=50,\n",
    "    num_return_sequences=3,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for i, gen in enumerate(generated, 1):\n",
    "    print(f\"\\n{i}. {gen['generated_text']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… GPT-2 generating creative text!\")\n",
    "print(\"ğŸ’¡ This is the same architecture as ChatGPT (but much smaller)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Real AI Application #1: Sentiment Analysis with Pre-trained BERT\n",
    "\n",
    "**Scenario**: Build a production-ready sentiment analyzer using BERT!\n",
    "\n",
    "**Why BERT?**\n",
    "- Pre-trained on 3.3B words (Wikipedia + BookCorpus)\n",
    "- Understands context bidirectionally\n",
    "- State-of-the-art on 11 NLP tasks\n",
    "\n",
    "**Our Approach:**\n",
    "1. Load pre-trained BERT\n",
    "2. Fine-tune on our specific data (optional)\n",
    "3. Use for inference\n",
    "\n",
    "**Applications:**\n",
    "- Product review analysis (Amazon, Yelp)\n",
    "- Social media monitoring (Twitter, Reddit)\n",
    "- Customer feedback analysis\n",
    "- Brand sentiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive review dataset\n",
    "reviews_bert = [\n",
    "    # Positive reviews\n",
    "    \"This product is absolutely fantastic! Best purchase I've made this year!\",\n",
    "    \"Outstanding quality and excellent customer service. Highly recommend!\",\n",
    "    \"Love everything about this! Worth every penny!\",\n",
    "    \"Amazing experience! The product exceeded all my expectations!\",\n",
    "    \"Perfect! Exactly what I was looking for. Very satisfied!\",\n",
    "    \"Incredible quality and fast shipping. Will definitely buy again!\",\n",
    "    \"Superb product! Better than advertised. Five stars!\",\n",
    "    \"Excellent value for money. Very pleased with this purchase!\",\n",
    "    \"Wonderful product! Highly recommended to everyone!\",\n",
    "    \"Best quality I've seen. Absolutely love it!\",\n",
    "    \"Great product! Meets all my needs perfectly!\",\n",
    "    \"Fantastic! Everything works as described. Very happy!\",\n",
    "    \"Top-notch quality! Impressed with every aspect!\",\n",
    "    \"Brilliant product! Definitely worth the investment!\",\n",
    "    \"Awesome! Exceeded my expectations in every way!\",\n",
    "    \n",
    "    # Negative reviews\n",
    "    \"Terrible product! Complete waste of money!\",\n",
    "    \"Worst purchase ever. Broke after one day of use.\",\n",
    "    \"Very disappointed. Poor quality and doesn't work properly.\",\n",
    "    \"Awful experience. Product is nothing like described.\",\n",
    "    \"Don't buy this! Total disappointment and waste.\",\n",
    "    \"Horrible quality. Returned immediately for refund.\",\n",
    "    \"Extremely disappointed. Not worth a single penny.\",\n",
    "    \"Terrible! Stopped working after first use.\",\n",
    "    \"Very poor quality. Would not recommend to anyone.\",\n",
    "    \"Disaster! Nothing works as promised.\",\n",
    "    \"Cheap materials and poor construction. Avoid!\",\n",
    "    \"Not satisfied at all. Waste of time and money.\",\n",
    "    \"Poor design and terrible functionality. Very unhappy.\",\n",
    "    \"Defective product. Customer service was useless.\",\n",
    "    \"Awful! Completely failed to meet expectations.\",\n",
    "]\n",
    "\n",
    "# Labels (1 = positive, 0 = negative)\n",
    "labels_bert = [1] * 15 + [0] * 15\n",
    "\n",
    "df_bert = pd.DataFrame({\n",
    "    'review': reviews_bert,\n",
    "    'label': labels_bert,\n",
    "    'sentiment': ['Positive' if l == 1 else 'Negative' for l in labels_bert]\n",
    "})\n",
    "\n",
    "print(\"â­ BERT Sentiment Analysis Dataset:\")\n",
    "print(f\"Total reviews: {len(df_bert)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df_bert['sentiment'].value_counts())\n",
    "print(\"\\nğŸ“Š Sample reviews:\")\n",
    "print(df_bert.sample(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT for sentiment analysis\n",
    "print(\"ğŸ¤– Loading Pre-trained BERT Model...\\n\")\n",
    "\n",
    "# Use a BERT model fine-tuned on sentiment analysis\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "sentiment_bert = pipeline('sentiment-analysis', model=model_name)\n",
    "\n",
    "print(f\"âœ… Loaded: {model_name}\\n\")\n",
    "print(\"ğŸ“Š This model is BERT fine-tuned on sentiment analysis!\")\n",
    "print(\"ğŸ’¡ It understands context and nuance far better than traditional methods!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BERT on our reviews\n",
    "print(\"ğŸ”® Testing BERT Sentiment Analyzer:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test on sample reviews\n",
    "test_reviews = df_bert.sample(6)['review'].tolist()\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = sentiment_bert(review)[0]\n",
    "    \n",
    "    print(f\"\\nğŸ“ Review: \\\"{review}\\\"\")\n",
    "    print(f\"ğŸ¯ BERT Prediction: {result['label']}\")\n",
    "    print(f\"ğŸ“Š Confidence: {result['score']:.2%}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… BERT performing excellently!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation on all reviews\n",
    "print(\"ğŸ“Š Evaluating BERT on Entire Dataset...\\n\")\n",
    "\n",
    "predictions = []\n",
    "confidences = []\n",
    "\n",
    "for review in df_bert['review']:\n",
    "    result = sentiment_bert(review)[0]\n",
    "    # Convert to binary (POSITIVE=1, NEGATIVE=0)\n",
    "    pred = 1 if result['label'] == 'POSITIVE' else 0\n",
    "    predictions.append(pred)\n",
    "    confidences.append(result['score'])\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(df_bert['label'], predictions)\n",
    "\n",
    "print(f\"ğŸ¯ BERT Accuracy: {accuracy:.2%}\\n\")\n",
    "print(\"ğŸ“‹ Classification Report:\\n\")\n",
    "print(classification_report(df_bert['label'], predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(df_bert['label'], predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('BERT Sentiment Analysis - Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Sentiment', fontsize=12)\n",
    "plt.xlabel('Predicted Sentiment', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice the high accuracy! This is the power of pre-trained Transformers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on complex, nuanced reviews\n",
    "complex_reviews = [\n",
    "    \"The product is good but the shipping was terrible.\",\n",
    "    \"I wanted to love this, but it just doesn't work for me.\",\n",
    "    \"Not bad for the price, though could be better.\",\n",
    "    \"Great quality but way too expensive for what you get.\",\n",
    "    \"I was skeptical at first, but this exceeded my expectations!\",\n",
    "    \"The features are amazing, unfortunately it broke quickly.\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ§  Testing BERT on Nuanced Reviews:\\n\")\n",
    "print(\"These reviews have mixed sentiments - let's see how BERT handles them!\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for review in complex_reviews:\n",
    "    result = sentiment_bert(review)[0]\n",
    "    \n",
    "    print(f\"\\nğŸ“ Review: \\\"{review}\\\"\")\n",
    "    print(f\"ğŸ¯ BERT Says: {result['label']}\")\n",
    "    print(f\"ğŸ“Š Confidence: {result['score']:.2%}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ’¡ BERT captures context and nuance!\")\n",
    "print(\"   Notice lower confidence for mixed reviews - that's appropriate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Real AI Application #2: Text Summarization with T5\n",
    "\n",
    "**Scenario**: Automatically summarize long documents using T5!\n",
    "\n",
    "**Why T5?**\n",
    "- \"Text-to-Text Transfer Transformer\"\n",
    "- Unified framework for all NLP tasks\n",
    "- State-of-the-art summarization\n",
    "\n",
    "**How T5 Works:**\n",
    "```\n",
    "Input: \"summarize: [long article]\"\n",
    "T5: [generates concise summary]\n",
    "```\n",
    "\n",
    "**Applications:**\n",
    "- News article summarization\n",
    "- Document management systems\n",
    "- Email digest generation\n",
    "- Meeting notes summarization\n",
    "- RAG systems (summarize retrieved documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load T5 for summarization\n",
    "print(\"ğŸ“ Loading T5 Summarization Model...\\n\")\n",
    "\n",
    "summarizer = pipeline('summarization', model='t5-small')\n",
    "\n",
    "print(\"âœ… T5 Model Loaded!\\n\")\n",
    "print(\"ğŸ’¡ T5 is trained on a massive text-to-text dataset!\")\n",
    "print(\"   It can summarize, translate, answer questions, and more!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long article about AI (simulating news article)\n",
    "long_article = \"\"\"\n",
    "Artificial intelligence has experienced unprecedented growth in 2024 and 2025, \n",
    "transforming industries and reshaping how businesses operate. Large language models \n",
    "like ChatGPT, Claude, and Gemini have become household names, demonstrating \n",
    "remarkable capabilities in natural language understanding and generation. \n",
    "These models power countless applications, from customer service chatbots to \n",
    "code generation tools and creative writing assistants.\n",
    "\n",
    "One of the most significant developments has been the rise of Retrieval-Augmented \n",
    "Generation (RAG) systems, which combine the power of large language models with \n",
    "external knowledge bases. This approach addresses the hallucination problem and \n",
    "enables AI systems to provide more accurate, source-backed responses. Companies \n",
    "across industries are implementing RAG systems for internal knowledge management, \n",
    "customer support automation, and intelligent document search.\n",
    "\n",
    "The AI industry has also seen remarkable progress in multimodal models that can \n",
    "process and generate both text and images. GPT-4 Vision, Gemini, and DALL-E 3 \n",
    "showcase the potential of AI to understand and create visual content. These \n",
    "capabilities are being applied in fields ranging from medical diagnosis to \n",
    "creative design and automated content generation.\n",
    "\n",
    "However, the rapid advancement of AI has also raised important questions about \n",
    "ethics, safety, and regulation. Policymakers worldwide are working to develop \n",
    "frameworks that ensure AI systems are developed and deployed responsibly, while \n",
    "still fostering innovation. The balance between enabling AI progress and \n",
    "protecting society remains a critical challenge for the coming years.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“° Original Article:\")\n",
    "print(\"=\"*80)\n",
    "print(long_article)\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š Article Length: {len(long_article.split())} words\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "print(\"ğŸ¤– Generating Summary with T5...\\n\")\n",
    "\n",
    "summary = summarizer(\n",
    "    long_article,\n",
    "    max_length=100,\n",
    "    min_length=30,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"âœ… Summary Generated!\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“„ SUMMARY:\")\n",
    "print(summary[0]['summary_text'])\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š Summary Length: {len(summary[0]['summary_text'].split())} words\")\n",
    "print(f\"ğŸ“‰ Compression Ratio: {len(summary[0]['summary_text'].split()) / len(long_article.split()):.1%}\")\n",
    "print(\"\\nğŸ’¡ T5 extracted the key points and condensed them!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on multiple articles with different topics\n",
    "articles = [\n",
    "    {\n",
    "        'title': 'Tech Industry Update',\n",
    "        'text': \"\"\"Apple has announced its latest iPhone 15 Pro featuring advanced AI \n",
    "        capabilities and improved camera systems powered by machine learning. The new \n",
    "        device includes a dedicated neural engine for on-device AI processing, enabling \n",
    "        features like real-time photo enhancement, advanced voice recognition, and \n",
    "        predictive text input. Industry analysts predict strong sales driven by the \n",
    "        growing demand for AI-powered smartphones. The company also unveiled new \n",
    "        privacy features that keep user data secure while still enabling advanced \n",
    "        AI functionality.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'title': 'Climate Change Research',\n",
    "        'text': \"\"\"Scientists have discovered that machine learning algorithms can \n",
    "        significantly improve climate change predictions by analyzing vast amounts of \n",
    "        environmental data. Researchers at leading universities are using deep learning \n",
    "        models to forecast extreme weather events, track deforestation, and monitor \n",
    "        ocean temperatures with unprecedented accuracy. These AI-powered tools are \n",
    "        helping policymakers make more informed decisions about climate action and \n",
    "        resource allocation. The technology could play a crucial role in mitigating \n",
    "        the effects of global warming in the coming decades.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'title': 'Healthcare Innovation',\n",
    "        'text': \"\"\"Artificial intelligence is revolutionizing healthcare with applications \n",
    "        in disease diagnosis, drug discovery, and personalized treatment plans. Recent \n",
    "        studies show that AI systems can detect certain cancers earlier and more \n",
    "        accurately than human doctors by analyzing medical imaging data. Pharmaceutical \n",
    "        companies are using machine learning to accelerate drug development, reducing \n",
    "        the time and cost of bringing new treatments to market. Hospitals are \n",
    "        implementing AI-powered systems for patient monitoring, resource optimization, \n",
    "        and administrative tasks, improving both patient outcomes and operational \n",
    "        efficiency.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ“° Summarizing Multiple Articles:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for article in articles:\n",
    "    summary = summarizer(\n",
    "        article['text'],\n",
    "        max_length=60,\n",
    "        min_length=20,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Œ {article['title']}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Original ({len(article['text'].split())} words):\")\n",
    "    print(article['text'][:150] + \"...\")\n",
    "    print(f\"\\nSummary ({len(summary[0]['summary_text'].split())} words):\")\n",
    "    print(summary[0]['summary_text'])\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\nâœ… T5 successfully summarized all articles!\")\n",
    "print(\"ğŸ’¡ This is used by news aggregators, research tools, and RAG systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Understanding BERT Tokenization\n",
    "\n",
    "**Tokenization** is crucial in Transformers! Let's see how BERT tokenizes text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Test sentences\n",
    "sentences = [\n",
    "    \"I love AI and machine learning!\",\n",
    "    \"Transformers revolutionized NLP.\",\n",
    "    \"ChatGPT is amazing!\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”¤ BERT Tokenization Examples:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Tokenize\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    # Convert to IDs\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    # Encode (includes special tokens)\n",
    "    encoded = tokenizer.encode(sentence)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Original: {sentence}\")\n",
    "    print(f\"ğŸ”¤ Tokens: {tokens}\")\n",
    "    print(f\"ğŸ”¢ Token IDs: {token_ids[:10]}...\" if len(token_ids) > 10 else f\"ğŸ”¢ Token IDs: {token_ids}\")\n",
    "    print(f\"ğŸ“¦ Encoded (with [CLS], [SEP]): {encoded}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nğŸ’¡ BERT uses WordPiece tokenization:\")\n",
    "print(\"   - [CLS]: Classification token (start of sequence)\")\n",
    "print(\"   - [SEP]: Separator token (end of sequence)\")\n",
    "print(\"   - ##: Subword continuation (e.g., 'playing' â†’ 'play', '##ing')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate subword tokenization\n",
    "test_words = [\n",
    "    \"ChatGPT\",\n",
    "    \"transformer\",\n",
    "    \"antidisestablishmentarianism\",\n",
    "    \"AI\",\n",
    "    \"preprocessing\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”¬ Subword Tokenization Demo:\\n\")\n",
    "print(f\"{'Word':<30} {'Tokens':<50}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for word in test_words:\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    print(f\"{word:<30} {str(tokens):<50}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Unknown words are broken into subwords!\")\n",
    "print(\"   This allows BERT to handle any word, even ones not in training data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Why This Matters for Modern AI\n",
    "\n",
    "### ğŸ¤– **ChatGPT, Claude, and Modern LLMs**\n",
    "\n",
    "Everything you learned today is **directly used** in production AI!\n",
    "\n",
    "**ğŸ” How ChatGPT Works:**\n",
    "```\n",
    "1. Tokenization (WordPiece/BPE)\n",
    "   \"Hello\" â†’ [15496]\n",
    "\n",
    "2. Embedding Layer\n",
    "   [15496] â†’ [0.23, -0.45, ...] (dense vector)\n",
    "\n",
    "3. Transformer Layers (96 layers in GPT-4!)\n",
    "   - Self-attention\n",
    "   - Feed-forward networks\n",
    "   - Layer normalization\n",
    "\n",
    "4. Output Generation\n",
    "   Predict next token â†’ \"world\" â†’ \"!\"\n",
    "```\n",
    "\n",
    "### ğŸ” **RAG Systems in Production**\n",
    "\n",
    "**RAG Pipeline with Transformers:**\n",
    "```\n",
    "1. Document Embedding (BERT/Sentence-BERT)\n",
    "   Documents â†’ Dense vectors\n",
    "\n",
    "2. Query Embedding (same model)\n",
    "   User query â†’ Dense vector\n",
    "\n",
    "3. Similarity Search (Vector Database)\n",
    "   Find similar documents using cosine similarity\n",
    "\n",
    "4. Summarization (T5/BART)\n",
    "   Optionally summarize retrieved docs\n",
    "\n",
    "5. Generation (GPT/Claude)\n",
    "   Generate answer using retrieved context\n",
    "```\n",
    "\n",
    "### ğŸ“Š **Real-World Applications**\n",
    "\n",
    "**ğŸ¢ Enterprises:**\n",
    "- Internal knowledge base search\n",
    "- Document summarization\n",
    "- Customer support automation\n",
    "\n",
    "**ğŸ“° Media & Content:**\n",
    "- News article categorization\n",
    "- Content recommendation\n",
    "- Automated content generation\n",
    "\n",
    "**ğŸ›’ E-commerce:**\n",
    "- Product review analysis\n",
    "- Personalized recommendations\n",
    "- Customer sentiment monitoring\n",
    "\n",
    "**ğŸ¥ Healthcare:**\n",
    "- Medical report summarization\n",
    "- Clinical decision support\n",
    "- Patient feedback analysis\n",
    "\n",
    "### ğŸ¯ **Key Trends (2024-2025)**\n",
    "\n",
    "**1. Smaller, Faster Models:**\n",
    "- DistilBERT, TinyBERT (50% smaller, 60% faster)\n",
    "- Mistral 7B (outperforms larger models)\n",
    "- Phi-2 (2.7B parameters, GPT-3.5 performance)\n",
    "\n",
    "**2. Multimodal AI:**\n",
    "- GPT-4V (Vision + Text)\n",
    "- Gemini (Text + Image + Audio + Video)\n",
    "- CLIP (Image-Text alignment)\n",
    "\n",
    "**3. Open Source LLMs:**\n",
    "- LLaMA 2, Mistral, Falcon\n",
    "- Run locally on consumer hardware\n",
    "- Fine-tune for specific domains\n",
    "\n",
    "**4. Efficient Fine-tuning:**\n",
    "- LoRA, QLoRA (parameter-efficient)\n",
    "- PEFT (Parameter-Efficient Fine-Tuning)\n",
    "- Adapt models with minimal compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Interactive Exercise\n",
    "\n",
    "**Challenge**: Build a complete NLP application using HuggingFace!\n",
    "\n",
    "**Scenario**: Multi-purpose text analyzer\n",
    "\n",
    "**Tasks**:\n",
    "1. Sentiment analysis (BERT)\n",
    "2. Named entity recognition (spaCy/BERT)\n",
    "3. Text summarization (T5)\n",
    "4. Keyword extraction\n",
    "\n",
    "**Create a function that takes text and returns all analyses!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!\n",
    "\n",
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Comprehensive text analysis using Transformers\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with all analyses\n",
    "    \"\"\"\n",
    "    # TODO: Implement sentiment analysis\n",
    "    # TODO: Implement NER\n",
    "    # TODO: Implement summarization (if text is long enough)\n",
    "    # TODO: Return comprehensive analysis\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Test your function\n",
    "test_text = \"\"\"Apple CEO Tim Cook announced exciting new AI features in iOS 18. \n",
    "The update will include advanced machine learning capabilities that improve \n",
    "user privacy while enhancing functionality. Analysts predict this will boost \n",
    "iPhone sales significantly in 2025.\"\"\"\n",
    "\n",
    "# result = analyze_text(test_text)\n",
    "\n",
    "print(\"Complete the TODO above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Solution (Try on your own first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION - Complete NLP Analyzer\n",
    "\n",
    "# Load models\n",
    "sentiment_pipeline = pipeline('sentiment-analysis')\n",
    "ner_pipeline = pipeline('ner', aggregation_strategy='simple')\n",
    "summarization_pipeline = pipeline('summarization', model='t5-small')\n",
    "\n",
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Comprehensive text analysis using Transformers\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Sentiment Analysis\n",
    "    sentiment = sentiment_pipeline(text)[0]\n",
    "    results['sentiment'] = {\n",
    "        'label': sentiment['label'],\n",
    "        'confidence': sentiment['score']\n",
    "    }\n",
    "    \n",
    "    # 2. Named Entity Recognition\n",
    "    entities = ner_pipeline(text)\n",
    "    results['entities'] = [\n",
    "        {\n",
    "            'text': ent['word'],\n",
    "            'type': ent['entity_group'],\n",
    "            'confidence': ent['score']\n",
    "        }\n",
    "        for ent in entities\n",
    "    ]\n",
    "    \n",
    "    # 3. Summarization (if text is long enough)\n",
    "    word_count = len(text.split())\n",
    "    if word_count > 30:\n",
    "        summary = summarization_pipeline(\n",
    "            text,\n",
    "            max_length=50,\n",
    "            min_length=10,\n",
    "            do_sample=False\n",
    "        )\n",
    "        results['summary'] = summary[0]['summary_text']\n",
    "    else:\n",
    "        results['summary'] = \"Text too short for summarization\"\n",
    "    \n",
    "    # 4. Text statistics\n",
    "    results['statistics'] = {\n",
    "        'word_count': word_count,\n",
    "        'character_count': len(text),\n",
    "        'sentence_count': len([s for s in text.split('.') if s.strip()])\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the analyzer\n",
    "test_text = \"\"\"Apple CEO Tim Cook announced exciting new AI features in iOS 18. \n",
    "The update will include advanced machine learning capabilities that improve \n",
    "user privacy while enhancing functionality. Analysts predict this will boost \n",
    "iPhone sales significantly in 2025.\"\"\"\n",
    "\n",
    "print(\"ğŸ” Comprehensive Text Analysis:\\n\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“ Input Text:\\n{test_text}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "analysis = analyze_text(test_text)\n",
    "\n",
    "print(\"\\nğŸ˜Š SENTIMENT ANALYSIS:\")\n",
    "print(f\"   Label: {analysis['sentiment']['label']}\")\n",
    "print(f\"   Confidence: {analysis['sentiment']['confidence']:.2%}\")\n",
    "\n",
    "print(\"\\nğŸ·ï¸ NAMED ENTITIES:\")\n",
    "for ent in analysis['entities']:\n",
    "    print(f\"   {ent['text']} ({ent['type']}) - {ent['confidence']:.2%}\")\n",
    "\n",
    "print(\"\\nğŸ“„ SUMMARY:\")\n",
    "print(f\"   {analysis['summary']}\")\n",
    "\n",
    "print(\"\\nğŸ“Š STATISTICS:\")\n",
    "print(f\"   Words: {analysis['statistics']['word_count']}\")\n",
    "print(f\"   Characters: {analysis['statistics']['character_count']}\")\n",
    "print(f\"   Sentences: {analysis['statistics']['sentence_count']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… Complete NLP analyzer built using Transformers!\")\n",
    "print(\"ğŸ’¡ This is production-ready code using state-of-the-art models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "**You just learned:**\n",
    "- âœ… Transformer architecture and why it revolutionized NLP\n",
    "- âœ… BERT (understanding), GPT (generation), T5 (text-to-text)\n",
    "- âœ… HuggingFace library and how to use pre-trained models\n",
    "- âœ… Sentiment analysis with BERT (production-ready!)\n",
    "- âœ… Text summarization with T5\n",
    "- âœ… How modern AI systems (ChatGPT, RAG) work\n",
    "\n",
    "### ğŸ¯ Key Takeaways:\n",
    "\n",
    "1. **Transformers are the foundation of modern AI**\n",
    "   - Self-attention mechanism\n",
    "   - Parallel processing\n",
    "   - Transfer learning through pre-training\n",
    "\n",
    "2. **HuggingFace makes AI accessible**\n",
    "   - 100,000+ pre-trained models\n",
    "   - Easy-to-use pipelines\n",
    "   - Production-ready implementations\n",
    "\n",
    "3. **Pre-trained models save time and resources**\n",
    "   - Don't train from scratch\n",
    "   - Fine-tune for your specific task\n",
    "   - Achieve state-of-the-art results\n",
    "\n",
    "4. **Modern NLP is accessible to everyone**\n",
    "   - 3 lines of code for sentiment analysis\n",
    "   - Free models from the community\n",
    "   - Run locally or in the cloud\n",
    "\n",
    "### ğŸš€ What's Next?\n",
    "\n",
    "**Continue Learning:**\n",
    "- **Fine-tuning**: Adapt models to your domain\n",
    "- **RAG Systems**: Build production RAG pipelines\n",
    "- **LangChain**: Framework for LLM applications\n",
    "- **Vector Databases**: Pinecone, Weaviate, Chroma\n",
    "- **Deployment**: FastAPI, Docker, cloud platforms\n",
    "\n",
    "**Practice Projects:**\n",
    "1. Build a customer support chatbot with RAG\n",
    "2. Create a document Q&A system\n",
    "3. Develop a content moderation pipeline\n",
    "4. Build a news aggregation and summarization tool\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¯ Final Exercise:**\n",
    "\n",
    "Build a complete RAG system:\n",
    "1. Load and chunk documents\n",
    "2. Generate embeddings with BERT\n",
    "3. Store in vector database (or numpy array)\n",
    "4. Implement semantic search\n",
    "5. Summarize retrieved documents with T5\n",
    "6. (Bonus) Generate answers with GPT-2\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¬ Remember:**\n",
    "\n",
    "*\"You've completed a comprehensive journey through NLP - from basic text preprocessing to state-of-the-art Transformers! The techniques you learned are powering ChatGPT, Claude, Google Search, and countless AI applications. You now have the knowledge to build production-ready NLP systems using the same tools that power the AI revolution. The future of AI is in your hands!\"* ğŸš€\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ”— Resources for Continued Learning:**\n",
    "\n",
    "**ğŸ“š Documentation:**\n",
    "- HuggingFace Docs: https://huggingface.co/docs\n",
    "- Transformers Library: https://huggingface.co/transformers\n",
    "\n",
    "**ğŸ“ Courses:**\n",
    "- HuggingFace Course (FREE): https://huggingface.co/course\n",
    "- fast.ai NLP Course: https://www.fast.ai\n",
    "\n",
    "**ğŸ¤ Community:**\n",
    "- HuggingFace Forums: https://discuss.huggingface.co\n",
    "- r/MachineLearning: Reddit community\n",
    "\n",
    "**ğŸ¯ Keep Building! The best way to learn is by doing!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
