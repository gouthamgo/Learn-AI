{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìò Day 1: Text Preprocessing and Embeddings\n",
        "\n",
        "**üéØ Goal:** Master text preprocessing and understand how words become numbers (embeddings)\n",
        "\n",
        "**‚è±Ô∏è Time:** 75-90 minutes\n",
        "\n",
        "**üåü Why This Matters for AI:**\n",
        "- Text preprocessing is the FIRST step for ChatGPT, Claude, and all LLMs\n",
        "- Word embeddings power RAG systems, semantic search, and document retrieval\n",
        "- Understanding embeddings helps you build better chatbots, search engines, and AI assistants\n",
        "- GPT-4, BERT, and all modern NLP models use embeddings as their foundation\n",
        "- RAG systems rely on embedding similarity to find relevant documents!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† What is Natural Language Processing (NLP)?\n",
        "\n",
        "**Natural Language Processing** is teaching computers to understand and generate human language!\n",
        "\n",
        "### üéØ Real-World NLP Applications (2024-2025):\n",
        "\n",
        "#### ü§ñ **Large Language Models (LLMs)**\n",
        "- **ChatGPT, Claude, GPT-4**: Generate human-like text\n",
        "- **Gemini, Llama 3**: Open-source and multimodal models\n",
        "- **Applications**: Writing assistants, code generation, tutoring\n",
        "\n",
        "#### üîç **RAG (Retrieval-Augmented Generation)**\n",
        "- **Process**: Embed documents ‚Üí Find similar ‚Üí Generate answer\n",
        "- **Applications**: Customer support bots, knowledge bases, Q&A systems\n",
        "- **Why**: Reduces hallucinations, provides sources, keeps data current\n",
        "\n",
        "#### üí¨ **Chatbots & Virtual Assistants**\n",
        "- **Intent Classification**: Understanding what users want\n",
        "- **Entity Recognition**: Extracting names, dates, locations\n",
        "- **Applications**: Customer service, booking systems, AI agents\n",
        "\n",
        "#### üåê **Semantic Search**\n",
        "- **Traditional Search**: Keyword matching (\"apple\" only finds \"apple\")\n",
        "- **Semantic Search**: Meaning matching (\"fruit\" finds \"apple\", \"orange\")\n",
        "- **Applications**: Google, document search, recommendation systems\n",
        "\n",
        "#### üé® **Multimodal AI**\n",
        "- **GPT-4V**: Processes images + text\n",
        "- **CLIP**: Connects images with text descriptions\n",
        "- **Applications**: Image captioning, visual question answering\n",
        "\n",
        "### üîë The Key Challenge:\n",
        "\n",
        "**Computers only understand numbers, not words!**\n",
        "\n",
        "```\n",
        "Human:    \"I love AI\" ‚ùå Computer can't process this\n",
        "Computer: [0.2, 0.8, 0.5] ‚úÖ Computer understands vectors!\n",
        "```\n",
        "\n",
        "**Our Mission Today:**\n",
        "1. **Clean text**: Remove noise, normalize words\n",
        "2. **Convert to numbers**: Turn words into vectors (embeddings)\n",
        "3. **Capture meaning**: Similar words ‚Üí Similar vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Text Preprocessing Pipeline\n",
        "\n",
        "Before feeding text to AI models, we need to CLEAN and PREPARE it!\n",
        "\n",
        "### üìã Standard NLP Pipeline:\n",
        "\n",
        "```\n",
        "Raw Text\n",
        "   ‚Üì\n",
        "1Ô∏è‚É£ Tokenization     (Split into words/sentences)\n",
        "   ‚Üì\n",
        "2Ô∏è‚É£ Lowercasing      (\"Hello\" ‚Üí \"hello\")\n",
        "   ‚Üì\n",
        "3Ô∏è‚É£ Remove Stopwords (Remove \"the\", \"is\", \"a\")\n",
        "   ‚Üì\n",
        "4Ô∏è‚É£ Stemming/Lemmatization (\"running\" ‚Üí \"run\")\n",
        "   ‚Üì\n",
        "Clean Tokens\n",
        "   ‚Üì\n",
        "5Ô∏è‚É£ Vectorization    (Convert to numbers)\n",
        "   ‚Üì\n",
        "Ready for ML/DL!\n",
        "```\n",
        "\n",
        "### üéØ Why Each Step Matters:\n",
        "\n",
        "**1Ô∏è‚É£ Tokenization**\n",
        "- Splits text into units (words, subwords, characters)\n",
        "- **Example**: \"I love NLP!\" ‚Üí [\"I\", \"love\", \"NLP\", \"!\"]\n",
        "- **Used in**: All NLP models (BERT, GPT, etc.)\n",
        "\n",
        "**2Ô∏è‚É£ Lowercasing**\n",
        "- Treats \"Hello\" and \"hello\" as the same word\n",
        "- **Example**: \"Python\" ‚Üí \"python\"\n",
        "- **Trade-off**: Loses information (\"Apple\" company vs \"apple\" fruit)\n",
        "\n",
        "**3Ô∏è‚É£ Stopword Removal**\n",
        "- Removes common words with little meaning\n",
        "- **Example**: \"the\", \"is\", \"a\", \"an\", \"in\"\n",
        "- **Why**: Reduces noise, speeds up processing\n",
        "- **Caution**: Modern LLMs often keep stopwords!\n",
        "\n",
        "**4Ô∏è‚É£ Stemming vs Lemmatization**\n",
        "- **Stemming**: Crude chopping (\"running\" ‚Üí \"run\", \"better\" ‚Üí \"better\")\n",
        "- **Lemmatization**: Smart reduction (\"running\" ‚Üí \"run\", \"better\" ‚Üí \"good\")\n",
        "- **Example**: \"studies\", \"studying\", \"studied\" ‚Üí \"study\"\n",
        "\n",
        "**5Ô∏è‚É£ Vectorization**\n",
        "- Converts words to numbers\n",
        "- **Methods**: Bag of Words, TF-IDF, Word2Vec, BERT embeddings\n",
        "- **This is where the magic happens!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "import sys\n",
        "!{sys.executable} -m pip install nltk scikit-learn gensim matplotlib numpy pandas seaborn --quiet\n",
        "\n",
        "print(\"‚úÖ Libraries installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLTK (Natural Language Toolkit)\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "print(\"üìö Libraries loaded!\")\n",
        "print(\"‚úÖ NLTK data downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî§ Step 1: Tokenization\n",
        "\n",
        "**Tokenization** = Breaking text into smaller units (tokens)\n",
        "\n",
        "### üìä Types of Tokenization:\n",
        "\n",
        "1. **Word Tokenization**: Split by words\n",
        "2. **Sentence Tokenization**: Split by sentences\n",
        "3. **Subword Tokenization**: Split into parts (used by BERT, GPT)\n",
        "\n",
        "### üéØ Why Tokenization Matters:\n",
        "- **ChatGPT**: Uses BPE (Byte-Pair Encoding) tokenization\n",
        "- **BERT**: Uses WordPiece tokenization\n",
        "- **Token Limits**: GPT-4 has 8K/32K token limits\n",
        "- **Pricing**: Many APIs charge per token!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example text about AI and RAG\n",
        "text = \"\"\"\n",
        "Natural Language Processing is revolutionizing AI in 2024-2025! \n",
        "Large Language Models like ChatGPT and Claude can understand context. \n",
        "RAG systems combine retrieval with generation for better accuracy.\n",
        "Word embeddings help computers understand semantic similarity.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìù Original Text:\")\n",
        "print(text)\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Sentence Tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"üìÑ Sentence Tokenization:\")\n",
        "for i, sent in enumerate(sentences, 1):\n",
        "    print(f\"{i}. {sent.strip()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Word Tokenization\n",
        "words = word_tokenize(text)\n",
        "print(\"üî§ Word Tokenization:\")\n",
        "print(words[:20])  # First 20 tokens\n",
        "print(f\"\\nTotal tokens: {len(words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßπ Step 2: Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def preprocess_text(text, remove_stopwords=True, lowercase=True):\n",
        "    \"\"\"\n",
        "    Clean and preprocess text\n",
        "    \n",
        "    Args:\n",
        "        text: Input text string\n",
        "        remove_stopwords: Whether to remove stopwords\n",
        "        lowercase: Whether to convert to lowercase\n",
        "    \n",
        "    Returns:\n",
        "        List of cleaned tokens\n",
        "    \"\"\"\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Lowercase\n",
        "    if lowercase:\n",
        "        tokens = [word.lower() for word in tokens]\n",
        "    \n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "    \n",
        "    # Remove stopwords\n",
        "    if remove_stopwords:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "# Test the preprocessing\n",
        "sample_text = \"I love learning about AI and Machine Learning in 2024-2025!\"\n",
        "\n",
        "print(\"üìù Original:\")\n",
        "print(sample_text)\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"üî§ After tokenization:\")\n",
        "print(word_tokenize(sample_text))\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"üßπ After full preprocessing:\")\n",
        "cleaned = preprocess_text(sample_text)\n",
        "print(cleaned)\n",
        "print(f\"\\nOriginal tokens: {len(word_tokenize(sample_text))}\")\n",
        "print(f\"Cleaned tokens: {len(cleaned)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Step 3: Stemming vs Lemmatization\n",
        "\n",
        "### üî™ Stemming (Fast but Crude)\n",
        "- Chops word endings\n",
        "- **Pro**: Very fast\n",
        "- **Con**: Sometimes creates non-words\n",
        "- **Example**: \"running\" ‚Üí \"run\", \"studies\" ‚Üí \"studi\"\n",
        "\n",
        "### üéØ Lemmatization (Slow but Accurate)\n",
        "- Uses dictionary and grammar\n",
        "- **Pro**: Returns real words\n",
        "- **Con**: Slower\n",
        "- **Example**: \"running\" ‚Üí \"run\", \"better\" ‚Üí \"good\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Test words\n",
        "test_words = [\n",
        "    'running', 'runs', 'ran',\n",
        "    'better', 'good', 'best',\n",
        "    'studies', 'studying', 'studied',\n",
        "    'computing', 'computers', 'computed'\n",
        "]\n",
        "\n",
        "print(\"üî¨ Stemming vs Lemmatization Comparison:\\n\")\n",
        "print(f\"{'Original':<15} {'Stemmed':<15} {'Lemmatized':<15}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for word in test_words:\n",
        "    stemmed = stemmer.stem(word)\n",
        "    lemmatized = lemmatizer.lemmatize(word, pos='v')  # pos='v' for verb\n",
        "    print(f\"{word:<15} {stemmed:<15} {lemmatized:<15}\")\n",
        "\n",
        "print(\"\\nüí° Notice:\")\n",
        "print(\"   - Stemming sometimes creates non-words ('studi')\")\n",
        "print(\"   - Lemmatization preserves real words\")\n",
        "print(\"   - Both reduce vocabulary size!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéí Step 4: Bag of Words (BoW)\n",
        "\n",
        "**Bag of Words** = Count how many times each word appears\n",
        "\n",
        "### üìä How it Works:\n",
        "\n",
        "```\n",
        "Documents:\n",
        "D1: \"I love AI\"\n",
        "D2: \"I love machine learning\"\n",
        "D3: \"AI and machine learning\"\n",
        "\n",
        "Vocabulary: [I, love, AI, machine, learning, and]\n",
        "\n",
        "Vectors:\n",
        "D1: [1, 1, 1, 0, 0, 0]  ‚Üí counts for each word\n",
        "D2: [1, 1, 0, 1, 1, 0]\n",
        "D3: [0, 0, 1, 1, 1, 1]\n",
        "```\n",
        "\n",
        "### ‚ö†Ô∏è Limitations:\n",
        "- **No word order**: \"AI loves me\" = \"me loves AI\"\n",
        "- **No semantics**: \"good\" ‚â† \"great\" (different vectors)\n",
        "- **High dimensionality**: One column per unique word\n",
        "\n",
        "### ‚úÖ Strengths:\n",
        "- **Simple and fast**\n",
        "- **Works well for classification**\n",
        "- **Baseline for NLP tasks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample documents about AI\n",
        "documents = [\n",
        "    \"I love natural language processing\",\n",
        "    \"Machine learning is amazing\",\n",
        "    \"I love machine learning\",\n",
        "    \"Natural language processing uses machine learning\",\n",
        "    \"Deep learning powers ChatGPT and Claude\"\n",
        "]\n",
        "\n",
        "print(\"üìö Documents:\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Create Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"üéí Bag of Words Representation:\")\n",
        "print(f\"\\nVocabulary: {list(feature_names)}\")\n",
        "print(f\"Vocabulary size: {len(feature_names)}\")\n",
        "\n",
        "# Display as DataFrame\n",
        "bow_df = pd.DataFrame(\n",
        "    bow_matrix.toarray(),\n",
        "    columns=feature_names,\n",
        "    index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
        ")\n",
        "\n",
        "print(\"\\nüìä Word Counts per Document:\")\n",
        "print(bow_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Bag of Words\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(bow_df, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
        "plt.title('Bag of Words Heatmap', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Words', fontsize=12)\n",
        "plt.ylabel('Documents', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üé® Each cell shows how many times a word appears in a document\")\n",
        "print(\"üìå Notice: Most cells are 0 (sparse matrix!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 5: TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "**TF-IDF** = Smart weighting that highlights important words\n",
        "\n",
        "### üéØ The Problem with Bag of Words:\n",
        "- Common words like \"the\", \"is\" get high counts\n",
        "- But they don't carry much meaning!\n",
        "- **Solution**: TF-IDF downweights common words\n",
        "\n",
        "### üìê How TF-IDF Works:\n",
        "\n",
        "**TF (Term Frequency):**\n",
        "```\n",
        "TF(word) = (Count of word in document) / (Total words in document)\n",
        "```\n",
        "\n",
        "**IDF (Inverse Document Frequency):**\n",
        "```\n",
        "IDF(word) = log(Total documents / Documents containing word)\n",
        "```\n",
        "\n",
        "**TF-IDF Score:**\n",
        "```\n",
        "TF-IDF = TF √ó IDF\n",
        "```\n",
        "\n",
        "### üí° Intuition:\n",
        "- **High TF-IDF**: Word is frequent in THIS document, rare in others ‚Üí Important!\n",
        "- **Low TF-IDF**: Word is common everywhere ‚Üí Not distinctive\n",
        "\n",
        "### üéØ Used In:\n",
        "- **Search Engines**: Ranking relevant documents\n",
        "- **Document Similarity**: Finding similar texts\n",
        "- **Keyword Extraction**: Identifying important terms\n",
        "- **RAG Systems**: Document retrieval before generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get feature names\n",
        "tfidf_features = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display as DataFrame\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf_features,\n",
        "    index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
        ")\n",
        "\n",
        "print(\"üìä TF-IDF Representation:\")\n",
        "print(tfidf_df.round(3))\n",
        "\n",
        "print(\"\\nüí° Interpretation:\")\n",
        "print(\"   - Higher values = More important to that document\")\n",
        "print(\"   - Values range from 0 to 1\")\n",
        "print(\"   - Common words get lower scores\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize TF-IDF\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(tfidf_df, annot=True, fmt='.2f', cmap='Blues', cbar_kws={'label': 'TF-IDF Score'})\n",
        "plt.title('TF-IDF Heatmap', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Words', fontsize=12)\n",
        "plt.ylabel('Documents', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Notice how TF-IDF highlights distinctive words!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 6: Word Embeddings (Word2Vec)\n",
        "\n",
        "**Word Embeddings** = Dense vectors that capture word meaning!\n",
        "\n",
        "### üéØ The Revolution:\n",
        "\n",
        "**Old Way (BoW/TF-IDF):**\n",
        "- Sparse vectors (mostly zeros)\n",
        "- No semantic meaning\n",
        "- \"king\" and \"queen\" are completely different\n",
        "\n",
        "**New Way (Embeddings):**\n",
        "- Dense vectors (all values meaningful)\n",
        "- **Captures semantics**: Similar words ‚Üí Similar vectors\n",
        "- **Math with meaning**: king - man + woman ‚âà queen\n",
        "\n",
        "### üìê Word2Vec Properties:\n",
        "\n",
        "```\n",
        "\"king\"   ‚Üí [0.2, 0.8, 0.5, ...] (300 dimensions)\n",
        "\"queen\"  ‚Üí [0.1, 0.7, 0.6, ...]\n",
        "\"man\"    ‚Üí [0.3, 0.2, 0.1, ...]\n",
        "\"woman\"  ‚Üí [0.2, 0.1, 0.2, ...]\n",
        "\n",
        "Magic:\n",
        "vector(\"king\") - vector(\"man\") + vector(\"woman\") ‚âà vector(\"queen\")\n",
        "```\n",
        "\n",
        "### üéØ Why This Matters for AI:\n",
        "\n",
        "**üîç RAG Systems:**\n",
        "- Embed documents and queries\n",
        "- Find similar documents using cosine similarity\n",
        "- Retrieve relevant context for LLM\n",
        "\n",
        "**üí¨ Chatbots:**\n",
        "- Understand user intent through embeddings\n",
        "- Match to similar training examples\n",
        "- Generate contextual responses\n",
        "\n",
        "**üåê Semantic Search:**\n",
        "- Search by meaning, not keywords\n",
        "- \"How to fix a bug\" finds \"debugging tutorial\"\n",
        "\n",
        "**ü§ñ Modern LLMs:**\n",
        "- BERT, GPT, Claude use advanced embeddings\n",
        "- Contextual embeddings (same word, different meanings)\n",
        "- Foundation of all transformer models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install and import Gensim for Word2Vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample corpus about AI and ML\n",
        "sentences = [\n",
        "    ['machine', 'learning', 'is', 'subset', 'of', 'artificial', 'intelligence'],\n",
        "    ['deep', 'learning', 'uses', 'neural', 'networks'],\n",
        "    ['natural', 'language', 'processing', 'helps', 'computers', 'understand', 'text'],\n",
        "    ['chatgpt', 'and', 'claude', 'are', 'large', 'language', 'models'],\n",
        "    ['rag', 'systems', 'combine', 'retrieval', 'and', 'generation'],\n",
        "    ['word', 'embeddings', 'capture', 'semantic', 'meaning'],\n",
        "    ['transformers', 'revolutionized', 'natural', 'language', 'processing'],\n",
        "    ['bert', 'and', 'gpt', 'use', 'attention', 'mechanisms'],\n",
        "    ['vector', 'databases', 'store', 'embeddings', 'for', 'similarity', 'search'],\n",
        "    ['semantic', 'search', 'finds', 'documents', 'by', 'meaning'],\n",
        "]\n",
        "\n",
        "print(\"üî§ Training Word2Vec on AI/ML corpus...\\n\")\n",
        "\n",
        "# Train Word2Vec model\n",
        "# vector_size: dimension of embeddings\n",
        "# window: context window size\n",
        "# min_count: ignore words appearing less than this\n",
        "# sg: 1 for skip-gram, 0 for CBOW\n",
        "model = Word2Vec(\n",
        "    sentences=sentences,\n",
        "    vector_size=50,  # smaller for demo\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    sg=1,  # Skip-gram\n",
        "    epochs=100\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Word2Vec model trained!\")\n",
        "print(f\"\\nVocabulary size: {len(model.wv)}\")\n",
        "print(f\"Embedding dimension: {model.wv.vector_size}\")\n",
        "\n",
        "# Get embedding for a word\n",
        "word = 'learning'\n",
        "embedding = model.wv[word]\n",
        "\n",
        "print(f\"\\nüî¢ Embedding for '{word}':\")\n",
        "print(f\"Shape: {embedding.shape}\")\n",
        "print(f\"First 10 dimensions: {embedding[:10].round(3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find similar words\n",
        "test_words = ['learning', 'language', 'embeddings', 'chatgpt']\n",
        "\n",
        "print(\"üîç Finding Similar Words:\\n\")\n",
        "\n",
        "for word in test_words:\n",
        "    if word in model.wv:\n",
        "        similar = model.wv.most_similar(word, topn=3)\n",
        "        print(f\"üìå Words similar to '{word}':\")\n",
        "        for similar_word, score in similar:\n",
        "            print(f\"   - {similar_word}: {score:.3f}\")\n",
        "        print()\n",
        "\n",
        "print(\"üí° Higher score = More similar!\")\n",
        "print(\"üìä Similarity measured using cosine similarity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Step 7: Visualizing Word Embeddings\n",
        "\n",
        "Word embeddings are high-dimensional (50-300 dimensions). Let's use **t-SNE** to visualize them in 2D!\n",
        "\n",
        "**t-SNE** = Dimensionality reduction that preserves similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Get all words and their embeddings\n",
        "words = list(model.wv.index_to_key)\n",
        "word_vectors = np.array([model.wv[word] for word in words])\n",
        "\n",
        "# Reduce to 2D using t-SNE\n",
        "print(\"üé® Reducing embeddings to 2D using t-SNE...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
        "embeddings_2d = tsne.fit_transform(word_vectors)\n",
        "\n",
        "print(\"‚úÖ Dimensionality reduction complete!\\n\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.6, c='steelblue')\n",
        "\n",
        "# Add word labels\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, \n",
        "                xy=(embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "                xytext=(5, 5),\n",
        "                textcoords='offset points',\n",
        "                fontsize=11,\n",
        "                fontweight='bold')\n",
        "\n",
        "plt.title('Word Embeddings Visualization (t-SNE)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Dimension 1', fontsize=12)\n",
        "plt.ylabel('Dimension 2', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Notice how similar words cluster together!\")\n",
        "print(\"üí° 'learning', 'language', 'processing' should be close\")\n",
        "print(\"üéØ This is how RAG systems find similar documents!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Real AI Application: Building a Document Similarity System for RAG\n",
        "\n",
        "**Scenario**: You're building a RAG-powered chatbot for a tech company!\n",
        "\n",
        "**Task**: Given a user query, find the most relevant documents from your knowledge base.\n",
        "\n",
        "**Steps**:\n",
        "1. Convert documents to TF-IDF vectors (or embeddings)\n",
        "2. Convert user query to same vector space\n",
        "3. Calculate cosine similarity\n",
        "4. Return top-K most similar documents\n",
        "5. (In real RAG) Feed these docs to LLM for answer generation\n",
        "\n",
        "**This is the core of RAG systems!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Knowledge base documents (simulating company documentation)\n",
        "knowledge_base = [\n",
        "    \"Machine learning is a subset of artificial intelligence that learns from data\",\n",
        "    \"Deep learning uses neural networks with multiple layers for complex pattern recognition\",\n",
        "    \"Natural language processing helps computers understand and generate human language\",\n",
        "    \"RAG systems combine retrieval and generation for more accurate AI responses\",\n",
        "    \"ChatGPT and Claude are large language models trained on massive text datasets\",\n",
        "    \"Word embeddings represent words as dense vectors capturing semantic meaning\",\n",
        "    \"Transformers use attention mechanisms to process sequential data like text\",\n",
        "    \"Vector databases store embeddings for efficient similarity search\",\n",
        "    \"Semantic search finds documents by meaning rather than exact keyword matches\",\n",
        "    \"Fine-tuning adapts pre-trained models to specific tasks or domains\"\n",
        "]\n",
        "\n",
        "print(\"üìö Knowledge Base:\")\n",
        "for i, doc in enumerate(knowledge_base, 1):\n",
        "    print(f\"{i}. {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "# Create TF-IDF vectors for all documents\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vectors = vectorizer.fit_transform(knowledge_base)\n",
        "\n",
        "print(f\"‚úÖ Vectorized {len(knowledge_base)} documents\")\n",
        "print(f\"üìä Vocabulary size: {len(vectorizer.get_feature_names_out())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_documents(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Search for most relevant documents given a query\n",
        "    \n",
        "    This is the retrieval step in RAG!\n",
        "    \n",
        "    Args:\n",
        "        query: User's search query\n",
        "        top_k: Number of top results to return\n",
        "    \n",
        "    Returns:\n",
        "        List of (document, similarity_score) tuples\n",
        "    \"\"\"\n",
        "    # Convert query to TF-IDF vector\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    \n",
        "    # Calculate cosine similarity with all documents\n",
        "    similarities = cosine_similarity(query_vector, doc_vectors)[0]\n",
        "    \n",
        "    # Get top-k most similar documents\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    \n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'document': knowledge_base[idx],\n",
        "            'score': similarities[idx],\n",
        "            'rank': len(results) + 1\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"How do neural networks work?\",\n",
        "    \"What is RAG and how does it improve AI?\",\n",
        "    \"Explain word embeddings\",\n",
        "]\n",
        "\n",
        "print(\"üîç Testing Document Retrieval System:\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n‚ùì Query: '{query}'\\n\")\n",
        "    \n",
        "    results = search_documents(query, top_k=3)\n",
        "    \n",
        "    print(\"üìÑ Top 3 Most Relevant Documents:\\n\")\n",
        "    for result in results:\n",
        "        print(f\"#{result['rank']} (Similarity: {result['score']:.3f})\")\n",
        "        print(f\"   {result['document']}\\n\")\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüéØ This is exactly how RAG systems work!\")\n",
        "print(\"   1. User asks a question\")\n",
        "print(\"   2. System finds relevant documents (what we just did)\")\n",
        "print(\"   3. LLM generates answer using retrieved documents\")\n",
        "print(\"   4. Result: Accurate, grounded, source-backed answers!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Why This Matters for Modern AI\n",
        "\n",
        "### üîç **RAG Systems (2024-2025 Trend)**\n",
        "\n",
        "What you just built is the **core of RAG**!\n",
        "\n",
        "**Full RAG Pipeline:**\n",
        "```\n",
        "User Query: \"What is machine learning?\"\n",
        "     ‚Üì\n",
        "1. EMBED query ‚Üí vector\n",
        "     ‚Üì\n",
        "2. RETRIEVE similar docs (what we built!)\n",
        "     ‚Üì\n",
        "3. GENERATE answer using LLM + retrieved docs\n",
        "     ‚Üì\n",
        "Answer: \"Based on our documentation, machine learning is...\"\n",
        "```\n",
        "\n",
        "### üéØ **Real-World Applications:**\n",
        "\n",
        "**1. Customer Support Bots**\n",
        "- Embed all support docs\n",
        "- User asks question ‚Üí retrieve relevant docs\n",
        "- LLM generates answer with sources\n",
        "\n",
        "**2. Internal Knowledge Systems**\n",
        "- Companies embed all internal docs\n",
        "- Employees search by meaning, not keywords\n",
        "- Find relevant info across 1000s of documents\n",
        "\n",
        "**3. Code Search (GitHub Copilot)**\n",
        "- Embed code snippets and descriptions\n",
        "- Search for \"how to read JSON file\"\n",
        "- Find relevant code examples\n",
        "\n",
        "**4. Semantic Search Engines**\n",
        "- Google, Bing use embeddings\n",
        "- Understand query intent\n",
        "- Find pages by meaning\n",
        "\n",
        "### ü§ñ **Modern Embedding Models:**\n",
        "\n",
        "In production, you'd use advanced embeddings:\n",
        "- **OpenAI Embeddings**: `text-embedding-3-large`\n",
        "- **Sentence Transformers**: `all-MiniLM-L6-v2`\n",
        "- **Cohere Embeddings**: Multilingual support\n",
        "- **Voyage AI**: Optimized for RAG\n",
        "\n",
        "These are 100x better than Word2Vec for RAG!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ YOUR TURN: Interactive Exercise\n",
        "\n",
        "**Challenge**: Build a product recommendation system using embeddings!\n",
        "\n",
        "**Scenario**: You work for an e-commerce company. Build a system that recommends similar products based on descriptions.\n",
        "\n",
        "**Tasks**:\n",
        "1. Create product descriptions (at least 5)\n",
        "2. Vectorize them using TF-IDF\n",
        "3. Implement a `find_similar_products()` function\n",
        "4. Test with sample queries\n",
        "\n",
        "**Bonus**: Visualize the product embeddings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE!\n",
        "\n",
        "# TODO 1: Create product descriptions\n",
        "products = [\n",
        "    # Add at least 5 product descriptions\n",
        "    # Example: \"Wireless bluetooth headphones with noise cancellation\"\n",
        "]\n",
        "\n",
        "# TODO 2: Vectorize products using TF-IDF\n",
        "# Hint: Use TfidfVectorizer\n",
        "\n",
        "# TODO 3: Implement find_similar_products(product_query, top_k=3)\n",
        "def find_similar_products(product_query, top_k=3):\n",
        "    \"\"\"\n",
        "    Find similar products based on description\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    pass\n",
        "\n",
        "# TODO 4: Test with queries\n",
        "# Example: find_similar_products(\"looking for wireless headphones\")\n",
        "\n",
        "print(\"Complete the TODOs above!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Solution (Try on your own first!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SOLUTION\n",
        "\n",
        "# Product catalog\n",
        "products = [\n",
        "    \"Wireless bluetooth headphones with active noise cancellation and 30-hour battery\",\n",
        "    \"USB-C charging cable with fast charging support for smartphones and tablets\",\n",
        "    \"Mechanical gaming keyboard with RGB lighting and customizable keys\",\n",
        "    \"4K webcam with autofocus and built-in microphone for video conferencing\",\n",
        "    \"Portable bluetooth speaker with waterproof design and 360-degree sound\",\n",
        "    \"Wireless gaming mouse with programmable buttons and adjustable DPI\",\n",
        "    \"Laptop stand with adjustable height and cooling fan for better ergonomics\",\n",
        "    \"Noise-cancelling earbuds with wireless charging case and touch controls\",\n",
        "]\n",
        "\n",
        "product_names = [\n",
        "    \"Premium Headphones\",\n",
        "    \"Fast Charging Cable\",\n",
        "    \"RGB Gaming Keyboard\",\n",
        "    \"4K Webcam\",\n",
        "    \"Portable Speaker\",\n",
        "    \"Gaming Mouse\",\n",
        "    \"Laptop Stand\",\n",
        "    \"Wireless Earbuds\"\n",
        "]\n",
        "\n",
        "print(\"üõçÔ∏è Product Catalog:\")\n",
        "for name, desc in zip(product_names, products):\n",
        "    print(f\"- {name}: {desc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Vectorize products\n",
        "product_vectorizer = TfidfVectorizer()\n",
        "product_vectors = product_vectorizer.fit_transform(products)\n",
        "\n",
        "def find_similar_products(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Find similar products based on query\n",
        "    \"\"\"\n",
        "    # Convert query to vector\n",
        "    query_vec = product_vectorizer.transform([query])\n",
        "    \n",
        "    # Calculate similarities\n",
        "    similarities = cosine_similarity(query_vec, product_vectors)[0]\n",
        "    \n",
        "    # Get top-k\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    \n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'name': product_names[idx],\n",
        "            'description': products[idx],\n",
        "            'score': similarities[idx]\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test queries\n",
        "queries = [\n",
        "    \"I need wireless audio device for music\",\n",
        "    \"Looking for gaming peripherals with lights\",\n",
        "    \"Want something for video calls and meetings\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"üîç Query: '{query}'\\n\")\n",
        "    recommendations = find_similar_products(query, top_k=3)\n",
        "    \n",
        "    print(\"üí° Recommended Products:\\n\")\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"{i}. {rec['name']} (Score: {rec['score']:.3f})\")\n",
        "        print(f\"   {rec['description']}\\n\")\n",
        "    \n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"‚úÖ Product recommendation system built!\")\n",
        "print(\"üéØ This is used in e-commerce, content recommendations, and more!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "**You just learned:**\n",
        "- ‚úÖ Text preprocessing pipeline (tokenization, cleaning, stemming, lemmatization)\n",
        "- ‚úÖ Bag of Words and TF-IDF vectorization\n",
        "- ‚úÖ Word2Vec embeddings and semantic similarity\n",
        "- ‚úÖ Visualizing word embeddings with t-SNE\n",
        "- ‚úÖ Built a document similarity system for RAG\n",
        "- ‚úÖ Understood how embeddings power modern AI!\n",
        "\n",
        "### üéØ Key Takeaways:\n",
        "\n",
        "1. **Text must be converted to numbers for AI**\n",
        "   - Preprocessing cleans and normalizes text\n",
        "   - Vectorization creates numeric representations\n",
        "\n",
        "2. **Embeddings capture semantic meaning**\n",
        "   - Similar words have similar vectors\n",
        "   - Enable semantic search and similarity\n",
        "\n",
        "3. **TF-IDF highlights important words**\n",
        "   - Downweights common words\n",
        "   - Used for document ranking and search\n",
        "\n",
        "4. **This powers modern AI systems**\n",
        "   - RAG uses embeddings for retrieval\n",
        "   - LLMs use advanced contextual embeddings\n",
        "   - Vector databases store embeddings at scale\n",
        "\n",
        "---\n",
        "\n",
        "**üéØ Practice Exercise (Before Day 2):**\n",
        "\n",
        "Build a simple chatbot FAQ system:\n",
        "1. Create 10+ FAQ pairs (question, answer)\n",
        "2. Vectorize all questions\n",
        "3. When user asks question, find most similar FAQ\n",
        "4. Return the corresponding answer\n",
        "\n",
        "This is a mini-RAG system!\n",
        "\n",
        "---\n",
        "\n",
        "**üìö Next Lesson:** Day 2 - Text Classification with Deep Learning\n",
        "- Embedding layers in neural networks\n",
        "- 1D CNNs for text\n",
        "- LSTM text classifiers\n",
        "- Attention mechanisms\n",
        "- Build spam detector and intent classifier!\n",
        "\n",
        "---\n",
        "\n",
        "**üí¨ Remember:**\n",
        "\n",
        "*\"You just built the foundation of RAG systems! Every time you use ChatGPT with file uploads, or ask a question to a company's AI chatbot, embeddings and similarity search are working behind the scenes. You now understand the core technology powering the AI revolution!\"* üöÄ\n",
        "\n",
        "---\n",
        "\n",
        "**üîó Connections to Modern AI:**\n",
        "- **RAG**: Embeddings + similarity search + LLM generation\n",
        "- **Semantic Search**: TF-IDF/embeddings for meaningful search\n",
        "- **Chatbots**: Intent matching using embedding similarity\n",
        "- **LLMs**: Use advanced contextual embeddings (BERT, GPT)\n",
        "- **Vector DBs**: Pinecone, Weaviate store billions of embeddings"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
