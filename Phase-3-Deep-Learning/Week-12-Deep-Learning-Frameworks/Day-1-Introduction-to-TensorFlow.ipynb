{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Day 1: Introduction to TensorFlow\n",
    "\n",
    "**üéØ Goal:** Master TensorFlow/Keras for building deep learning models\n",
    "\n",
    "**‚è±Ô∏è Time:** 60-90 minutes\n",
    "\n",
    "**üåü Why This Matters for AI:**\n",
    "- TensorFlow powers real-world AI: Google Translate, YouTube recommendations, Gmail spam detection\n",
    "- Used by 60% of Fortune 500 companies for production AI systems\n",
    "- Foundation for building RAG systems, multimodal AI, and transformer models\n",
    "- Essential for creating computer vision, NLP, and recommendation systems\n",
    "\n",
    "**üî• 2024-2025 AI Trends You'll Learn:**\n",
    "- Building blocks for RAG (Retrieval-Augmented Generation) systems\n",
    "- Neural networks for multimodal AI (text + images)\n",
    "- Transfer learning for efficient model development\n",
    "- Production-ready model deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ What is TensorFlow?\n",
    "\n",
    "**TensorFlow** is Google's open-source deep learning framework.\n",
    "\n",
    "**Think of it as:**\n",
    "- üèóÔ∏è A construction kit for building AI models\n",
    "- üß† A brain-building toolkit\n",
    "- ‚ö° A high-performance computation engine\n",
    "\n",
    "**Real-World Uses:**\n",
    "- Google Photos (face recognition)\n",
    "- DeepMind AlphaGo (game playing)\n",
    "- Healthcare diagnostics (disease detection)\n",
    "- Self-driving cars (object detection)\n",
    "\n",
    "**Keras** = TensorFlow's high-level, user-friendly API (makes building models EASY!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow (run this once)\n",
    "!pip install tensorflow numpy matplotlib scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"‚úÖ TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"‚úÖ Keras Version: {keras.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Section 1: TensorFlow Basics - Tensors\n",
    "\n",
    "**Tensors** = Multi-dimensional arrays (the fundamental data structure)\n",
    "\n",
    "| Dimension | Name | Example | AI Use |\n",
    "|-----------|------|---------|--------|\n",
    "| 0D | Scalar | `5` | Single value, loss |\n",
    "| 1D | Vector | `[1, 2, 3]` | Feature values |\n",
    "| 2D | Matrix | `[[1, 2], [3, 4]]` | Tabular data, embeddings |\n",
    "| 3D | 3D Tensor | `[[[...]]]` | RGB image, time series |\n",
    "| 4D | 4D Tensor | `[[[[...]]]]` | Batch of images |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors\n",
    "\n",
    "# 0D tensor (scalar)\n",
    "scalar = tf.constant(42)\n",
    "print(f\"Scalar: {scalar}\")\n",
    "print(f\"Shape: {scalar.shape}\\n\")\n",
    "\n",
    "# 1D tensor (vector)\n",
    "vector = tf.constant([1, 2, 3, 4, 5])\n",
    "print(f\"Vector: {vector}\")\n",
    "print(f\"Shape: {vector.shape}\\n\")\n",
    "\n",
    "# 2D tensor (matrix) - like a spreadsheet!\n",
    "matrix = tf.constant([[1, 2, 3],\n",
    "                      [4, 5, 6]])\n",
    "print(f\"Matrix:\\n{matrix}\")\n",
    "print(f\"Shape: {matrix.shape}\\n\")\n",
    "\n",
    "# 3D tensor - like a color image (height, width, channels)\n",
    "image_tensor = tf.random.normal([224, 224, 3])  # 224x224 RGB image\n",
    "print(f\"Image Tensor Shape: {image_tensor.shape}\")\n",
    "print(f\"  ‚Üí 224 height, 224 width, 3 color channels (RGB)\\n\")\n",
    "\n",
    "# 4D tensor - batch of images\n",
    "batch_images = tf.random.normal([32, 224, 224, 3])  # 32 images\n",
    "print(f\"Batch of Images Shape: {batch_images.shape}\")\n",
    "print(f\"  ‚Üí 32 images, each 224x224 with 3 color channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¢ Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\n",
    "a = tf.constant([1, 2, 3])\n",
    "b = tf.constant([4, 5, 6])\n",
    "\n",
    "# Addition\n",
    "print(f\"Addition: {a + b}\")\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "print(f\"Multiplication: {a * b}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "mat1 = tf.constant([[1, 2], [3, 4]])\n",
    "mat2 = tf.constant([[5, 6], [7, 8]])\n",
    "print(f\"\\nMatrix Multiplication:\\n{tf.matmul(mat1, mat2)}\")\n",
    "\n",
    "# Common operations for neural networks\n",
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "print(f\"\\nMean: {tf.reduce_mean(x)}\")\n",
    "print(f\"Sum: {tf.reduce_sum(x)}\")\n",
    "print(f\"Max: {tf.reduce_max(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Section 2: Sequential API - The Simplest Way\n",
    "\n",
    "**Sequential API** = Stack layers like LEGO blocks\n",
    "\n",
    "Perfect for:\n",
    "- ‚úÖ Simple feedforward networks\n",
    "- ‚úÖ Basic CNN (Convolutional Neural Networks)\n",
    "- ‚úÖ Simple RNN (Recurrent Neural Networks)\n",
    "\n",
    "**Architecture:** Input ‚Üí Hidden Layer 1 ‚Üí Hidden Layer 2 ‚Üí Output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple Neural Network for Classification\n",
    "# Let's build a network to classify if a number is > 50\n",
    "\n",
    "# Create a Sequential model\n",
    "model = models.Sequential([\n",
    "    # Input layer (10 features)\n",
    "    layers.Input(shape=(10,)),\n",
    "    \n",
    "    # Hidden layer 1: 64 neurons, ReLU activation\n",
    "    layers.Dense(64, activation='relu', name='hidden_layer_1'),\n",
    "    \n",
    "    # Hidden layer 2: 32 neurons, ReLU activation\n",
    "    layers.Dense(32, activation='relu', name='hidden_layer_2'),\n",
    "    \n",
    "    # Output layer: 1 neuron, sigmoid for binary classification\n",
    "    layers.Dense(1, activation='sigmoid', name='output_layer')\n",
    "])\n",
    "\n",
    "# View model architecture\n",
    "print(\"üîç Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üß† Understanding the Summary:**\n",
    "- **Param #**: Number of learnable parameters (weights + biases)\n",
    "- **Output Shape**: Dimensions of data after each layer\n",
    "- **Total params**: All weights the model needs to learn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',              # Adam optimizer (adaptive learning rate)\n",
    "    loss='binary_crossentropy',    # For binary classification (0 or 1)\n",
    "    metrics=['accuracy']           # Track accuracy during training\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled and ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Alternative Way: Add Layers One by One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to build Sequential models\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Input(shape=(10,)))\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(32, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Section 3: Functional API - For Complex Architectures\n",
    "\n",
    "**Functional API** = Build complex, non-linear architectures\n",
    "\n",
    "**Use when you need:**\n",
    "- üîÄ Multiple inputs (e.g., text + images for multimodal AI)\n",
    "- üîÄ Multiple outputs (e.g., predict age + gender simultaneously)\n",
    "- üîÄ Skip connections (like ResNet)\n",
    "- üîÄ Shared layers\n",
    "\n",
    "**2024-2025 Trend:** Multimodal AI models use Functional API!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multi-Input Model (Multimodal AI!)\n",
    "# Scenario: Predict house price using BOTH numerical features AND image of the house\n",
    "\n",
    "# Input 1: Numerical features (size, bedrooms, etc.)\n",
    "numerical_input = layers.Input(shape=(10,), name='numerical_features')\n",
    "x1 = layers.Dense(32, activation='relu')(numerical_input)\n",
    "x1 = layers.Dense(16, activation='relu')(x1)\n",
    "\n",
    "# Input 2: Image features (pretend we have image features)\n",
    "image_input = layers.Input(shape=(128,), name='image_features')\n",
    "x2 = layers.Dense(64, activation='relu')(image_input)\n",
    "x2 = layers.Dense(32, activation='relu')(x2)\n",
    "\n",
    "# Combine both inputs\n",
    "combined = layers.concatenate([x1, x2])\n",
    "\n",
    "# Final layers\n",
    "z = layers.Dense(32, activation='relu')(combined)\n",
    "output = layers.Dense(1, activation='linear', name='price_output')(z)\n",
    "\n",
    "# Create the model\n",
    "multi_input_model = models.Model(\n",
    "    inputs=[numerical_input, image_input],\n",
    "    outputs=output,\n",
    "    name='HousePricePredictor'\n",
    ")\n",
    "\n",
    "print(\"üè† Multi-Input Model for House Price Prediction:\")\n",
    "multi_input_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üî• This is EXACTLY how modern multimodal AI works:**\n",
    "- GPT-4 Vision: Text + Images\n",
    "- CLIP: Text + Images\n",
    "- Gemini: Text + Images + Video + Audio\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multi-Output Model\n",
    "# Scenario: Predict BOTH age AND gender from a face image\n",
    "\n",
    "# Single input\n",
    "input_layer = layers.Input(shape=(128,), name='face_features')\n",
    "\n",
    "# Shared layers\n",
    "x = layers.Dense(64, activation='relu')(input_layer)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# Output 1: Age prediction (regression)\n",
    "age_output = layers.Dense(1, activation='linear', name='age')(x)\n",
    "\n",
    "# Output 2: Gender prediction (binary classification)\n",
    "gender_output = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "# Create model with multiple outputs\n",
    "multi_output_model = models.Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=[age_output, gender_output],\n",
    "    name='AgeGenderPredictor'\n",
    ")\n",
    "\n",
    "print(\"üë§ Multi-Output Model:\")\n",
    "multi_output_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîó Skip Connections (Like ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip connections help deep networks train better\n",
    "# Used in ResNet, UNet, and modern transformers\n",
    "\n",
    "inputs = layers.Input(shape=(32,))\n",
    "\n",
    "# First block\n",
    "x = layers.Dense(32, activation='relu')(inputs)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# Skip connection: Add input to output\n",
    "x = layers.Add()([inputs, x])  # ‚Üê This is the skip connection!\n",
    "\n",
    "# Second block\n",
    "y = layers.Dense(32, activation='relu')(x)\n",
    "y = layers.Dense(32, activation='relu')(y)\n",
    "\n",
    "# Another skip connection\n",
    "y = layers.Add()([x, y])\n",
    "\n",
    "# Output\n",
    "outputs = layers.Dense(10, activation='softmax')(y)\n",
    "\n",
    "skip_model = models.Model(inputs=inputs, outputs=outputs, name='ResidualNetwork')\n",
    "\n",
    "print(\"üîó Model with Skip Connections:\")\n",
    "skip_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Section 4: REAL AI EXAMPLE - Image Classifier\n",
    "\n",
    "**Project:** Build a Convolutional Neural Network (CNN) to classify handwritten digits (MNIST)\n",
    "\n",
    "**Real-World Applications:**\n",
    "- Check scanning (banks)\n",
    "- Postal code reading\n",
    "- Document digitization\n",
    "- Form processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset (70,000 handwritten digits)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"Training images: {X_train.shape}\")  # (60000, 28, 28)\n",
    "print(f\"Training labels: {y_train.shape}\")  # (60000,)\n",
    "print(f\"Test images: {X_test.shape}\")       # (10000, 28, 28)\n",
    "print(f\"Test labels: {y_test.shape}\")       # (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüñºÔ∏è These are real handwritten digits from the MNIST dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# 1. Reshape to add channel dimension (needed for CNN)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 2. Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Convert labels to one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"‚úÖ Preprocessed data shape: {X_train.shape}\")\n",
    "print(f\"‚úÖ One-hot labels shape: {y_train_cat.shape}\")\n",
    "print(f\"\\nExample label: {y_train[0]} ‚Üí One-hot: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Build CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Convolutional Neural Network (CNN)\n",
    "cnn_model = models.Sequential([\n",
    "    # Input layer\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    \n",
    "    # Convolutional Block 1\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Block 2\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Block 3\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Prevent overfitting\n",
    "    \n",
    "    # Output layer (10 classes: digits 0-9)\n",
    "    layers.Dense(10, activation='softmax')\n",
    "], name='MNIST_CNN')\n",
    "\n",
    "print(\"üñºÔ∏è CNN Architecture:\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üß† Layer Breakdown:**\n",
    "- **Conv2D**: Detects patterns (edges, curves)\n",
    "- **MaxPooling2D**: Reduces size, keeps important features\n",
    "- **Flatten**: Converts 2D to 1D for dense layers\n",
    "- **Dense**: Learns combinations of features\n",
    "- **Dropout**: Prevents overfitting by randomly dropping neurons\n",
    "- **Softmax**: Outputs probabilities for each class\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # For multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CNN Model compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Training the CNN...\\n\")\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=5,              # Train for 5 epochs (increase for better accuracy)\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nüìä Test Results:\")\n",
    "print(f\"   Loss: {test_loss:.4f}\")\n",
    "print(f\"   Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nüéâ Our model can recognize handwritten digits with high accuracy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÆ Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test images\n",
    "predictions = cnn_model.predict(X_test[:10])\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    predicted_digit = np.argmax(predictions[i])\n",
    "    true_digit = y_test[i]\n",
    "    confidence = np.max(predictions[i]) * 100\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if predicted_digit == true_digit else 'red'\n",
    "    \n",
    "    plt.title(f\"Pred: {predicted_digit}\\nTrue: {true_digit}\\n({confidence:.1f}%)\",\n",
    "              color=color, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Green = Correct, Red = Incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Section 5: Model Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "cnn_model.save('mnist_cnn_model.keras')\n",
    "print(\"‚úÖ Model saved as 'mnist_cnn_model.keras'\")\n",
    "\n",
    "# Save only weights\n",
    "cnn_model.save_weights('mnist_cnn_weights.weights.h5')\n",
    "print(\"‚úÖ Weights saved as 'mnist_cnn_weights.weights.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = keras.models.load_model('mnist_cnn_model.keras')\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Verify it works\n",
    "test_loss, test_accuracy = loaded_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"\\nLoaded model accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(\"üéâ Same accuracy - model loaded correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercise 1: Build Your Own Classifier\n",
    "\n",
    "**Challenge:** Build a neural network to classify fashion items (Fashion-MNIST)\n",
    "\n",
    "**Dataset:** 10 classes (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)\n",
    "\n",
    "**Your Task:**\n",
    "1. Load Fashion-MNIST dataset\n",
    "2. Build a CNN (similar to MNIST but customize it!)\n",
    "3. Train for 5 epochs\n",
    "4. Evaluate accuracy\n",
    "\n",
    "**Starter Code Below** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Fashion-MNIST Classifier\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Step 1: Load data\n",
    "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Step 2: Preprocess (normalize, reshape, one-hot encode)\n",
    "# YOUR CODE HERE\n",
    "X_train_fashion = X_train_fashion.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test_fashion = X_test_fashion.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train_fashion_cat = to_categorical(y_train_fashion, 10)\n",
    "y_test_fashion_cat = to_categorical(y_test_fashion, 10)\n",
    "\n",
    "# Step 3: Build your model\n",
    "# YOUR CODE HERE\n",
    "fashion_model = models.Sequential([\n",
    "    # Add layers here!\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    # TODO: Add Conv2D, MaxPooling, Dense layers\n",
    "])\n",
    "\n",
    "# Step 4: Compile\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 5: Train\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 6: Evaluate\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution to Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Fashion-MNIST Classifier\n",
    "\n",
    "# Data is already preprocessed above\n",
    "\n",
    "# Build model\n",
    "fashion_model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "], name='Fashion_MNIST_CNN')\n",
    "\n",
    "# Compile\n",
    "fashion_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"üöÄ Training Fashion-MNIST model...\\n\")\n",
    "fashion_history = fashion_model.fit(\n",
    "    X_train_fashion, y_train_fashion_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = fashion_model.evaluate(X_test_fashion, y_test_fashion_cat, verbose=0)\n",
    "print(f\"\\nüìä Fashion-MNIST Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercise 2: Multi-Input Model\n",
    "\n",
    "**Challenge:** Build a multi-input model that combines numerical and categorical features\n",
    "\n",
    "**Scenario:** Predict if a customer will buy a product based on:\n",
    "- Input 1: Numerical features (age, income, time_on_site)\n",
    "- Input 2: Categorical features (embedded customer segment)\n",
    "\n",
    "**Hint:** Use Functional API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Multi-Input Model\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Numerical features\n",
    "numerical_data = np.random.randn(n_samples, 3)\n",
    "\n",
    "# Categorical features (already embedded)\n",
    "categorical_data = np.random.randn(n_samples, 5)\n",
    "\n",
    "# Labels\n",
    "labels = np.random.randint(0, 2, size=(n_samples, 1))\n",
    "\n",
    "# TODO: Build a multi-input model using Functional API\n",
    "# Input 1: numerical_input (shape: 3)\n",
    "# Input 2: categorical_input (shape: 5)\n",
    "# Combine them and output binary prediction\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution to Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Multi-Input Model\n",
    "\n",
    "# Input 1: Numerical features\n",
    "numerical_input = layers.Input(shape=(3,), name='numerical')\n",
    "x1 = layers.Dense(16, activation='relu')(numerical_input)\n",
    "x1 = layers.Dense(8, activation='relu')(x1)\n",
    "\n",
    "# Input 2: Categorical features\n",
    "categorical_input = layers.Input(shape=(5,), name='categorical')\n",
    "x2 = layers.Dense(16, activation='relu')(categorical_input)\n",
    "x2 = layers.Dense(8, activation='relu')(x2)\n",
    "\n",
    "# Combine\n",
    "combined = layers.concatenate([x1, x2])\n",
    "z = layers.Dense(16, activation='relu')(combined)\n",
    "output = layers.Dense(1, activation='sigmoid', name='output')(z)\n",
    "\n",
    "# Create model\n",
    "multi_model = models.Model(\n",
    "    inputs=[numerical_input, categorical_input],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "# Compile\n",
    "multi_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "multi_model.fit(\n",
    "    [numerical_data, categorical_data],\n",
    "    labels,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-input model trained successfully!\")\n",
    "multi_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "**You just learned:**\n",
    "- ‚úÖ TensorFlow/Keras basics and tensor operations\n",
    "- ‚úÖ Sequential API for simple models\n",
    "- ‚úÖ Functional API for complex architectures\n",
    "- ‚úÖ Building and training CNN for image classification\n",
    "- ‚úÖ Multi-input and multi-output models\n",
    "- ‚úÖ Skip connections (ResNet-style)\n",
    "- ‚úÖ Saving and loading models\n",
    "\n",
    "**üî• Real-World Skills:**\n",
    "- Build multimodal AI systems (text + images)\n",
    "- Create production-ready image classifiers\n",
    "- Design complex neural network architectures\n",
    "- Deploy models for real applications\n",
    "\n",
    "**üéØ Practice Challenges:**\n",
    "1. Increase CNN epochs to 10 and beat 99% accuracy on MNIST\n",
    "2. Add data augmentation to Fashion-MNIST\n",
    "3. Build a 3-input model (numerical + categorical + image)\n",
    "4. Implement a ResNet-style network with skip connections\n",
    "\n",
    "---\n",
    "\n",
    "**üìö Next Lesson:** Day 2 - Introduction to PyTorch (Learn the other major framework!)\n",
    "\n",
    "**üí¨ Questions?** Experiment with different architectures, layer sizes, and activation functions!\n",
    "\n",
    "---\n",
    "\n",
    "*Remember: TensorFlow powers real-world AI systems at Google, Uber, Airbnb, and thousands of companies worldwide!* üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
