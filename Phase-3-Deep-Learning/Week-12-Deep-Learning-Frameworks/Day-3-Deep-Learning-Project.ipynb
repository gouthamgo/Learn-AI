{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Day 3: Deep Learning Project - Fashion Item Classifier\n",
    "\n",
    "**üéØ Goal:** Build a complete end-to-end deep learning project from scratch\n",
    "\n",
    "**‚è±Ô∏è Time:** 90-120 minutes\n",
    "\n",
    "**üåü Why This Matters for AI:**\n",
    "- Learn the COMPLETE workflow: data ‚Üí training ‚Üí deployment\n",
    "- Build a production-ready image classifier\n",
    "- Master best practices for real-world AI projects\n",
    "- Portfolio project you can showcase to employers\n",
    "\n",
    "**üî• Real-World Applications:**\n",
    "- E-commerce: Automatic product categorization\n",
    "- Fashion retail: Visual search and recommendations\n",
    "- Inventory management: Automated item classification\n",
    "- Quality control: Defect detection in manufacturing\n",
    "\n",
    "**üéØ Project Overview:**\n",
    "- Dataset: Fashion-MNIST (70,000 grayscale images of clothing)\n",
    "- Task: Classify 10 fashion categories\n",
    "- Both TensorFlow and PyTorch implementations\n",
    "- Complete pipeline: preprocessing ‚Üí training ‚Üí evaluation ‚Üí deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Project Roadmap\n",
    "\n",
    "**Phase 1: Data Loading & Exploration**\n",
    "- Load Fashion-MNIST dataset\n",
    "- Visualize samples\n",
    "- Understand class distribution\n",
    "\n",
    "**Phase 2: Data Preprocessing**\n",
    "- Normalize images\n",
    "- Reshape for CNN input\n",
    "- Split train/validation/test sets\n",
    "- Create data loaders\n",
    "\n",
    "**Phase 3: Model Architecture**\n",
    "- Design CNN architecture\n",
    "- Implement in both TensorFlow and PyTorch\n",
    "- Compare approaches\n",
    "\n",
    "**Phase 4: Training**\n",
    "- Set up training loop\n",
    "- Monitor metrics\n",
    "- Implement early stopping\n",
    "- Visualize training progress\n",
    "\n",
    "**Phase 5: Evaluation**\n",
    "- Test set performance\n",
    "- Confusion matrix\n",
    "- Per-class accuracy\n",
    "- Error analysis\n",
    "\n",
    "**Phase 6: Model Deployment**\n",
    "- Save models\n",
    "- Load for inference\n",
    "- Make predictions on new images\n",
    "- Export for production\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install tensorflow torch torchvision numpy matplotlib scikit-learn seaborn\n",
    "\n",
    "# Import TensorFlow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Import utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check versions\n",
    "print(\"=\"*60)\n",
    "print(\"Environment Setup\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Phase 1: Data Loading & Exploration\n",
    "\n",
    "**Fashion-MNIST Dataset:**\n",
    "- 70,000 grayscale images (60,000 train + 10,000 test)\n",
    "- Size: 28x28 pixels\n",
    "- 10 classes of fashion items\n",
    "- Created by Zalando Research\n",
    "- Drop-in replacement for MNIST\n",
    "\n",
    "**Classes:**\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set: {X_train_full.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Image shape: {X_train_full[0].shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train_full))}\")\n",
    "print(f\"Pixel value range: [{X_train_full.min()}, {X_train_full.max()}]\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(\"\\nClasses:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from each class\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(10):\n",
    "    # Get random sample from class i\n",
    "    idx = np.where(y_train_full == i)[0]\n",
    "    random_idx = np.random.choice(idx, 5, replace=False)\n",
    "    \n",
    "    for j, sample_idx in enumerate(random_idx):\n",
    "        plt.subplot(10, 5, i*5 + j + 1)\n",
    "        plt.imshow(X_train_full[sample_idx], cmap='gray')\n",
    "        if j == 0:\n",
    "            plt.ylabel(class_names[i], fontsize=12, rotation=0, \n",
    "                      ha='right', va='center')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.suptitle('Fashion-MNIST: 5 Random Samples per Class', fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "unique, counts = np.unique(y_train_full, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar([class_names[i] for i in unique], counts, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add counts on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Pie chart\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(counts, labels=[class_names[i] for i in unique], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Class Distribution (%)')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check if balanced\n",
    "is_balanced = np.std(counts) < 100\n",
    "print(f\"\\n{'‚úÖ' if is_balanced else '‚ö†Ô∏è'} Dataset is {'balanced' if is_balanced else 'imbalanced'}\")\n",
    "print(f\"Standard deviation: {np.std(counts):.2f} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Pixel Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pixel value distribution\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Sample image\n",
    "plt.subplot(1, 3, 1)\n",
    "sample_idx = 42\n",
    "plt.imshow(X_train_full[sample_idx], cmap='gray')\n",
    "plt.title(f'Sample Image: {class_names[y_train_full[sample_idx]]}')\n",
    "plt.axis('off')\n",
    "\n",
    "# Histogram of pixel values\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(X_train_full[sample_idx].flatten(), bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Pixel Value Distribution')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Overall statistics\n",
    "plt.subplot(1, 3, 3)\n",
    "stats_text = f\"\"\"\n",
    "Dataset Statistics:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Mean: {X_train_full.mean():.2f}\n",
    "Std: {X_train_full.std():.2f}\n",
    "Min: {X_train_full.min()}\n",
    "Max: {X_train_full.max()}\n",
    "\n",
    "Shape: {X_train_full.shape}\n",
    "Dtype: {X_train_full.dtype}\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, stats_text, fontsize=12, family='monospace',\n",
    "         verticalalignment='center')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Phase 2: Data Preprocessing\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "1. ‚úÖ Normalize pixel values to [0, 1]\n",
    "2. ‚úÖ Reshape for CNN input (add channel dimension)\n",
    "3. ‚úÖ Split into train/validation sets\n",
    "4. ‚úÖ Convert labels to one-hot encoding (TensorFlow)\n",
    "5. ‚úÖ Create data loaders (PyTorch)\n",
    "\n",
    "**Why Normalize?**\n",
    "- Faster convergence\n",
    "- Better gradient flow\n",
    "- Prevents numerical instability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train = X_train_full[:-10000]\n",
    "X_val = X_train_full[-10000:]\n",
    "y_train = y_train_full[:-10000]\n",
    "y_val = y_train_full[-10000:]\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Validation: {X_val.shape[0]:,} samples\")\n",
    "print(f\"Test: {X_test.shape[0]:,} samples\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ TensorFlow Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow preprocessing\n",
    "print(\"\\nüîµ TensorFlow Preprocessing:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "X_train_tf = X_train.astype('float32') / 255.0\n",
    "X_val_tf = X_val.astype('float32') / 255.0\n",
    "X_test_tf = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for CNN (add channel dimension)\n",
    "X_train_tf = X_train_tf.reshape(-1, 28, 28, 1)\n",
    "X_val_tf = X_val_tf.reshape(-1, 28, 28, 1)\n",
    "X_test_tf = X_test_tf.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_tf = to_categorical(y_train, 10)\n",
    "y_val_tf = to_categorical(y_val, 10)\n",
    "y_test_tf = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"‚úÖ Input shape: {X_train_tf.shape}\")\n",
    "print(f\"‚úÖ Label shape: {y_train_tf.shape}\")\n",
    "print(f\"‚úÖ Pixel range: [{X_train_tf.min()}, {X_train_tf.max()}]\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî• PyTorch Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch preprocessing\n",
    "print(\"\\nüî• PyTorch Preprocessing:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "X_train_pt = torch.FloatTensor(X_train) / 255.0\n",
    "X_val_pt = torch.FloatTensor(X_val) / 255.0\n",
    "X_test_pt = torch.FloatTensor(X_test) / 255.0\n",
    "\n",
    "# Reshape for CNN (PyTorch uses channels-first: N, C, H, W)\n",
    "X_train_pt = X_train_pt.unsqueeze(1)  # Add channel dimension\n",
    "X_val_pt = X_val_pt.unsqueeze(1)\n",
    "X_test_pt = X_test_pt.unsqueeze(1)\n",
    "\n",
    "# Convert labels to tensors\n",
    "y_train_pt = torch.LongTensor(y_train)\n",
    "y_val_pt = torch.LongTensor(y_val)\n",
    "y_test_pt = torch.LongTensor(y_test)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_pt, y_train_pt)\n",
    "val_dataset = TensorDataset(X_val_pt, y_val_pt)\n",
    "test_dataset = TensorDataset(X_test_pt, y_test_pt)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Input shape: {X_train_pt.shape}\")\n",
    "print(f\"‚úÖ Label shape: {y_train_pt.shape}\")\n",
    "print(f\"‚úÖ Pixel range: [{X_train_pt.min()}, {X_train_pt.max()}]\")\n",
    "print(f\"‚úÖ Batch size: 128\")\n",
    "print(f\"‚úÖ Number of batches: {len(train_loader)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Phase 3: Model Architecture\n",
    "\n",
    "**CNN Architecture Design:**\n",
    "- 3 Convolutional blocks (each with Conv2D + MaxPooling)\n",
    "- Batch Normalization for faster training\n",
    "- Dropout for regularization\n",
    "- Dense layers for classification\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (28x28x1)\n",
    "    ‚Üì\n",
    "Conv2D(32) + ReLU + BatchNorm + MaxPool ‚Üí (14x14x32)\n",
    "    ‚Üì\n",
    "Conv2D(64) + ReLU + BatchNorm + MaxPool ‚Üí (7x7x64)\n",
    "    ‚Üì\n",
    "Conv2D(128) + ReLU + BatchNorm + MaxPool ‚Üí (3x3x128)\n",
    "    ‚Üì\n",
    "Flatten ‚Üí 1152\n",
    "    ‚Üì\n",
    "Dense(256) + ReLU + Dropout(0.5)\n",
    "    ‚Üì\n",
    "Dense(128) + ReLU + Dropout(0.5)\n",
    "    ‚Üì\n",
    "Dense(10) + Softmax\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TensorFlow/Keras model\n",
    "def create_tensorflow_model():\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ], name='FashionCNN_TensorFlow')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "tf_model = create_tensorflow_model()\n",
    "\n",
    "# Compile model\n",
    "tf_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"üîµ TensorFlow Model:\")\n",
    "print(\"=\"*60)\n",
    "tf_model.summary()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî• PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build PyTorch model\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Conv Block 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Conv Block 3\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pt_model = FashionCNN().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pt_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\nüî• PyTorch Model:\")\n",
    "print(\"=\"*60)\n",
    "print(pt_model)\n",
    "print(\"=\"*60)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in pt_model.parameters()):,}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Phase 4: Training\n",
    "\n",
    "**Training Configuration:**\n",
    "- Optimizer: Adam\n",
    "- Learning rate: 0.001\n",
    "- Batch size: 128\n",
    "- Epochs: 20 (with early stopping)\n",
    "- Early stopping patience: 3 epochs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ Train TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_fashion_model_tf.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"üöÄ Training TensorFlow Model...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "tf_history = tf_model.fit(\n",
    "    X_train_tf, y_train_tf,\n",
    "    validation_data=(X_val_tf, y_val_tf),\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tf_training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {tf_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî• Train PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_pytorch_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, patience=3):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_y.size(0)\n",
    "            train_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += batch_y.size(0)\n",
    "                val_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        # Calculate averages\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_fashion_model_pt.pth')\n",
    "            print(\"‚úÖ Model saved (best validation loss)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train model\n",
    "print(\"üöÄ Training PyTorch Model...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "pt_history = train_pytorch_model(\n",
    "    pt_model, train_loader, val_loader,\n",
    "    criterion, optimizer,\n",
    "    num_epochs=20, patience=3\n",
    ")\n",
    "\n",
    "pt_training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {pt_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Training Progress Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# TensorFlow - Loss\n",
    "axes[0, 0].plot(tf_history.history['loss'], label='Train Loss', marker='o')\n",
    "axes[0, 0].plot(tf_history.history['val_loss'], label='Val Loss', marker='o')\n",
    "axes[0, 0].set_title('TensorFlow: Training & Validation Loss', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# TensorFlow - Accuracy\n",
    "axes[0, 1].plot(tf_history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "axes[0, 1].plot(tf_history.history['val_accuracy'], label='Val Accuracy', marker='o')\n",
    "axes[0, 1].set_title('TensorFlow: Training & Validation Accuracy', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# PyTorch - Loss\n",
    "axes[1, 0].plot(pt_history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[1, 0].plot(pt_history['val_loss'], label='Val Loss', marker='o')\n",
    "axes[1, 0].set_title('PyTorch: Training & Validation Loss', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# PyTorch - Accuracy\n",
    "axes[1, 1].plot(pt_history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1, 1].plot(pt_history['val_acc'], label='Val Accuracy', marker='o')\n",
    "axes[1, 1].set_title('PyTorch: Training & Validation Accuracy', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TensorFlow training time: {tf_training_time:.2f} seconds\")\n",
    "print(f\"PyTorch training time: {pt_training_time:.2f} seconds\")\n",
    "print(f\"\\nFinal TensorFlow validation accuracy: {tf_history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Final PyTorch validation accuracy: {pt_history['val_acc'][-1]:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Phase 5: Evaluation\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Test accuracy\n",
    "- Per-class accuracy\n",
    "- Confusion matrix\n",
    "- Classification report (precision, recall, F1-score)\n",
    "- Error analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ Evaluate TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üîµ TensorFlow Model Evaluation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tf_test_loss, tf_test_acc = tf_model.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print(f\"Test Loss: {tf_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {tf_test_acc*100:.2f}%\")\n",
    "\n",
    "# Get predictions\n",
    "tf_predictions = tf_model.predict(X_test_tf, verbose=0)\n",
    "tf_pred_classes = np.argmax(tf_predictions, axis=1)\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî• Evaluate PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "pt_model.load_state_dict(torch.load('best_fashion_model_pt.pth'))\n",
    "pt_model.eval()\n",
    "\n",
    "print(\"\\nüî• PyTorch Model Evaluation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "pt_pred_classes = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = pt_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += batch_y.size(0)\n",
    "        test_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        pt_pred_classes.extend(predicted.cpu().numpy())\n",
    "\n",
    "pt_test_loss = test_loss / len(test_loader)\n",
    "pt_test_acc = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {pt_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {pt_test_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices\n",
    "tf_cm = confusion_matrix(y_test, tf_pred_classes)\n",
    "pt_cm = confusion_matrix(y_test, pt_pred_classes)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# TensorFlow confusion matrix\n",
    "sns.heatmap(tf_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('TensorFlow: Confusion Matrix', fontsize=14)\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "plt.setp(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# PyTorch confusion matrix\n",
    "sns.heatmap(pt_cm, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=axes[1], cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title('PyTorch: Confusion Matrix', fontsize=14)\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà Per-Class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "print(\"\\nüîµ TensorFlow Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, tf_pred_classes, target_names=class_names))\n",
    "\n",
    "print(\"\\nüî• PyTorch Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, pt_pred_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "tf_class_acc = tf_cm.diagonal() / tf_cm.sum(axis=1) * 100\n",
    "pt_class_acc = pt_cm.diagonal() / pt_cm.sum(axis=1) * 100\n",
    "\n",
    "# Plot per-class accuracy\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "bars1 = ax.bar(x - width/2, tf_class_acc, width, label='TensorFlow', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, pt_class_acc, width, label='PyTorch', color='darkorange')\n",
    "\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Per-Class Accuracy Comparison', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nPer-Class Accuracy Statistics:\")\n",
    "print(\"=\"*60)\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{name:15} - TF: {tf_class_acc[i]:5.2f}% | PT: {pt_class_acc[i]:5.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified examples (using TensorFlow predictions)\n",
    "misclassified_idx = np.where(tf_pred_classes != y_test)[0]\n",
    "\n",
    "print(f\"Total misclassified: {len(misclassified_idx)} out of {len(y_test)} ({len(misclassified_idx)/len(y_test)*100:.2f}%)\\n\")\n",
    "\n",
    "# Visualize some misclassified examples\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, idx in enumerate(misclassified_idx[:20]):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_test[idx], cmap='gray')\n",
    "    \n",
    "    true_label = class_names[y_test[idx]]\n",
    "    pred_label = class_names[tf_pred_classes[idx]]\n",
    "    confidence = tf_predictions[idx][tf_pred_classes[idx]] * 100\n",
    "    \n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\",\n",
    "              fontsize=9, color='red')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Misclassified Examples (TensorFlow)', fontsize=16, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Phase 6: Model Deployment\n",
    "\n",
    "**Deployment Steps:**\n",
    "1. Save trained models\n",
    "2. Create inference functions\n",
    "3. Test on new images\n",
    "4. Export for production\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TensorFlow model\n",
    "tf_model.save('fashion_classifier_tf.keras')\n",
    "print(\"‚úÖ TensorFlow model saved as 'fashion_classifier_tf.keras'\")\n",
    "\n",
    "# Save PyTorch model\n",
    "torch.save({\n",
    "    'model_state_dict': pt_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_names': class_names\n",
    "}, 'fashion_classifier_pt.pth')\n",
    "print(\"‚úÖ PyTorch model saved as 'fashion_classifier_pt.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÆ Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow inference function\n",
    "def predict_tensorflow(image, model):\n",
    "    \"\"\"\n",
    "    Predict fashion item class using TensorFlow model.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (28x28 grayscale)\n",
    "        model: Trained TensorFlow model\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class: Predicted class name\n",
    "        confidence: Prediction confidence (0-1)\n",
    "        probabilities: All class probabilities\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    if len(image.shape) == 2:\n",
    "        image = image.reshape(1, 28, 28, 1)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(image, verbose=0)[0]\n",
    "    predicted_idx = np.argmax(predictions)\n",
    "    \n",
    "    return class_names[predicted_idx], predictions[predicted_idx], predictions\n",
    "\n",
    "# PyTorch inference function\n",
    "def predict_pytorch(image, model):\n",
    "    \"\"\"\n",
    "    Predict fashion item class using PyTorch model.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (28x28 grayscale)\n",
    "        model: Trained PyTorch model\n",
    "    \n",
    "    Returns:\n",
    "        predicted_class: Predicted class name\n",
    "        confidence: Prediction confidence (0-1)\n",
    "        probabilities: All class probabilities\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess\n",
    "    if len(image.shape) == 2:\n",
    "        image = torch.FloatTensor(image).unsqueeze(0).unsqueeze(0)\n",
    "    image = image / 255.0\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_idx = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return class_names[predicted_idx], probabilities[predicted_idx].item(), probabilities.cpu().numpy()\n",
    "\n",
    "print(\"‚úÖ Inference functions created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on random samples\n",
    "test_indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, idx in enumerate(test_indices):\n",
    "    # Get predictions\n",
    "    tf_pred, tf_conf, tf_probs = predict_tensorflow(X_test[idx], tf_model)\n",
    "    pt_pred, pt_conf, pt_probs = predict_pytorch(X_test[idx], pt_model)\n",
    "    \n",
    "    # Plot image\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[idx], cmap='gray')\n",
    "    \n",
    "    true_label = class_names[y_test[idx]]\n",
    "    color = 'green' if tf_pred == true_label else 'red'\n",
    "    \n",
    "    title = f\"True: {true_label}\\n\"\n",
    "    title += f\"TF: {tf_pred} ({tf_conf*100:.1f}%)\\n\"\n",
    "    title += f\"PT: {pt_pred} ({pt_conf*100:.1f}%)\"\n",
    "    \n",
    "    plt.title(title, fontsize=9, color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Model Predictions Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Green = Correct, Red = Incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercise 1: Improve the Model\n",
    "\n",
    "**Challenge:** Can you beat the baseline models?\n",
    "\n",
    "**Ideas to try:**\n",
    "1. Add more convolutional layers\n",
    "2. Increase filters (32 ‚Üí 64 ‚Üí 128 ‚Üí 256)\n",
    "3. Add data augmentation (rotation, flip, zoom)\n",
    "4. Try different optimizers (SGD with momentum, RMSprop)\n",
    "5. Adjust learning rate\n",
    "6. Add more dense layers\n",
    "7. Try different batch sizes\n",
    "8. Implement learning rate scheduling\n",
    "\n",
    "**Your Turn!** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Improve the model\n",
    "# TODO: Build your improved model here\n",
    "\n",
    "# Ideas:\n",
    "# - Add data augmentation\n",
    "# - Deeper network\n",
    "# - Different architecture (ResNet-style, etc.)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Interactive Exercise 2: Build a Web App\n",
    "\n",
    "**Challenge:** Create a simple web interface for your model\n",
    "\n",
    "**Steps:**\n",
    "1. Use Gradio or Streamlit\n",
    "2. Load your trained model\n",
    "3. Accept image uploads\n",
    "4. Display predictions with confidence scores\n",
    "5. Show top-3 predictions\n",
    "\n",
    "**Starter Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Web App (optional)\n",
    "# Uncomment and run:\n",
    "\n",
    "# !pip install gradio\n",
    "# import gradio as gr\n",
    "\n",
    "# def classify_fashion_item(image):\n",
    "#     # Preprocess image\n",
    "#     # Make prediction\n",
    "#     # Return result\n",
    "#     pass\n",
    "\n",
    "# interface = gr.Interface(\n",
    "#     fn=classify_fashion_item,\n",
    "#     inputs=gr.Image(shape=(28, 28)),\n",
    "#     outputs=\"text\",\n",
    "#     title=\"Fashion Item Classifier\"\n",
    "# )\n",
    "\n",
    "# interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "**You just built a complete end-to-end deep learning project!**\n",
    "\n",
    "**What you accomplished:**\n",
    "- ‚úÖ Loaded and explored a real-world dataset\n",
    "- ‚úÖ Preprocessed data for deep learning\n",
    "- ‚úÖ Built CNN models in BOTH TensorFlow and PyTorch\n",
    "- ‚úÖ Trained models with early stopping\n",
    "- ‚úÖ Evaluated performance with multiple metrics\n",
    "- ‚úÖ Created confusion matrices and error analysis\n",
    "- ‚úÖ Saved models for deployment\n",
    "- ‚úÖ Built inference functions\n",
    "- ‚úÖ Compared TensorFlow vs PyTorch\n",
    "\n",
    "**üî• Real-World Skills:**\n",
    "- Production-ready image classification\n",
    "- Complete ML pipeline development\n",
    "- Model evaluation and debugging\n",
    "- Framework comparison (TensorFlow vs PyTorch)\n",
    "- Deployment preparation\n",
    "\n",
    "**üìä Project Results:**\n",
    "- Trained 2 high-accuracy fashion classifiers\n",
    "- Achieved ~90%+ test accuracy\n",
    "- Identified which classes are hardest to classify\n",
    "- Ready-to-deploy models\n",
    "\n",
    "**üéØ Next Steps:**\n",
    "1. Deploy to cloud (AWS, GCP, Azure)\n",
    "2. Create REST API with FastAPI\n",
    "3. Build mobile app with TensorFlow Lite\n",
    "4. Try transfer learning with pre-trained models\n",
    "5. Experiment with other datasets (CIFAR-10, ImageNet)\n",
    "\n",
    "**üî• 2024-2025 Applications:**\n",
    "- E-commerce visual search\n",
    "- Automated inventory management\n",
    "- Fashion recommendation systems\n",
    "- Quality control in manufacturing\n",
    "- Multimodal AI (combine with text descriptions)\n",
    "\n",
    "**üíº Portfolio Project:**\n",
    "- Add to GitHub with README\n",
    "- Deploy as web app\n",
    "- Showcase in job interviews\n",
    "- Write a blog post about it\n",
    "\n",
    "---\n",
    "\n",
    "**üìö What's Next:**\n",
    "- Week 13: Transfer Learning & Pre-trained Models\n",
    "- Week 14: Advanced CNN Architectures (ResNet, EfficientNet)\n",
    "- Week 15: Recurrent Neural Networks & LSTMs\n",
    "- Week 16: Transformers & Attention Mechanisms\n",
    "\n",
    "**üí¨ Share Your Project:**\n",
    "- Tweet your results with #100DaysOfCode\n",
    "- Post on LinkedIn\n",
    "- Share on GitHub\n",
    "- Help others learn!\n",
    "\n",
    "---\n",
    "\n",
    "*Remember: You now have a complete deep learning project in your portfolio. This is EXACTLY what employers want to see!* üöÄ\n",
    "\n",
    "**Keep learning, keep building, keep shipping!** üí™"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
