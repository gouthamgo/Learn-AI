{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# üöÄ Week 3, Day 3: Interactive Visualizations\n",
    "\n",
    "**üéØ Goal:** Create stunning interactive visualizations and AI dashboards with Plotly\n",
    "\n",
    "**‚è±Ô∏è Time:** 60-90 minutes\n",
    "\n",
    "**üåü Why This Matters for AI:**\n",
    "- **Interactive exploration** - Zoom, pan, hover for insights\n",
    "- **Real-time dashboards** - Monitor AI models in production\n",
    "- **Stakeholder communication** - Impress non-technical audiences\n",
    "- **Web deployment** - Share interactive reports online\n",
    "- **3D visualization** - Explore high-dimensional data\n",
    "\n",
    "---\n",
    "\n",
    "## üî• 2024-2025 AI Trend Alert!\n",
    "\n",
    "**AI Observability** is now ESSENTIAL:\n",
    "- Monitor LLM costs, latency, quality in real-time\n",
    "- **Interactive dashboards track production AI systems!**\n",
    "- Companies like Langsmith, W&B, Arize use Plotly\n",
    "\n",
    "**Agentic AI** requires real-time monitoring:\n",
    "- Track autonomous agent decisions\n",
    "- Visualize multi-step reasoning chains\n",
    "- **Interactive plots show agent behavior patterns!**\n",
    "\n",
    "**Multimodal AI Debugging**:\n",
    "- Explore relationships between text, image, audio embeddings\n",
    "- **3D scatter plots visualize embedding spaces!**\n",
    "\n",
    "**You'll build dashboards like those at OpenAI, Anthropic, Google DeepMind!** üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üìä What is Plotly?\n",
    "\n",
    "**Plotly** = Interactive, web-based visualizations\n",
    "\n",
    "Think of it as:\n",
    "- Matplotlib: Static images üì∑\n",
    "- Plotly: Interactive web apps üåê\n",
    "\n",
    "**Key superpowers:**\n",
    "- **Hover** to see exact values\n",
    "- **Zoom** into interesting regions\n",
    "- **Pan** around your data\n",
    "- **Click** legends to show/hide\n",
    "- **Export** to PNG, SVG, HTML\n",
    "- **Deploy** to web with one click\n",
    "\n",
    "Let's make your first interactive plot! ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Plotly (if needed)\n",
    "# !pip install plotly\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Plotly version:\", px.__version__)\n",
    "print(\"‚úÖ Ready to create interactive visualizations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## üé® Your First Interactive Plot - One Line of Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI model training data\n",
    "training_data = pd.DataFrame({\n",
    "    'Epoch': np.arange(1, 51),\n",
    "    'Training_Loss': 2.5 * np.exp(-0.08 * np.arange(1, 51)) + 0.1 * np.random.randn(50),\n",
    "    'Validation_Loss': 2.5 * np.exp(-0.07 * np.arange(1, 51)) + 0.15 * np.random.randn(50),\n",
    "    'Learning_Rate': 0.001 * 0.95 ** np.arange(1, 51)\n",
    "})\n",
    "\n",
    "# Create interactive line plot\n",
    "fig = px.line(training_data, x='Epoch', y=['Training_Loss', 'Validation_Loss'],\n",
    "             title='ü§ñ Interactive AI Training Monitor',\n",
    "             labels={'value': 'Loss', 'variable': 'Type'})\n",
    "\n",
    "fig.update_layout(hovermode='x unified')  # Unified hover tooltip\n",
    "fig.show()\n",
    "\n",
    "print(\"üéâ Try it:\")\n",
    "print(\"  - Hover over the line to see exact values\")\n",
    "print(\"  - Double-click legend items to isolate\")\n",
    "print(\"  - Single-click legend to show/hide\")\n",
    "print(\"  - Use toolbar to zoom, pan, reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## üìà Interactive Scatter Plots - Explore Data Relationships\n",
    "\n",
    "### 1Ô∏è‚É£ Basic Interactive Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model specifications\n",
    "np.random.seed(42)\n",
    "models_df = pd.DataFrame({\n",
    "    'Model': ['GPT-4', 'Claude-3.5-Sonnet', 'Gemini-1.5-Pro', 'Llama-3.1-405B', \n",
    "             'GPT-3.5', 'Claude-3-Haiku', 'Gemini-1.5-Flash', 'Llama-3.1-70B',\n",
    "             'GPT-4-Turbo', 'Mistral-Large', 'Command-R+', 'Phi-3'],\n",
    "    'Parameters_B': [1800, 200, 540, 405, 175, 50, 100, 70, 1800, 176, 104, 14],\n",
    "    'Benchmark_Score': [95, 94, 92, 89, 85, 88, 87, 86, 94, 88, 87, 82],\n",
    "    'Cost_per_1M_tokens': [30, 15, 7, 5, 2, 1.5, 2.5, 3, 20, 8, 5, 1],\n",
    "    'Release_Year': [2023, 2024, 2024, 2024, 2022, 2024, 2024, 2024, 2023, 2024, 2024, 2024],\n",
    "    'Category': ['Frontier', 'Frontier', 'Frontier', 'Open', \n",
    "                'Legacy', 'Fast', 'Fast', 'Open',\n",
    "                'Frontier', 'Specialized', 'Specialized', 'Efficient']\n",
    "})\n",
    "\n",
    "# Create interactive scatter with multiple features\n",
    "fig = px.scatter(models_df, \n",
    "                x='Cost_per_1M_tokens', \n",
    "                y='Benchmark_Score',\n",
    "                size='Parameters_B',  # Bubble size\n",
    "                color='Category',  # Color by category\n",
    "                hover_name='Model',  # Show on hover\n",
    "                hover_data={'Parameters_B': ':.0f', 'Release_Year': True},\n",
    "                title='üîç LLM Performance vs Cost Analysis (2024)',\n",
    "                labels={'Cost_per_1M_tokens': 'Cost per 1M Tokens ($)',\n",
    "                       'Benchmark_Score': 'Performance Score'})\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "print(\"üí° Insights:\")\n",
    "print(\"  - Frontier models: High performance, high cost\")\n",
    "print(\"  - Efficient models: Good performance/cost ratio\")\n",
    "print(\"  - Try hovering to see each model's details!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Animated Scatter - Show Trends Over Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create historical data (2020-2024)\n",
    "historical_data = pd.DataFrame({\n",
    "    'Year': np.repeat([2020, 2021, 2022, 2023, 2024], 5),\n",
    "    'Model': ['GPT-3', 'BERT', 'T5', 'RoBERTa', 'XLNet'] * 5,\n",
    "    'Parameters_B': np.array([175, 110, 11, 125, 54] * 5) * np.repeat([1, 1.1, 1.2, 1.3, 1.4], 5),\n",
    "    'Benchmark_Score': np.array([70, 65, 68, 72, 66]) + np.repeat([0, 3, 6, 10, 15], 5) + np.random.randn(25),\n",
    "    'Category': ['LLM', 'Encoder', 'Seq2Seq', 'Encoder', 'Encoder'] * 5\n",
    "})\n",
    "\n",
    "# Create animated scatter\n",
    "fig = px.scatter(historical_data,\n",
    "                x='Parameters_B',\n",
    "                y='Benchmark_Score',\n",
    "                animation_frame='Year',  # Animate over years!\n",
    "                animation_group='Model',  # Group by model\n",
    "                size='Parameters_B',\n",
    "                color='Category',\n",
    "                hover_name='Model',\n",
    "                title='üìà AI Model Evolution (2020-2024)',\n",
    "                range_x=[0, 300],\n",
    "                range_y=[60, 95])\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "print(\"üé¨ Press PLAY to see AI evolution over time!\")\n",
    "print(\"   Notice: Models get bigger AND smarter each year!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## üìä Interactive Bar Charts & Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AI usage statistics\n",
    "usage_stats = pd.DataFrame({\n",
    "    'Use_Case': ['Code Generation', 'Content Writing', 'Data Analysis', \n",
    "                'Customer Support', 'Research', 'Translation', 'Summarization'],\n",
    "    'GPT-4': [92, 88, 85, 90, 94, 89, 91],\n",
    "    'Claude-3.5': [94, 96, 87, 88, 92, 87, 93],\n",
    "    'Gemini-Pro': [90, 85, 90, 86, 88, 91, 89]\n",
    "})\n",
    "\n",
    "usage_long = usage_stats.melt(id_vars='Use_Case', var_name='Model', value_name='Score')\n",
    "\n",
    "# Interactive grouped bar chart\n",
    "fig = px.bar(usage_long,\n",
    "            x='Use_Case',\n",
    "            y='Score',\n",
    "            color='Model',\n",
    "            barmode='group',  # Grouped bars\n",
    "            title='üéØ LLM Performance Across Use Cases',\n",
    "            labels={'Score': 'Performance Score', 'Use_Case': 'Use Case'})\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"üé® Try clicking legend items to compare models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## üå°Ô∏è Interactive Heatmaps - Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature correlation matrix for ML model\n",
    "features = ['Age', 'Income', 'Credit_Score', 'Debt_Ratio', 'Loan_Amount', 'Interest_Rate']\n",
    "correlation_matrix = np.array([\n",
    "    [1.00, 0.45, 0.62, -0.23, 0.38, -0.15],\n",
    "    [0.45, 1.00, 0.78, -0.45, 0.68, -0.52],\n",
    "    [0.62, 0.78, 1.00, -0.67, 0.42, -0.71],\n",
    "    [-0.23, -0.45, -0.67, 1.00, -0.15, 0.82],\n",
    "    [0.38, 0.68, 0.42, -0.15, 1.00, -0.34],\n",
    "    [-0.15, -0.52, -0.71, 0.82, -0.34, 1.00]\n",
    "])\n",
    "\n",
    "# Create interactive heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=correlation_matrix,\n",
    "    x=features,\n",
    "    y=features,\n",
    "    colorscale='RdBu',\n",
    "    zmid=0,  # Center colorscale at 0\n",
    "    text=correlation_matrix,\n",
    "    texttemplate='%{text:.2f}',\n",
    "    textfont={\"size\": 12},\n",
    "    colorbar=dict(title=\"Correlation\")\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üî• Feature Correlation Matrix - Loan Prediction Model',\n",
    "    xaxis_title='Features',\n",
    "    yaxis_title='Features',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üí° Feature engineering insights:\")\n",
    "print(\"  - Strong positive: Income ‚Üî Credit_Score (0.78)\")\n",
    "print(\"  - Strong negative: Credit_Score ‚Üî Interest_Rate (-0.71)\")\n",
    "print(\"  - Hover to see exact correlations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## üéØ 3D Scatter Plots - Visualize Embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate text embeddings (like BERT, GPT embeddings)\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Create 3 clusters (representing different topics)\n",
    "cluster1 = np.random.randn(n_samples//3, 3) + [2, 2, 2]  # Tech\n",
    "cluster2 = np.random.randn(n_samples//3, 3) + [-2, -2, 2]  # Health\n",
    "cluster3 = np.random.randn(n_samples//3, 3) + [0, -2, -2]  # Finance\n",
    "\n",
    "embeddings_3d = pd.DataFrame(\n",
    "    np.vstack([cluster1, cluster2, cluster3]),\n",
    "    columns=['Dim_1', 'Dim_2', 'Dim_3']\n",
    ")\n",
    "embeddings_3d['Topic'] = ['Tech']*(n_samples//3) + ['Health']*(n_samples//3) + ['Finance']*(n_samples//3)\n",
    "embeddings_3d['Document_ID'] = [f'Doc_{i}' for i in range(len(embeddings_3d))]\n",
    "\n",
    "# Create 3D scatter plot\n",
    "fig = px.scatter_3d(embeddings_3d,\n",
    "                    x='Dim_1',\n",
    "                    y='Dim_2',\n",
    "                    z='Dim_3',\n",
    "                    color='Topic',\n",
    "                    hover_name='Document_ID',\n",
    "                    title='üåê 3D Text Embedding Visualization (t-SNE/UMAP style)',\n",
    "                    labels={'Dim_1': 'Dimension 1',\n",
    "                           'Dim_2': 'Dimension 2',\n",
    "                           'Dim_3': 'Dimension 3'})\n",
    "\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(height=700)\n",
    "fig.show()\n",
    "\n",
    "print(\"üéÆ 3D Interaction:\")\n",
    "print(\"  - Click and drag to rotate\")\n",
    "print(\"  - Scroll to zoom\")\n",
    "print(\"  - Hover to see document IDs\")\n",
    "print(\"\\n‚ú® This is how RAG systems visualize document similarity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## üìä Subplots - Create Dashboards!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive AI monitoring dashboard\n",
    "np.random.seed(42)\n",
    "hours = np.arange(24)\n",
    "\n",
    "dashboard_data = {\n",
    "    'Hour': hours,\n",
    "    'API_Calls': np.random.poisson(500, 24) + hours * 20,\n",
    "    'Avg_Latency_ms': np.random.gamma(2, 100, 24),\n",
    "    'Error_Rate': np.random.beta(2, 100, 24),\n",
    "    'Cost_USD': (np.random.poisson(500, 24) + hours * 20) * 0.002\n",
    "}\n",
    "\n",
    "# Create 2x2 subplot dashboard\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('API Calls Over Time', 'Average Latency',\n",
    "                   'Error Rate', 'Cumulative Cost'),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "          [{'type': 'scatter'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "# Plot 1: API Calls\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hours, y=dashboard_data['API_Calls'], \n",
    "              mode='lines+markers', name='API Calls',\n",
    "              line=dict(color='blue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Latency\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hours, y=dashboard_data['Avg_Latency_ms'],\n",
    "              mode='lines+markers', name='Latency',\n",
    "              line=dict(color='orange', width=2)),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Error Rate\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hours, y=dashboard_data['Error_Rate'] * 100,\n",
    "              mode='lines+markers', name='Error Rate',\n",
    "              line=dict(color='red', width=2)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Cumulative Cost\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hours, y=np.cumsum(dashboard_data['Cost_USD']),\n",
    "              mode='lines+markers', name='Cost',\n",
    "              line=dict(color='green', width=2),\n",
    "              fill='tozeroy'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_xaxes(title_text=\"Hour of Day\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Hour of Day\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Calls\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"ms\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Error %\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"USD\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='üöÄ AI API Monitoring Dashboard - Live Production Metrics',\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üìä This is what production AI monitoring looks like!\")\n",
    "print(\"   Used by: OpenAI, Anthropic, Cohere, all AI companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## üéØ Real AI Example: Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive model benchmark data\n",
    "benchmarks = pd.DataFrame({\n",
    "    'Model': ['GPT-4', 'Claude-3.5', 'Gemini-1.5-Pro', 'Llama-3.1-405B'] * 6,\n",
    "    'Benchmark': ['MMLU', 'GSM8K', 'HumanEval', 'TruthfulQA', 'HellaSwag', 'ARC'] * 4,\n",
    "    'Score': [\n",
    "        # GPT-4\n",
    "        86.4, 92.0, 67.0, 59.0, 95.3, 96.3,\n",
    "        # Claude-3.5  \n",
    "        88.7, 96.4, 73.0, 62.0, 95.4, 96.4,\n",
    "        # Gemini-1.5-Pro\n",
    "        85.9, 91.7, 71.9, 57.0, 92.5, 95.6,\n",
    "        # Llama-3.1-405B\n",
    "        85.2, 89.0, 61.0, 55.0, 89.3, 94.8\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create interactive grouped bar chart\n",
    "fig = px.bar(benchmarks,\n",
    "            x='Benchmark',\n",
    "            y='Score',\n",
    "            color='Model',\n",
    "            barmode='group',\n",
    "            title='üèÜ LLM Benchmark Comparison (2024)',\n",
    "            labels={'Score': 'Benchmark Score (%)', 'Benchmark': 'Test'},\n",
    "            text='Score')\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "print(\"üìä Benchmark meanings:\")\n",
    "print(\"  - MMLU: General knowledge (57 subjects)\")\n",
    "print(\"  - GSM8K: Math word problems\")\n",
    "print(\"  - HumanEval: Code generation\")\n",
    "print(\"  - TruthfulQA: Truthfulness\")\n",
    "print(\"  - HellaSwag: Common sense reasoning\")\n",
    "print(\"  - ARC: Science questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## üåä Waterfall Charts - Show Cumulative Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI model optimization journey\n",
    "optimization_steps = {\n",
    "    'Step': ['Baseline', 'Better Prompt', 'RAG Added', 'Fine-tuning', \n",
    "            'Caching', 'Batch Processing', 'Final'],\n",
    "    'Improvement': [0, 15, 25, 20, -10, -8, 0],  # Negative = cost reduction\n",
    "    'Measure': ['relative'] * 6 + ['total']\n",
    "}\n",
    "\n",
    "fig = go.Figure(go.Waterfall(\n",
    "    name=\"Accuracy\",\n",
    "    orientation=\"v\",\n",
    "    measure=optimization_steps['Measure'],\n",
    "    x=optimization_steps['Step'],\n",
    "    y=optimization_steps['Improvement'],\n",
    "    textposition=\"outside\",\n",
    "    text=[f\"+{v}%\" if v > 0 else f\"{v}%\" for v in optimization_steps['Improvement']],\n",
    "    connector={\"line\": {\"color\": \"rgb(63, 63, 63)\"}},\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üéØ AI Model Optimization Journey\",\n",
    "    xaxis_title=\"Optimization Step\",\n",
    "    yaxis_title=\"Accuracy Improvement (%)\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üí° Optimization insights:\")\n",
    "print(\"  - Biggest win: RAG (+25%)\")\n",
    "print(\"  - Trade-offs: Caching reduces accuracy slightly (-10%)\")\n",
    "print(\"  - Final improvement: +42% total!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## üéØ MINI CHALLENGE: Build an LLM Cost Optimizer Dashboard\n",
    "\n",
    "**Scenario:** You need to optimize LLM API costs across different models!\n",
    "\n",
    "**Your Task:** Create an interactive dashboard with:\n",
    "1. Cost per model over time\n",
    "2. Quality vs Cost scatter plot\n",
    "3. Token usage distribution\n",
    "4. Recommendation engine visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic LLM usage data\n",
    "np.random.seed(42)\n",
    "days = 30\n",
    "\n",
    "cost_data = pd.DataFrame({\n",
    "    'Day': np.tile(np.arange(1, days+1), 4),\n",
    "    'Model': np.repeat(['GPT-4', 'GPT-3.5', 'Claude-3.5', 'Llama-3'], days),\n",
    "    'Daily_Cost': np.concatenate([\n",
    "        np.random.gamma(3, 30, days),  # GPT-4\n",
    "        np.random.gamma(2, 10, days),  # GPT-3.5\n",
    "        np.random.gamma(2.5, 20, days),  # Claude\n",
    "        np.random.gamma(1.5, 5, days)   # Llama\n",
    "    ]),\n",
    "    'Quality_Score': np.concatenate([\n",
    "        np.random.beta(9, 1, days) * 100,\n",
    "        np.random.beta(7, 2, days) * 100,\n",
    "        np.random.beta(8, 1.5, days) * 100,\n",
    "        np.random.beta(6, 2.5, days) * 100\n",
    "    ]),\n",
    "    'Tokens_Used': np.concatenate([\n",
    "        np.random.poisson(50000, days),\n",
    "        np.random.poisson(150000, days),\n",
    "        np.random.poisson(80000, days),\n",
    "        np.random.poisson(200000, days)\n",
    "    ])\n",
    "})\n",
    "\n",
    "# TODO: Create your dashboard!\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Daily Cost Trends', 'Quality vs Cost Analysis',\n",
    "                   'Token Usage Distribution', 'Cost Efficiency Score'),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "          [{'type': 'box'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Cost trends\n",
    "for model in ['GPT-4', 'GPT-3.5', 'Claude-3.5', 'Llama-3']:\n",
    "    model_data = cost_data[cost_data['Model'] == model]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=model_data['Day'], y=model_data['Daily_Cost'],\n",
    "                  mode='lines', name=model),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot 2: Quality vs Cost\n",
    "for model in ['GPT-4', 'GPT-3.5', 'Claude-3.5', 'Llama-3']:\n",
    "    model_data = cost_data[cost_data['Model'] == model]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=model_data['Daily_Cost'], y=model_data['Quality_Score'],\n",
    "                  mode='markers', name=model, showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot 3: Token distribution\n",
    "for model in ['GPT-4', 'GPT-3.5', 'Claude-3.5', 'Llama-3']:\n",
    "    model_data = cost_data[cost_data['Model'] == model]\n",
    "    fig.add_trace(\n",
    "        go.Box(y=model_data['Tokens_Used'], name=model, showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Plot 4: Efficiency (Quality / Cost)\n",
    "efficiency = cost_data.groupby('Model').apply(\n",
    "    lambda x: x['Quality_Score'].mean() / x['Daily_Cost'].mean()\n",
    ").reset_index(name='Efficiency')\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=efficiency['Model'], y=efficiency['Efficiency'],\n",
    "          text=efficiency['Efficiency'].round(2),\n",
    "          textposition='outside', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(title_text=\"Day\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Daily Cost ($)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Model\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Model\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Cost ($)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Quality Score\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Tokens\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Quality/Cost\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='üí∞ LLM Cost Optimization Dashboard',\n",
    "    height=900\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate insights\n",
    "total_cost = cost_data.groupby('Model')['Daily_Cost'].sum()\n",
    "avg_quality = cost_data.groupby('Model')['Quality_Score'].mean()\n",
    "\n",
    "print(\"\\nüí° Cost Optimization Recommendations:\")\n",
    "print(f\"\\nTotal 30-day costs:\")\n",
    "for model in total_cost.index:\n",
    "    print(f\"  {model}: ${total_cost[model]:.2f} (Quality: {avg_quality[model]:.1f}/100)\")\n",
    "\n",
    "print(f\"\\nüèÜ Best efficiency: {efficiency.loc[efficiency['Efficiency'].idxmax(), 'Model']}\")\n",
    "print(f\"üí∏ Potential savings: Switch low-priority tasks to efficient models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## üíæ Saving Interactive Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample plot\n",
    "fig = px.scatter(models_df, x='Cost_per_1M_tokens', y='Benchmark_Score',\n",
    "                size='Parameters_B', color='Category', hover_name='Model',\n",
    "                title='LLM Performance vs Cost')\n",
    "\n",
    "# Save as interactive HTML (can share with anyone!)\n",
    "fig.write_html('llm_analysis.html')\n",
    "\n",
    "# Save as static image\n",
    "# fig.write_image('llm_analysis.png')  # Requires kaleido: pip install kaleido\n",
    "\n",
    "# Save as JSON (can reload later)\n",
    "# fig.write_json('llm_analysis.json')\n",
    "\n",
    "print(\"‚úÖ Saved interactive plot as HTML!\")\n",
    "print(\"   You can:\")\n",
    "print(\"   - Open in browser\")\n",
    "print(\"   - Share with colleagues\")\n",
    "print(\"   - Embed in websites\")\n",
    "print(\"   - Host on GitHub Pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "**You just learned:**\n",
    "- ‚úÖ Why Plotly is essential for modern AI dashboards\n",
    "- ‚úÖ Interactive line, scatter, bar, histogram plots\n",
    "- ‚úÖ Animated visualizations (time series)\n",
    "- ‚úÖ 3D scatter plots (embedding visualization)\n",
    "- ‚úÖ Heatmaps and correlation matrices\n",
    "- ‚úÖ Multi-plot dashboards with subplots\n",
    "- ‚úÖ Real AI examples (cost optimization, model comparison)\n",
    "- ‚úÖ Saving and sharing interactive plots\n",
    "\n",
    "**üéØ Plotly Cheat Sheet:**\n",
    "```python\n",
    "# Plotly Express (high-level, easy)\n",
    "px.line()        # Line plots\n",
    "px.scatter()     # Scatter plots\n",
    "px.bar()         # Bar charts\n",
    "px.histogram()   # Histograms\n",
    "px.box()         # Box plots\n",
    "px.scatter_3d()  # 3D scatter\n",
    "px.scatter(animation_frame='Year')  # Animated!\n",
    "\n",
    "# Graph Objects (low-level, powerful)\n",
    "go.Figure()      # Custom figures\n",
    "go.Scatter()     # Custom scatter\n",
    "go.Bar()         # Custom bars\n",
    "go.Heatmap()     # Heatmaps\n",
    "make_subplots()  # Dashboards\n",
    "\n",
    "# Save and share\n",
    "fig.write_html('plot.html')  # Interactive HTML\n",
    "fig.show()                   # Display\n",
    "```\n",
    "\n",
    "**üéØ Practice Exercise:**\n",
    "\n",
    "Build a complete AI model monitoring dashboard with:\n",
    "1. Real-time accuracy plot (simulated streaming data)\n",
    "2. Confusion matrix heatmap\n",
    "3. Feature importance bar chart\n",
    "4. Prediction distribution histogram\n",
    "5. 3D decision boundary visualization\n",
    "6. Make it fully interactive and shareable!\n",
    "\n",
    "---\n",
    "\n",
    "**üìö Next Week:** Week 4 - Math for AI (The Foundation of ML!)\n",
    "\n",
    "**üí° Fun Fact:** \n",
    "- Plotly powers dashboards at Tesla, Google, Netflix\n",
    "- TensorBoard (Google) uses similar interactive plots\n",
    "- Weights & Biases, Langsmith use Plotly for ML tracking\n",
    "\n",
    "---\n",
    "\n",
    "**üéñÔ∏è Achievement Unlocked: Visualization Master!**\n",
    "\n",
    "*You can now create world-class AI visualizations and dashboards!* üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**Week 3 Complete! üéä**\n",
    "\n",
    "You've mastered:\n",
    "- Day 1: Matplotlib (foundation)\n",
    "- Day 2: Seaborn (statistical)\n",
    "- Day 3: Plotly (interactive)\n",
    "\n",
    "**You're now ready to visualize ANY AI/ML project!** ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
