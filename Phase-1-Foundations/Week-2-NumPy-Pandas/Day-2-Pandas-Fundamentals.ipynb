{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“Š Week 2, Day 2: Pandas Fundamentals\n",
        "\n",
        "**ðŸŽ¯ Goal:** Master Pandas DataFrames - Excel on steroids for AI/ML!\n",
        "\n",
        "**â±ï¸ Time:** 60-90 minutes\n",
        "\n",
        "**ðŸŒŸ Why This Matters for AI:**\n",
        "- **90% of AI projects start with Pandas** - Data cleaning, exploration, preprocessing\n",
        "- Handle massive datasets (millions of rows) with ease\n",
        "- Bridge between raw data and ML models\n",
        "- Industry standard for data science\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¥ 2024-2025 AI Trend Alert!\n",
        "\n",
        "**Agentic AI** is transforming how we build AI systems:\n",
        "- AI agents that can act autonomously\n",
        "- Multi-step reasoning and decision making\n",
        "- **Pandas processes agent memory and knowledge bases!**\n",
        "\n",
        "**Multimodal AI** (GPT-4V, Gemini, Claude) combines:\n",
        "- Text + Images + Audio + Video\n",
        "- **Pandas manages metadata for millions of multimodal files!**\n",
        "\n",
        "**You'll learn the tools used by Google, Meta, and OpenAI data teams!** ðŸš€\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ What is Pandas?\n",
        "\n",
        "**Pandas** = Panel Data\n",
        "\n",
        "Think of it as **Excel meets Python** with superpowers:\n",
        "- Excel: Great for small datasets, manual work ðŸ“\n",
        "- Pandas: Handles millions of rows, fully automated ðŸš€\n",
        "\n",
        "**Real-world example:**\n",
        "- Analyze 10 million customer reviews for sentiment AI\n",
        "- Excel: Crashes ðŸ’¥\n",
        "- Pandas: Processes in seconds âœ…\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Pandas (Google Colab has it pre-installed!)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"âœ… Pandas is ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Two Core Data Structures\n",
        "\n",
        "### 1ï¸âƒ£ Series (1D - Like a column)\n",
        "- Single column of data\n",
        "- Like a NumPy array with labels\n",
        "\n",
        "### 2ï¸âƒ£ DataFrame (2D - Like Excel)\n",
        "- Multiple columns of data\n",
        "- Most important structure for AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Series - Single column\n",
        "model_accuracies = pd.Series([0.85, 0.92, 0.88, 0.95, 0.89], \n",
        "                             name=\"Accuracy\")\n",
        "print(\"ðŸ“Š Series (AI Model Accuracies):\")\n",
        "print(model_accuracies)\n",
        "print(\"\\nType:\", type(model_accuracies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrame - Multiple columns (like Excel)\n",
        "ai_models = pd.DataFrame({\n",
        "    'Model': ['GPT-4', 'Claude-3.5', 'Gemini-Pro', 'Llama-3', 'Mistral'],\n",
        "    'Parameters_B': [1800, 200, 540, 70, 7],  # Billions\n",
        "    'Accuracy': [0.95, 0.94, 0.92, 0.88, 0.85],\n",
        "    'Release_Year': [2023, 2024, 2024, 2024, 2023]\n",
        "})\n",
        "\n",
        "print(\"ðŸ“Š DataFrame (Leading AI Models 2024):\")\n",
        "print(ai_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ§  AI Connection:**\n",
        "- **Series** = Single feature (e.g., prices, ratings, temperatures)\n",
        "- **DataFrame** = Complete dataset with many features\n",
        "- This is how you'll organize ALL AI training data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ—ï¸ Creating DataFrames - Multiple Ways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: From dictionary (most common!)\n",
        "df1 = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'age': [25, 30, 35],\n",
        "    'city': ['NYC', 'SF', 'LA']\n",
        "})\n",
        "print(\"Method 1 - From Dictionary:\")\n",
        "print(df1)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: From NumPy array\n",
        "data = np.random.rand(5, 3)  # 5 rows, 3 columns\n",
        "df2 = pd.DataFrame(data, \n",
        "                   columns=['Feature_1', 'Feature_2', 'Feature_3'])\n",
        "print(\"Method 2 - From NumPy Array:\")\n",
        "print(df2)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 3: From list of dictionaries\n",
        "training_runs = [\n",
        "    {'epoch': 1, 'loss': 2.5, 'accuracy': 0.65},\n",
        "    {'epoch': 2, 'loss': 1.8, 'accuracy': 0.78},\n",
        "    {'epoch': 3, 'loss': 1.2, 'accuracy': 0.85},\n",
        "    {'epoch': 4, 'loss': 0.8, 'accuracy': 0.91}\n",
        "]\n",
        "df3 = pd.DataFrame(training_runs)\n",
        "print(\"Method 3 - From List of Dicts (Training Log):\")\n",
        "print(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‚ Reading Real Data - CSV & JSON\n",
        "\n",
        "**This is where Pandas shines!** 99% of real AI projects start with loading data from files.\n",
        "\n",
        "Let's create and load a real AI dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a realistic AI training dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate 1000 AI-generated images with metadata\n",
        "image_data = pd.DataFrame({\n",
        "    'image_id': range(1, 1001),\n",
        "    'model': np.random.choice(['DALL-E-3', 'Midjourney', 'Stable-Diffusion'], 1000),\n",
        "    'prompt_length': np.random.randint(10, 200, 1000),\n",
        "    'generation_time_sec': np.random.uniform(1, 30, 1000).round(2),\n",
        "    'quality_score': np.random.uniform(0.5, 1.0, 1000).round(3),\n",
        "    'nsfw_flagged': np.random.choice([True, False], 1000, p=[0.05, 0.95]),\n",
        "    'user_rating': np.random.randint(1, 6, 1000)\n",
        "})\n",
        "\n",
        "# Save to CSV (like real data!)\n",
        "image_data.to_csv('ai_generated_images.csv', index=False)\n",
        "print(\"âœ… Created AI image dataset with 1000 samples\")\n",
        "\n",
        "# Now read it back (this is what you'll do in real projects!)\n",
        "df = pd.read_csv('ai_generated_images.csv')\n",
        "print(\"\\nðŸ“‚ Loaded dataset from CSV:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading JSON (common for API data)\n",
        "json_data = {\n",
        "    'requests': [\n",
        "        {'user_id': 'U001', 'tokens': 450, 'model': 'gpt-4', 'cost': 0.03},\n",
        "        {'user_id': 'U002', 'tokens': 1200, 'model': 'gpt-4', 'cost': 0.08},\n",
        "        {'user_id': 'U003', 'tokens': 800, 'model': 'claude-3', 'cost': 0.04}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame from JSON structure\n",
        "api_df = pd.DataFrame(json_data['requests'])\n",
        "print(\"ðŸ“‚ API Request Data (JSON â†’ DataFrame):\")\n",
        "print(api_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ” Data Inspection - First Look at Your Data\n",
        "\n",
        "**ALWAYS start here!** Understanding your data is 50% of AI success."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load our AI image dataset\n",
        "df = pd.read_csv('ai_generated_images.csv')\n",
        "\n",
        "print(\"ðŸ“Š Dataset Shape:\")\n",
        "print(f\"Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")\n",
        "print(f\"Total cells: {df.size:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# head() - First few rows\n",
        "print(\"ðŸ‘€ First 5 rows (.head()):\")\n",
        "print(df.head())\n",
        "print(\"\\nðŸ‘€ First 3 rows (.head(3)):\")\n",
        "print(df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tail() - Last few rows\n",
        "print(\"ðŸ‘€ Last 5 rows (.tail()):\")\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# info() - Data types and missing values\n",
        "print(\"â„¹ï¸ Dataset Info (.info()):\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe() - Statistical summary (SUPER IMPORTANT!)\n",
        "print(\"ðŸ“ˆ Statistical Summary (.describe()):\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column names and types\n",
        "print(\"ðŸ“‹ Column Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nðŸ“Š Data Types:\")\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ§  Pro Tip:**\n",
        "```python\n",
        "# Your AI data exploration checklist:\n",
        "df.shape        # How big is the data?\n",
        "df.head()       # What does it look like?\n",
        "df.info()       # Any missing values? Data types correct?\n",
        "df.describe()   # Any outliers? Reasonable ranges?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Selecting Data - The Power Moves\n",
        "\n",
        "### 1ï¸âƒ£ Selecting Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single column (returns Series)\n",
        "models = df['model']\n",
        "print(\"ðŸ“Š Single Column (Series):\")\n",
        "print(models.head())\n",
        "print(f\"Type: {type(models)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple columns (returns DataFrame)\n",
        "subset = df[['model', 'quality_score', 'user_rating']]\n",
        "print(\"ðŸ“Š Multiple Columns (DataFrame):\")\n",
        "print(subset.head())\n",
        "print(f\"Type: {type(subset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2ï¸âƒ£ Selecting Rows - iloc vs loc\n",
        "\n",
        "**iloc** = integer location (position-based)  \n",
        "**loc** = label location (index-based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# iloc - Position-based (like array indexing)\n",
        "print(\"ðŸ“ iloc - Position-based:\")\n",
        "print(\"\\nFirst row (iloc[0]):\")\n",
        "print(df.iloc[0])\n",
        "\n",
        "print(\"\\nFirst 3 rows (iloc[0:3]):\")\n",
        "print(df.iloc[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specific rows and columns with iloc\n",
        "print(\"ðŸ“ iloc - Rows 0-4, Columns 1-3:\")\n",
        "print(df.iloc[0:5, 1:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loc - Label-based (uses index and column names)\n",
        "print(\"ðŸ“ loc - Label-based:\")\n",
        "print(\"\\nRows 0-4, specific columns:\")\n",
        "print(df.loc[0:4, ['model', 'quality_score', 'user_rating']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3ï¸âƒ£ Boolean Indexing - The Most Powerful!\n",
        "\n",
        "**Filter data like SQL WHERE clause**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter: High-quality images only\n",
        "high_quality = df[df['quality_score'] > 0.9]\n",
        "print(f\"ðŸŒŸ High Quality Images (score > 0.9): {len(high_quality)} images\")\n",
        "print(high_quality.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter: DALL-E images only\n",
        "dalle_images = df[df['model'] == 'DALL-E-3']\n",
        "print(f\"ðŸŽ¨ DALL-E-3 Images: {len(dalle_images)} images\")\n",
        "print(dalle_images.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple conditions with & (AND) and | (OR)\n",
        "# High quality AND fast generation\n",
        "fast_quality = df[(df['quality_score'] > 0.9) & (df['generation_time_sec'] < 10)]\n",
        "print(f\"âš¡ Fast & High Quality: {len(fast_quality)} images\")\n",
        "print(fast_quality.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OR condition - Either highly rated OR high quality\n",
        "excellent = df[(df['user_rating'] == 5) | (df['quality_score'] > 0.95)]\n",
        "print(f\"ðŸ† Excellent Images (5-star OR quality>0.95): {len(excellent)} images\")\n",
        "print(excellent.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# isin() - Filter multiple values\n",
        "top_models = df[df['model'].isin(['DALL-E-3', 'Midjourney'])]\n",
        "print(f\"ðŸŽ¯ DALL-E-3 or Midjourney: {len(top_models)} images\")\n",
        "print(top_models['model'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Quick Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# value_counts() - Count occurrences (SUPER USEFUL!)\n",
        "print(\"ðŸ“Š Images by Model:\")\n",
        "print(df['model'].value_counts())\n",
        "\n",
        "print(\"\\nðŸ“Š User Ratings Distribution:\")\n",
        "print(df['user_rating'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unique() - Find unique values\n",
        "print(\"ðŸŽ¯ Unique Models:\")\n",
        "print(df['model'].unique())\n",
        "\n",
        "print(f\"\\nðŸ“Š Number of unique models: {df['model'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sorting data\n",
        "print(\"ðŸ† Top 10 Highest Quality Images:\")\n",
        "top_quality = df.sort_values('quality_score', ascending=False).head(10)\n",
        "print(top_quality[['image_id', 'model', 'quality_score', 'user_rating']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-column sorting\n",
        "print(\"ðŸ“Š Sort by Model, then Quality Score:\")\n",
        "sorted_df = df.sort_values(['model', 'quality_score'], ascending=[True, False])\n",
        "print(sorted_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Real AI Example: Movie Recommendation System Dataset\n",
        "\n",
        "Let's create a realistic dataset for building a recommendation AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create movie ratings dataset (like Netflix, Spotify)\n",
        "np.random.seed(42)\n",
        "\n",
        "movies = ['The Matrix', 'Inception', 'Interstellar', 'Arrival', 'Her', \n",
        "          'Ex Machina', 'Blade Runner 2049', 'The Prestige', 'Memento', 'Tenet']\n",
        "\n",
        "# 500 user ratings\n",
        "movie_ratings = pd.DataFrame({\n",
        "    'user_id': np.random.randint(1, 101, 500),  # 100 users\n",
        "    'movie': np.random.choice(movies, 500),\n",
        "    'rating': np.random.randint(1, 6, 500),\n",
        "    'watch_time_min': np.random.randint(30, 180, 500),\n",
        "    'completed': np.random.choice([True, False], 500, p=[0.7, 0.3]),\n",
        "    'timestamp': pd.date_range('2024-01-01', periods=500, freq='H')\n",
        "})\n",
        "\n",
        "print(\"ðŸŽ¬ Movie Ratings Dataset:\")\n",
        "print(movie_ratings.head(10))\n",
        "print(f\"\\nðŸ“Š Shape: {movie_ratings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze the data\n",
        "print(\"ðŸ“Š Average Rating by Movie:\")\n",
        "avg_ratings = movie_ratings.groupby('movie')['rating'].mean().sort_values(ascending=False)\n",
        "print(avg_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find most popular movies\n",
        "print(\"ðŸ”¥ Most Rated Movies:\")\n",
        "print(movie_ratings['movie'].value_counts().head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter: High-quality recommendations\n",
        "recommendations = movie_ratings[\n",
        "    (movie_ratings['rating'] >= 4) & \n",
        "    (movie_ratings['completed'] == True)\n",
        "]\n",
        "print(f\"â­ High-Quality Recommendations: {len(recommendations)} ratings\")\n",
        "print(recommendations.groupby('movie').size().sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Practice Exercise: Build Your Own AI Dataset Analysis\n",
        "\n",
        "**Scenario:** You're analyzing ChatGPT API usage for cost optimization!\n",
        "\n",
        "Use the code below to practice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create API usage dataset\n",
        "np.random.seed(100)\n",
        "\n",
        "api_usage = pd.DataFrame({\n",
        "    'request_id': range(1, 201),\n",
        "    'user_id': np.random.randint(1000, 1050, 200),\n",
        "    'model': np.random.choice(['gpt-4', 'gpt-3.5-turbo', 'claude-3'], 200, p=[0.3, 0.5, 0.2]),\n",
        "    'input_tokens': np.random.randint(50, 2000, 200),\n",
        "    'output_tokens': np.random.randint(100, 1500, 200),\n",
        "    'response_time_ms': np.random.randint(500, 5000, 200),\n",
        "    'success': np.random.choice([True, False], 200, p=[0.95, 0.05])\n",
        "})\n",
        "\n",
        "# Calculate cost (example pricing)\n",
        "def calculate_cost(row):\n",
        "    if row['model'] == 'gpt-4':\n",
        "        return (row['input_tokens'] * 0.00003 + row['output_tokens'] * 0.00006)\n",
        "    elif row['model'] == 'gpt-3.5-turbo':\n",
        "        return (row['input_tokens'] * 0.000001 + row['output_tokens'] * 0.000002)\n",
        "    else:  # claude-3\n",
        "        return (row['input_tokens'] * 0.000015 + row['output_tokens'] * 0.000075)\n",
        "\n",
        "api_usage['cost_usd'] = api_usage.apply(calculate_cost, axis=1)\n",
        "\n",
        "print(\"ðŸ’° API Usage Dataset:\")\n",
        "print(api_usage.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Your turn! Answer these questions:\n",
        "\n",
        "# 1. How many requests used GPT-4?\n",
        "gpt4_count = len(api_usage[api_usage['model'] == 'gpt-4'])\n",
        "print(f\"1. GPT-4 requests: {gpt4_count}\")\n",
        "\n",
        "# 2. What's the average cost per request for each model?\n",
        "print(\"\\n2. Average cost by model:\")\n",
        "print(api_usage.groupby('model')['cost_usd'].mean().round(6))\n",
        "\n",
        "# 3. Find all failed requests (success == False)\n",
        "failed = api_usage[api_usage['success'] == False]\n",
        "print(f\"\\n3. Failed requests: {len(failed)}\")\n",
        "\n",
        "# 4. What's the total cost?\n",
        "total_cost = api_usage['cost_usd'].sum()\n",
        "print(f\"\\n4. Total cost: ${total_cost:.2f}\")\n",
        "\n",
        "# 5. Find requests that took > 3 seconds AND cost > $0.01\n",
        "expensive_slow = api_usage[(api_usage['response_time_ms'] > 3000) & (api_usage['cost_usd'] > 0.01)]\n",
        "print(f\"\\n5. Expensive & slow requests: {len(expensive_slow)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "**You just learned:**\n",
        "- âœ… What Pandas is and why it's essential for AI\n",
        "- âœ… Series vs DataFrame (the two core structures)\n",
        "- âœ… Creating DataFrames from various sources\n",
        "- âœ… Reading CSV and JSON files (real-world data!)\n",
        "- âœ… Data inspection (head, tail, info, describe)\n",
        "- âœ… Selecting data (columns, iloc, loc)\n",
        "- âœ… Boolean indexing (powerful filtering!)\n",
        "- âœ… Quick analysis (value_counts, sorting, groupby)\n",
        "- âœ… Real AI examples (images, movies, API usage)\n",
        "\n",
        "**ðŸŽ¯ Key Takeaways:**\n",
        "```python\n",
        "# Your Pandas workflow for every AI project:\n",
        "df = pd.read_csv('data.csv')     # 1. Load data\n",
        "df.info()                         # 2. Inspect\n",
        "df.describe()                     # 3. Understand\n",
        "df[df['score'] > 0.9]            # 4. Filter\n",
        "df.groupby('category').mean()    # 5. Analyze\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸ“š Next Lesson:** Day 3 - Data Manipulation & Cleaning (The Real AI Work!)\n",
        "\n",
        "**ðŸ’¡ Fun Fact:** 80% of AI/ML time is spent on data preparation with Pandas. Only 20% on modeling!\n",
        "\n",
        "---\n",
        "\n",
        "*You now have the skills used by data scientists at Google, Meta, and OpenAI!* ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
