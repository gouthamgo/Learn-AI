{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 3: Your First ML Model - Linear Regression\n",
    "\n",
    "**ðŸŽ¯ Goal:** Build, train, and evaluate a complete Machine Learning model\n",
    "\n",
    "**â±ï¸ Time:** 60-75 minutes\n",
    "\n",
    "**ðŸŒŸ Why This Matters for AI:**\n",
    "- Linear Regression is the foundation of modern AI\n",
    "- Neural Networks are just advanced versions of regression!\n",
    "- Understanding evaluation metrics helps you build better AI systems\n",
    "- Same principles power recommendation systems, price prediction, and more\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” What is Linear Regression?\n",
    "\n",
    "**Simple Definition:** Finding the best straight line through data points\n",
    "\n",
    "**The Goal:** Predict a continuous number (like price, temperature, sales)\n",
    "\n",
    "**Examples:**\n",
    "- Predict house price based on size\n",
    "- Predict temperature based on time\n",
    "- Predict salary based on years of experience\n",
    "\n",
    "### ðŸ“ The Math (Don't Panic!)\n",
    "\n",
    "**The line equation you learned in school:**\n",
    "```\n",
    "y = mx + b\n",
    "```\n",
    "\n",
    "**In Machine Learning:**\n",
    "```\n",
    "y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **y** = prediction (what we want to find)\n",
    "- **x** = features (input data)\n",
    "- **w** = weights (importance of each feature)\n",
    "- **b** = bias (starting point)\n",
    "\n",
    "**The model learns the best w and b values!** ðŸŽ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  How Does Linear Regression Learn?\n",
    "\n",
    "**Process:**\n",
    "1. Start with random weights (w) and bias (b)\n",
    "2. Make predictions\n",
    "3. Calculate error (how wrong are we?)\n",
    "4. Adjust weights to reduce error\n",
    "5. Repeat until error is minimized\n",
    "\n",
    "**This is called \"Gradient Descent\"** - the backbone of ALL ML! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn pandas numpy matplotlib seaborn --quiet\n",
    "\n",
    "print(\"âœ… All libraries installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set style for beautiful plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"ðŸ“š Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ  Project: Predicting House Prices\n",
    "\n",
    "**Real-World Dataset:** California Housing Prices\n",
    "\n",
    "**Features:**\n",
    "- House size (square feet)\n",
    "- Number of bedrooms\n",
    "- House age\n",
    "- Location score\n",
    "\n",
    "**Target:**\n",
    "- House price (what we want to predict!)\n",
    "\n",
    "Let's build a model that real estate companies use! ðŸ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create/Load the Dataset ðŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic house price dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 100 houses\n",
    "n_houses = 100\n",
    "\n",
    "# Features\n",
    "house_size = np.random.randint(800, 3500, n_houses)  # sq ft\n",
    "bedrooms = np.random.randint(1, 6, n_houses)  # 1-5 bedrooms\n",
    "house_age = np.random.randint(0, 50, n_houses)  # 0-50 years old\n",
    "location_score = np.random.randint(1, 11, n_houses)  # 1-10 rating\n",
    "\n",
    "# Create realistic price based on features\n",
    "# Formula: base price + (size effect) + (bedroom effect) - (age effect) + (location effect) + noise\n",
    "base_price = 100000\n",
    "price = (\n",
    "    base_price + \n",
    "    (house_size * 150) +  # $150 per sq ft\n",
    "    (bedrooms * 20000) +  # $20k per bedroom\n",
    "    (-house_age * 1000) +  # Lose $1k per year of age\n",
    "    (location_score * 15000) +  # $15k per location point\n",
    "    np.random.randint(-30000, 30000, n_houses)  # Random noise\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Size_SqFt': house_size,\n",
    "    'Bedrooms': bedrooms,\n",
    "    'Age_Years': house_age,\n",
    "    'Location_Score': location_score,\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "print(\"ðŸ  House Price Dataset:\")\n",
    "print(data.head(10))\n",
    "print(f\"\\nðŸ“Š Total houses: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore the Data ðŸ”\n",
    "\n",
    "Always visualize your data before modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"ðŸ“Š Statistical Summary:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations - which features are most important?\n",
    "print(\"ðŸ”— Correlation with Price:\")\n",
    "correlations = data.corr()['Price'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "print(\"\\nðŸ’¡ Higher correlation = More important for prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Price vs Size\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Size_SqFt'], data['Price'], alpha=0.6, color='blue')\n",
    "plt.xlabel('House Size (Square Feet)', fontsize=12)\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.title('House Price vs Size', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ˆ Notice the upward trend? Bigger houses = Higher prices!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Size vs Price\n",
    "axes[0, 0].scatter(data['Size_SqFt'], data['Price'], alpha=0.6, color='blue')\n",
    "axes[0, 0].set_xlabel('Size (sq ft)')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].set_title('Size vs Price')\n",
    "\n",
    "# Bedrooms vs Price\n",
    "axes[0, 1].scatter(data['Bedrooms'], data['Price'], alpha=0.6, color='green')\n",
    "axes[0, 1].set_xlabel('Bedrooms')\n",
    "axes[0, 1].set_ylabel('Price ($)')\n",
    "axes[0, 1].set_title('Bedrooms vs Price')\n",
    "\n",
    "# Age vs Price\n",
    "axes[1, 0].scatter(data['Age_Years'], data['Price'], alpha=0.6, color='red')\n",
    "axes[1, 0].set_xlabel('Age (years)')\n",
    "axes[1, 0].set_ylabel('Price ($)')\n",
    "axes[1, 0].set_title('Age vs Price')\n",
    "\n",
    "# Location vs Price\n",
    "axes[1, 1].scatter(data['Location_Score'], data['Price'], alpha=0.6, color='purple')\n",
    "axes[1, 1].set_xlabel('Location Score')\n",
    "axes[1, 1].set_ylabel('Price ($)')\n",
    "axes[1, 1].set_title('Location vs Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare Data for ML ðŸ› ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data[['Size_SqFt', 'Bedrooms', 'Age_Years', 'Location_Score']].values\n",
    "y = data['Price'].values\n",
    "\n",
    "print(\"ðŸ“Š Features (X) shape:\", X.shape)\n",
    "print(\"ðŸŽ¯ Target (y) shape:\", y.shape)\n",
    "print(\"\\nâœ… X has 4 features for each of 100 houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"ðŸ”€ Data Split Complete!\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(\"\\nðŸ’¡ Model will learn from 80 houses, test on 20 unseen houses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create and Train the Model ðŸ‹ï¸\n",
    "\n",
    "**This is where the magic happens!** âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"ðŸ¤– Model created!\")\n",
    "print(\"Model type:\", type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (fit it to the data)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"ðŸŽ“ Model trained successfully!\")\n",
    "print(\"\\nâœ¨ The model has learned the relationship between features and price!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Understand What the Model Learned ðŸ§ \n",
    "\n",
    "Let's see the weights (importance) of each feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learned coefficients (weights)\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "feature_names = ['Size_SqFt', 'Bedrooms', 'Age_Years', 'Location_Score']\n",
    "\n",
    "print(\"ðŸ” What the model learned:\")\n",
    "print(f\"\\nIntercept (base price): ${intercept:,.2f}\")\n",
    "print(\"\\nFeature Weights:\")\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"  {name}: ${coef:,.2f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(f\"  - Each extra sq ft adds ${coefficients[0]:.2f} to price\")\n",
    "print(f\"  - Each extra bedroom adds ${coefficients[1]:,.2f} to price\")\n",
    "print(f\"  - Each year of age changes price by ${coefficients[2]:,.2f}\")\n",
    "print(f\"  - Each location point adds ${coefficients[3]:,.2f} to price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions ðŸ”®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"ðŸ”® Predictions made!\")\n",
    "print(\"\\nðŸ“Š First 10 predictions vs actual prices:\")\n",
    "print(\"\\nPredicted\\t\\tActual\\t\\t\\tDifference\")\n",
    "print(\"=\"*60)\n",
    "for pred, actual in zip(y_pred[:10], y_test[:10]):\n",
    "    diff = abs(pred - actual)\n",
    "    print(f\"${pred:,.2f}\\t\\t${actual:,.2f}\\t\\t${diff:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, color='blue', s=100)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price ($)', fontsize=12)\n",
    "plt.ylabel('Predicted Price ($)', fontsize=12)\n",
    "plt.title('Predicted vs Actual House Prices', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ˆ Points close to the red line = Good predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate Model Performance ðŸ“Š\n",
    "\n",
    "**How good is our model?**\n",
    "\n",
    "We use 3 key metrics:\n",
    "\n",
    "**1. MAE (Mean Absolute Error)**\n",
    "- Average difference between prediction and actual\n",
    "- In dollars: How much are we off on average?\n",
    "- **Lower is better** âœ…\n",
    "\n",
    "**2. RMSE (Root Mean Squared Error)**\n",
    "- Similar to MAE but penalizes large errors more\n",
    "- **Lower is better** âœ…\n",
    "\n",
    "**3. RÂ² Score (R-squared)**\n",
    "- How much variance the model explains (0 to 1)\n",
    "- 1.0 = Perfect predictions\n",
    "- 0.0 = Terrible predictions\n",
    "- **Higher is better** âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š MODEL PERFORMANCE REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"   â†’ On average, predictions are off by ${mae:,.2f}\")\n",
    "\n",
    "print(f\"\\n2. Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
    "print(f\"   â†’ Larger errors are penalized more\")\n",
    "\n",
    "print(f\"\\n3. RÂ² Score: {r2:.4f} ({r2*100:.2f}%)\")\n",
    "print(f\"   â†’ Model explains {r2*100:.2f}% of price variance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Interpretation\n",
    "if r2 > 0.8:\n",
    "    print(\"âœ… EXCELLENT MODEL! RÂ² > 0.8\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"ðŸ‘ GOOD MODEL! RÂ² > 0.6\")\n",
    "elif r2 > 0.4:\n",
    "    print(\"âš ï¸ FAIR MODEL. Room for improvement.\")\n",
    "else:\n",
    "    print(\"âŒ POOR MODEL. Needs major improvements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Make Predictions for New Houses ðŸ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New houses we want to price\n",
    "new_houses = np.array([\n",
    "    [2000, 3, 10, 8],   # 2000 sq ft, 3 bed, 10 years old, location score 8\n",
    "    [1500, 2, 5, 6],    # 1500 sq ft, 2 bed, 5 years old, location score 6\n",
    "    [3000, 4, 2, 9],    # 3000 sq ft, 4 bed, 2 years old, location score 9\n",
    "])\n",
    "\n",
    "# Predict prices\n",
    "predicted_prices = model.predict(new_houses)\n",
    "\n",
    "print(\"ðŸ  Price Predictions for New Houses:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSize\\tBeds\\tAge\\tLocation\\tPredicted Price\")\n",
    "print(\"=\"*70)\n",
    "for house, price in zip(new_houses, predicted_prices):\n",
    "    print(f\"{house[0]}\\t{house[1]}\\t{house[2]}\\t{house[3]}\\t\\t${price:,.2f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Why This Matters for Modern AI\n",
    "\n",
    "**The principles you just learned power EVERYTHING in AI!**\n",
    "\n",
    "### ðŸ¤– **Neural Networks**\n",
    "- Neural networks = Many linear regressions stacked together!\n",
    "- ChatGPT, DALL-E, all use the same gradient descent learning\n",
    "\n",
    "### ðŸ” **RAG Systems**\n",
    "- Predict relevance scores for documents (regression!)\n",
    "- Rank results before sending to LLM\n",
    "\n",
    "### ðŸ“Š **Recommendation Systems**\n",
    "- Netflix, Spotify use regression to predict ratings\n",
    "- \"You might rate this movie 4.5 stars\" â† Regression prediction!\n",
    "\n",
    "### ðŸŽ¨ **Image Generation**\n",
    "- Predict pixel values (regression for each pixel!)\n",
    "- Diffusion models = Advanced regression over time\n",
    "\n",
    "### ðŸ¤ **Agentic AI**\n",
    "- Predict value of different actions\n",
    "- Choose action with highest predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ YOUR TURN: Interactive Exercise\n",
    "\n",
    "**Challenge:** Build a model to predict student exam scores!\n",
    "\n",
    "**Dataset:**\n",
    "- Study hours per week\n",
    "- Attendance percentage\n",
    "- Previous exam score\n",
    "- Sleep hours per night\n",
    "\n",
    "**Target:** Final exam score (0-100)\n",
    "\n",
    "Follow all the steps we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student exam score dataset\n",
    "np.random.seed(42)\n",
    "n_students = 80\n",
    "\n",
    "study_hours = np.random.randint(5, 40, n_students)\n",
    "attendance = np.random.randint(50, 100, n_students)\n",
    "previous_score = np.random.randint(40, 95, n_students)\n",
    "sleep_hours = np.random.randint(4, 10, n_students)\n",
    "\n",
    "# Create realistic exam scores\n",
    "exam_score = (\n",
    "    20 +  # Base score\n",
    "    (study_hours * 1.2) +  # More study = higher score\n",
    "    (attendance * 0.3) +  # Better attendance = higher score\n",
    "    (previous_score * 0.2) +  # Past performance matters\n",
    "    (sleep_hours * 2) +  # Sleep is important!\n",
    "    np.random.randint(-10, 10, n_students)  # Noise\n",
    ")\n",
    "exam_score = np.clip(exam_score, 0, 100)  # Keep scores 0-100\n",
    "\n",
    "student_data = pd.DataFrame({\n",
    "    'Study_Hours': study_hours,\n",
    "    'Attendance_%': attendance,\n",
    "    'Previous_Score': previous_score,\n",
    "    'Sleep_Hours': sleep_hours,\n",
    "    'Exam_Score': exam_score\n",
    "})\n",
    "\n",
    "print(\"ðŸ“š Student Exam Score Dataset:\")\n",
    "print(student_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!\n",
    "\n",
    "# Step 1: Explore the data\n",
    "# TODO: Print statistics and check correlations\n",
    "\n",
    "# Step 2: Prepare X and y\n",
    "# TODO: Separate features and target\n",
    "\n",
    "# Step 3: Split data\n",
    "# TODO: train_test_split with 80/20\n",
    "\n",
    "# Step 4: Create and train model\n",
    "# TODO: LinearRegression and fit\n",
    "\n",
    "# Step 5: Make predictions\n",
    "# TODO: Predict on test set\n",
    "\n",
    "# Step 6: Evaluate model\n",
    "# TODO: Calculate MAE, RMSE, RÂ²\n",
    "\n",
    "# Step 7: Predict for a new student:\n",
    "# Study 25 hours/week, 85% attendance, previous score 75, sleeps 7 hours\n",
    "# TODO: Make prediction\n",
    "\n",
    "print(\"Complete the TODOs above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Solution (Try on your own first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Explore\n",
    "print(\"ðŸ“Š Correlations with Exam Score:\")\n",
    "print(student_data.corr()['Exam_Score'].sort_values(ascending=False))\n",
    "\n",
    "# Step 2: Prepare X and y\n",
    "X_students = student_data[['Study_Hours', 'Attendance_%', 'Previous_Score', 'Sleep_Hours']].values\n",
    "y_students = student_data['Exam_Score'].values\n",
    "\n",
    "# Step 3: Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_students, y_students, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Train\n",
    "student_model = LinearRegression()\n",
    "student_model.fit(X_train, y_train)\n",
    "print(\"\\nâœ… Model trained!\")\n",
    "\n",
    "# Step 5: Predict\n",
    "y_pred = student_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL PERFORMANCE:\")\n",
    "print(f\"MAE: {mae:.2f} points\")\n",
    "print(f\"RMSE: {rmse:.2f} points\")\n",
    "print(f\"RÂ² Score: {r2:.4f} ({r2*100:.2f}%)\")\n",
    "\n",
    "# Step 7: Predict for new student\n",
    "new_student = np.array([[25, 85, 75, 7]])  # Study, Attendance, Previous, Sleep\n",
    "predicted_score = student_model.predict(new_student)\n",
    "\n",
    "print(f\"\\nðŸŽ“ Predicted exam score for new student: {predicted_score[0]:.1f}/100\")\n",
    "\n",
    "# Show feature importance\n",
    "print(\"\\nðŸ’¡ Feature Importance (Coefficients):\")\n",
    "features = ['Study_Hours', 'Attendance_%', 'Previous_Score', 'Sleep_Hours']\n",
    "for feature, coef in zip(features, student_model.coef_):\n",
    "    print(f\"  {feature}: {coef:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Linear Regression Checklist\n",
    "\n",
    "**Before building a regression model:**\n",
    "\n",
    "**1. Understand the Problem** ðŸŽ¯\n",
    "- [ ] Is this a regression problem? (Predicting a number?)\n",
    "- [ ] Do I have enough data? (At least 50+ samples)\n",
    "- [ ] Are features related to target?\n",
    "\n",
    "**2. Prepare Data** ðŸ› ï¸\n",
    "- [ ] Handle missing values\n",
    "- [ ] Encode categorical variables\n",
    "- [ ] Check for outliers\n",
    "- [ ] Split train/test\n",
    "\n",
    "**3. Build Model** ðŸ—ï¸\n",
    "- [ ] Create LinearRegression()\n",
    "- [ ] Fit on training data\n",
    "- [ ] Make predictions\n",
    "\n",
    "**4. Evaluate** ðŸ“Š\n",
    "- [ ] Calculate MAE, RMSE, RÂ²\n",
    "- [ ] Visualize predictions vs actual\n",
    "- [ ] Check if RÂ² > 0.6 (good model)\n",
    "\n",
    "**5. Interpret** ðŸ§ \n",
    "- [ ] Understand coefficients\n",
    "- [ ] Identify most important features\n",
    "- [ ] Make predictions for new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "**You just built a complete Machine Learning model!** ðŸŽŠ\n",
    "\n",
    "**What you learned:**\n",
    "- âœ… What Linear Regression is and how it works\n",
    "- âœ… How to train a model using scikit-learn\n",
    "- âœ… How to make predictions on new data\n",
    "- âœ… How to evaluate model performance (MAE, RMSE, RÂ²)\n",
    "- âœ… How to interpret coefficients and feature importance\n",
    "- âœ… Real-world application: House price prediction\n",
    "\n",
    "**ðŸŽ¯ Practice Projects (Highly Recommended!):**\n",
    "\n",
    "**1. Beginner:**\n",
    "- Predict car prices based on age, mileage, brand\n",
    "- Predict temperature based on time and location\n",
    "\n",
    "**2. Intermediate:**\n",
    "- Download Kaggle \"House Prices\" dataset\n",
    "- Build a salary prediction model\n",
    "\n",
    "**3. Advanced:**\n",
    "- Predict stock prices (challenging!)\n",
    "- Build a recommendation system score predictor\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ“š What's Next?**\n",
    "\n",
    "**Week 7 Preview:**\n",
    "- Classification models (Logistic Regression, Decision Trees)\n",
    "- More advanced evaluation metrics\n",
    "- Cross-validation and hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ’¬ Key Takeaway:**\n",
    "\n",
    "*You just built the same type of model that powers real estate predictions, salary estimations, and even parts of modern AI systems. Linear Regression is simple, but it's the foundation of EVERYTHING in machine learning. Master this, and you'll understand 80% of ML!* ðŸš€\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ”— Connections to Modern AI:**\n",
    "\n",
    "- **GPT/LLMs**: Predict next word using advanced regression\n",
    "- **RAG Systems**: Score document relevance (regression!)\n",
    "- **Recommendation Systems**: Predict ratings using regression\n",
    "- **Image AI**: Predict pixel values (regression for each pixel)\n",
    "- **Agentic AI**: Predict action values using regression\n",
    "- **Transformers**: Attention scores computed via learned weights (regression!)\n",
    "\n",
    "**Every advanced AI model builds on these foundations!** ðŸŒŸ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
