{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìò Day 1: Bagging and Boosting\n",
    "\n",
    "**üéØ Goal:** Master ensemble methods that power modern AI systems\n",
    "\n",
    "**‚è±Ô∏è Time:** 90-120 minutes\n",
    "\n",
    "**üåü Why This Matters for AI:**\n",
    "- Ensemble methods dramatically improve AI model accuracy\n",
    "- Used in production RAG systems to improve retrieval accuracy\n",
    "- Foundation for Kaggle-winning solutions and real-world ML\n",
    "- Critical for Agentic AI decision-making reliability\n",
    "- Powers ranking systems in modern search and recommendation engines\n",
    "- Essential for building robust production AI systems in 2024-2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble-intro",
   "metadata": {},
   "source": [
    "## ü§î What are Ensemble Methods?\n",
    "\n",
    "**Ensemble = Combining multiple models to make better predictions**\n",
    "\n",
    "**The Wisdom of Crowds:**\n",
    "- One expert might be wrong\n",
    "- But ask 100 experts and average their opinions ‚Üí More accurate!\n",
    "\n",
    "**Real-World Analogy:**\n",
    "- üè• **Medical Diagnosis:** Get second, third opinions from multiple doctors\n",
    "- üéØ **Jury Decision:** 12 people decide together (not just 1 judge)\n",
    "- üìä **Weather Forecast:** Combines multiple prediction models\n",
    "\n",
    "**Two Main Approaches:**\n",
    "1. **Bagging** (Bootstrap Aggregating): Train models independently, then vote\n",
    "2. **Boosting**: Train models sequentially, each fixing previous errors\n",
    "\n",
    "Let's explore both! üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensemble methods\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make plots beautiful\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"Let's build powerful ensemble models! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-intro",
   "metadata": {},
   "source": [
    "## üìä Our Dataset: Document Relevance for RAG Systems\n",
    "\n",
    "**Real AI Application:** Building a document classifier for Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "**Scenario:** You're building a RAG system for customer support. When a user asks a question, your system needs to:\n",
    "1. Retrieve potentially relevant documents\n",
    "2. **Classify which documents are actually relevant** ‚Üê We're building this!\n",
    "3. Feed only relevant docs to the LLM\n",
    "\n",
    "**Features:**\n",
    "- `query_doc_similarity`: Semantic similarity score (0-1)\n",
    "- `keyword_matches`: Number of matching keywords\n",
    "- `doc_popularity`: How often this doc helped others\n",
    "- `doc_recency`: Days since doc was updated\n",
    "- `doc_length`: Document word count\n",
    "- `user_feedback_score`: Historical relevance ratings\n",
    "\n",
    "**Target:**\n",
    "- `is_relevant`: 1 = Relevant, 0 = Not Relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic RAG document classification dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 2000\n",
    "\n",
    "# Generate features for relevant and non-relevant documents\n",
    "data = {\n",
    "    'query_doc_similarity': np.concatenate([\n",
    "        np.random.beta(8, 2, 800),      # Relevant: high similarity\n",
    "        np.random.beta(2, 5, 1200)       # Not relevant: low similarity\n",
    "    ]),\n",
    "    'keyword_matches': np.concatenate([\n",
    "        np.random.poisson(8, 800),\n",
    "        np.random.poisson(2, 1200)\n",
    "    ]),\n",
    "    'doc_popularity': np.concatenate([\n",
    "        np.random.exponential(50, 800),\n",
    "        np.random.exponential(10, 1200)\n",
    "    ]),\n",
    "    'doc_recency': np.concatenate([\n",
    "        np.random.exponential(30, 800),   # Relevant: more recent\n",
    "        np.random.exponential(100, 1200)  # Not relevant: older\n",
    "    ]),\n",
    "    'doc_length': np.concatenate([\n",
    "        np.random.normal(500, 100, 800),\n",
    "        np.random.normal(300, 150, 1200)\n",
    "    ]),\n",
    "    'user_feedback_score': np.concatenate([\n",
    "        np.random.beta(9, 2, 800) * 5,    # Relevant: high ratings (0-5)\n",
    "        np.random.beta(2, 4, 1200) * 5    # Not relevant: low ratings\n",
    "    ]),\n",
    "    'is_relevant': [1] * 800 + [0] * 1200  # 40% relevant, 60% not relevant\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"üìö RAG Document Classification Dataset Created!\")\n",
    "print(f\"Total documents: {len(df)}\")\n",
    "print(f\"Relevant documents: {df['is_relevant'].sum()}\")\n",
    "print(f\"Not relevant: {(df['is_relevant'] == 0).sum()}\")\n",
    "print(\"\\nFirst few documents:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference between relevant and non-relevant documents\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('üìä RAG System: Relevant vs Non-Relevant Documents', fontsize=16, fontweight='bold')\n",
    "\n",
    "features = ['query_doc_similarity', 'keyword_matches', 'doc_popularity', \n",
    "            'doc_recency', 'doc_length', 'user_feedback_score']\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    df[df['is_relevant'] == 1][feature].hist(ax=ax, alpha=0.6, label='Relevant', bins=30, color='green')\n",
    "    df[df['is_relevant'] == 0][feature].hist(ax=ax, alpha=0.6, label='Not Relevant', bins=30, color='red')\n",
    "    \n",
    "    ax.set_title(feature.replace('_', ' ').title())\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Notice the patterns! Relevant docs have higher similarity, more keywords, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare-data",
   "metadata": {},
   "source": [
    "## üîß Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop('is_relevant', axis=1)\n",
    "y = df['is_relevant']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Data prepared!\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-model",
   "metadata": {},
   "source": [
    "## üìä Baseline: Single Decision Tree\n",
    "\n",
    "Let's start with a single decision tree to establish a baseline. Then we'll see how ensemble methods improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-tree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single decision tree (baseline)\n",
    "single_tree = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "single_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_single = single_tree.predict(X_test)\n",
    "accuracy_single = accuracy_score(y_test, y_pred_single)\n",
    "\n",
    "print(\"üå≥ Single Decision Tree (Baseline):\")\n",
    "print(f\"Accuracy: {accuracy_single:.2%}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_single, target_names=['Not Relevant', 'Relevant']))\n",
    "\n",
    "print(\"\\nüí° This is our baseline. Can ensemble methods beat it? Let's find out!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bagging-intro",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Bagging (Bootstrap Aggregating)\n",
    "\n",
    "**What is Bagging?**\n",
    "- Train multiple models on different random samples of the data\n",
    "- Each model votes on the final prediction\n",
    "- Combine predictions by majority vote\n",
    "\n",
    "**How it works:**\n",
    "1. Create multiple random samples from training data (with replacement)\n",
    "2. Train one model on each sample\n",
    "3. For prediction: Each model votes, majority wins!\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Reduces overfitting\n",
    "- ‚úÖ More stable predictions\n",
    "- ‚úÖ Works well with high-variance models (like decision trees)\n",
    "\n",
    "**üéØ Real AI Use Cases:**\n",
    "- **RAG systems**: Multiple retrievers vote on document relevance\n",
    "- **Content moderation**: Ensemble of classifiers reduces false positives\n",
    "- **Anomaly detection**: Multiple models catch different types of anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bagging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bagging Classifier\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=10),\n",
    "    n_estimators=50,  # 50 decision trees\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(\"üéí Bagging Classifier Results:\")\n",
    "print(f\"Number of trees: {bagging.n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_bagging:.2%}\")\n",
    "print(f\"\\nüìà Improvement over single tree: {(accuracy_bagging - accuracy_single):.2%}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_bagging, target_names=['Not Relevant', 'Relevant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-forest-intro",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Random Forests (Advanced Bagging)\n",
    "\n",
    "**What is Random Forest?**\n",
    "- Bagging + Extra randomness\n",
    "- Each tree uses random subset of features\n",
    "- More diversity = Better ensemble!\n",
    "\n",
    "**Key Differences from Bagging:**\n",
    "- Bagging: All trees see all features\n",
    "- Random Forest: Each tree sees random subset of features\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Even better accuracy than simple bagging\n",
    "- ‚úÖ Handles high-dimensional data well\n",
    "- ‚úÖ Built-in feature importance\n",
    "- ‚úÖ Robust to outliers and noise\n",
    "\n",
    "**üéØ Real AI Use Cases (2024-2025):**\n",
    "- **Query routing in RAG**: Which knowledge base to search?\n",
    "- **Intent classification**: Route user queries to correct AI agent\n",
    "- **Feature extraction**: Pre-processing for Transformer models\n",
    "- **Ranking systems**: Combine with neural networks in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,  # 100 trees\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"üå≤ Random Forest Results:\")\n",
    "print(f\"Number of trees: {rf.n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2%}\")\n",
    "print(f\"\\nüìà Improvement over single tree: {(accuracy_rf - accuracy_single):.2%}\")\n",
    "print(f\"üìà Improvement over bagging: {(accuracy_rf - accuracy_bagging):.2%}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Not Relevant', 'Relevant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üî• Most Important Features for Document Relevance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='forestgreen')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('üéØ Random Forest: Feature Importance for RAG Document Classification', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Insight: query_doc_similarity is the most important feature!\")\n",
    "print(\"This makes sense - semantic similarity is crucial for RAG systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boosting-intro",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Boosting: AdaBoost\n",
    "\n",
    "**What is Boosting?**\n",
    "- Train models sequentially (not in parallel like bagging)\n",
    "- Each new model focuses on errors from previous models\n",
    "- Combine models with weighted voting\n",
    "\n",
    "**AdaBoost (Adaptive Boosting):**\n",
    "1. Train first model on all data\n",
    "2. Identify misclassified examples\n",
    "3. Give MORE weight to misclassified examples\n",
    "4. Train next model (focuses on hard examples)\n",
    "5. Repeat!\n",
    "\n",
    "**Key Difference from Bagging:**\n",
    "- **Bagging**: Models trained independently\n",
    "- **Boosting**: Models trained sequentially, learning from mistakes\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Often higher accuracy than bagging\n",
    "- ‚úÖ Reduces both bias and variance\n",
    "- ‚úÖ Works well with weak learners\n",
    "\n",
    "**Challenges:**\n",
    "- ‚ö†Ô∏è More prone to overfitting\n",
    "- ‚ö†Ô∏è Sensitive to noisy data and outliers\n",
    "- ‚ö†Ô∏è Sequential training (can't parallelize)\n",
    "\n",
    "**üéØ Real AI Use Cases:**\n",
    "- **Face detection**: Original AdaBoost use case (Viola-Jones)\n",
    "- **Click-through rate prediction**: Ad ranking systems\n",
    "- **Fraud detection**: Catching subtle patterns\n",
    "- **RAG re-ranking**: Fine-tuning document relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AdaBoost Classifier\n",
    "adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),  # Weak learners (shallow trees)\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_ada = adaboost.predict(X_test)\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "\n",
    "print(\"üöÄ AdaBoost Results:\")\n",
    "print(f\"Number of estimators: {adaboost.n_estimators}\")\n",
    "print(f\"Learning rate: {adaboost.learning_rate}\")\n",
    "print(f\"Accuracy: {accuracy_ada:.2%}\")\n",
    "print(f\"\\nüìà Improvement over single tree: {(accuracy_ada - accuracy_single):.2%}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ada, target_names=['Not Relevant', 'Relevant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-all",
   "metadata": {},
   "source": [
    "## üìä Compare All Models\n",
    "\n",
    "Let's see which ensemble method performs best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Single Tree', 'Bagging', 'Random Forest', 'AdaBoost'],\n",
    "    'Accuracy': [accuracy_single, accuracy_bagging, accuracy_rf, accuracy_ada],\n",
    "    'Type': ['Baseline', 'Ensemble (Bagging)', 'Ensemble (Bagging)', 'Ensemble (Boosting)']\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"üèÜ Model Comparison for RAG Document Classification:\")\n",
    "print(results.to_string(index=False))\n",
    "print(f\"\\nü•á Best Model: {results.iloc[0]['Model']} with {results.iloc[0]['Accuracy']:.2%} accuracy\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#95a5a6', '#3498db', '#2ecc71', '#e74c3c']\n",
    "bars = plt.bar(results['Model'], results['Accuracy'], color=colors)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('üéØ Ensemble Methods Comparison: RAG Document Classification', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.axhline(y=accuracy_single, color='gray', linestyle='--', alpha=0.5, label='Baseline')\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2%}',\n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight: Ensemble methods consistently outperform single models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-ai-example",
   "metadata": {},
   "source": [
    "## üåü Real AI Example: Improving RAG Retrieval Accuracy\n",
    "\n",
    "**Problem:** In production RAG systems, retrieving irrelevant documents wastes:\n",
    "- üí∞ LLM tokens (costs money)\n",
    "- ‚ö° Processing time (slower responses)\n",
    "- üéØ Answer quality (confuses the LLM)\n",
    "\n",
    "**Solution:** Use ensemble classifier to filter documents BEFORE sending to LLM\n",
    "\n",
    "**Pipeline:**\n",
    "1. User asks question\n",
    "2. Vector search retrieves 100 candidate documents\n",
    "3. **Ensemble classifier filters to top 10 most relevant** ‚Üê Our model!\n",
    "4. Send only top 10 to LLM\n",
    "5. LLM generates better answer, faster and cheaper!\n",
    "\n",
    "Let's simulate this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate RAG retrieval scenario\n",
    "print(\"üîç RAG System Simulation\\n\" + \"=\"*50)\n",
    "\n",
    "# Simulate: Vector search returned 20 candidate documents\n",
    "sample_docs = X_test.head(20).copy()\n",
    "sample_labels = y_test.head(20).copy()\n",
    "\n",
    "# Get predictions from our best model (Random Forest)\n",
    "predictions = rf.predict(sample_docs)\n",
    "probabilities = rf.predict_proba(sample_docs)[:, 1]  # Probability of being relevant\n",
    "\n",
    "# Create results dataframe\n",
    "rag_results = pd.DataFrame({\n",
    "    'doc_id': range(1, 21),\n",
    "    'similarity': sample_docs['query_doc_similarity'].values,\n",
    "    'predicted_relevant': predictions,\n",
    "    'relevance_score': probabilities,\n",
    "    'actual_relevant': sample_labels.values\n",
    "}).sort_values('relevance_score', ascending=False)\n",
    "\n",
    "print(\"\\nüìö Retrieved Documents (sorted by ensemble relevance score):\")\n",
    "print(rag_results.head(10).to_string(index=False))\n",
    "\n",
    "# Calculate metrics\n",
    "top_10_docs = rag_results.head(10)\n",
    "precision_at_10 = top_10_docs['actual_relevant'].sum() / 10\n",
    "\n",
    "# Compare to naive approach (just using similarity)\n",
    "naive_top_10 = rag_results.nlargest(10, 'similarity')\n",
    "naive_precision = naive_top_10['actual_relevant'].sum() / 10\n",
    "\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"  Ensemble Classifier Precision@10: {precision_at_10:.0%}\")\n",
    "print(f\"  Naive Similarity Precision@10: {naive_precision:.0%}\")\n",
    "print(f\"  Improvement: {(precision_at_10 - naive_precision):.0%}\")\n",
    "\n",
    "print(\"\\nüí° Impact:\")\n",
    "print(f\"  Relevant docs sent to LLM: {int(precision_at_10 * 10)}/10\")\n",
    "print(f\"  Irrelevant docs filtered: {10 - int(precision_at_10 * 10)}/10\")\n",
    "print(f\"  Token savings: ~{(1 - precision_at_10) * 100:.0%} reduction in wasted tokens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voting-classifier",
   "metadata": {},
   "source": [
    "## üó≥Ô∏è Bonus: Voting Classifier (Combining Different Models)\n",
    "\n",
    "**What if we combine different types of models?**\n",
    "\n",
    "**Voting Classifier:**\n",
    "- Combines predictions from multiple different algorithms\n",
    "- Example: Logistic Regression + Random Forest + AdaBoost\n",
    "- Two types:\n",
    "  - **Hard Voting**: Majority vote wins\n",
    "  - **Soft Voting**: Average probabilities (usually better)\n",
    "\n",
    "**üéØ Real AI Use Cases:**\n",
    "- **Production ML**: Combine traditional ML + neural networks\n",
    "- **Agentic AI**: Multiple specialized agents vote on action\n",
    "- **Multimodal AI**: Combine text, image, and audio classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voting-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diverse base models\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_voter = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "ada_voter = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Create voting classifier with soft voting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_reg),\n",
    "        ('rf', rf_voter),\n",
    "        ('ada', ada_voter)\n",
    "    ],\n",
    "    voting='soft'  # Average probabilities\n",
    ")\n",
    "\n",
    "# Train on scaled data (Logistic Regression needs scaling)\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"üó≥Ô∏è Voting Classifier Results:\")\n",
    "print(f\"Models combined: Logistic Regression + Random Forest + AdaBoost\")\n",
    "print(f\"Voting type: Soft (probability averaging)\")\n",
    "print(f\"Accuracy: {accuracy_voting:.2%}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting, target_names=['Not Relevant', 'Relevant']))\n",
    "\n",
    "print(\"\\nüí° Voting ensembles can combine the strengths of different algorithm families!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "## üéØ YOUR TURN: Exercise 1 - Email Priority Classification\n",
    "\n",
    "**Challenge:** Build an ensemble classifier for email priority detection!\n",
    "\n",
    "**Scenario:** You're building an AI assistant that needs to classify emails as:\n",
    "- High Priority (needs immediate attention)\n",
    "- Low Priority (can wait)\n",
    "\n",
    "**Your Task:**\n",
    "1. Train a Random Forest classifier\n",
    "2. Train an AdaBoost classifier\n",
    "3. Compare their accuracy\n",
    "4. Which works better?\n",
    "\n",
    "Don't worry - experiment and learn! üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email priority dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "n_emails = 1500\n",
    "\n",
    "email_data = {\n",
    "    'from_vip': np.concatenate([\n",
    "        np.random.binomial(1, 0.7, 600),   # High priority: often from VIP\n",
    "        np.random.binomial(1, 0.2, 900)    # Low priority: rarely from VIP\n",
    "    ]),\n",
    "    'has_deadline_keywords': np.concatenate([\n",
    "        np.random.binomial(1, 0.8, 600),\n",
    "        np.random.binomial(1, 0.1, 900)\n",
    "    ]),\n",
    "    'reply_expected': np.concatenate([\n",
    "        np.random.binomial(1, 0.9, 600),\n",
    "        np.random.binomial(1, 0.3, 900)\n",
    "    ]),\n",
    "    'cc_count': np.concatenate([\n",
    "        np.random.poisson(5, 600),\n",
    "        np.random.poisson(1, 900)\n",
    "    ]),\n",
    "    'sender_email_frequency': np.concatenate([\n",
    "        np.random.exponential(10, 600),\n",
    "        np.random.exponential(2, 900)\n",
    "    ]),\n",
    "    'is_high_priority': [1] * 600 + [0] * 900\n",
    "}\n",
    "\n",
    "email_df = pd.DataFrame(email_data)\n",
    "email_df = email_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"üìß Email Priority Dataset:\")\n",
    "print(email_df.head())\n",
    "print(f\"\\nTotal emails: {len(email_df)}\")\n",
    "print(f\"High priority: {email_df['is_high_priority'].sum()}\")\n",
    "print(f\"Low priority: {(email_df['is_high_priority'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!\n",
    "# Hint: Follow the same steps as above\n",
    "\n",
    "# Step 1: Separate X and y\n",
    "X_email = # YOUR CODE\n",
    "y_email = # YOUR CODE\n",
    "\n",
    "# Step 2: Split data\n",
    "# YOUR CODE\n",
    "\n",
    "# Step 3: Train Random Forest\n",
    "# YOUR CODE\n",
    "\n",
    "# Step 4: Train AdaBoost\n",
    "# YOUR CODE\n",
    "\n",
    "# Step 5: Compare accuracy\n",
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution-1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìñ Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "# Step 1: Separate X and y\n",
    "X_email = email_df.drop('is_high_priority', axis=1)\n",
    "y_email = email_df['is_high_priority']\n",
    "\n",
    "# Step 2: Split data\n",
    "X_train_em, X_test_em, y_train_em, y_test_em = train_test_split(\n",
    "    X_email, y_email, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Train Random Forest\n",
    "rf_email = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_email.fit(X_train_em, y_train_em)\n",
    "rf_email_acc = accuracy_score(y_test_em, rf_email.predict(X_test_em))\n",
    "\n",
    "# Step 4: Train AdaBoost\n",
    "ada_email = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_email.fit(X_train_em, y_train_em)\n",
    "ada_email_acc = accuracy_score(y_test_em, ada_email.predict(X_test_em))\n",
    "\n",
    "# Step 5: Compare\n",
    "print(f\"Random Forest Accuracy: {rf_email_acc:.2%}\")\n",
    "print(f\"AdaBoost Accuracy: {ada_email_acc:.2%}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "**You just learned:**\n",
    "\n",
    "### 1. **Bagging (Bootstrap Aggregating)**\n",
    "   - ‚úÖ Train models independently on random samples\n",
    "   - ‚úÖ Combine via majority vote\n",
    "   - ‚úÖ Reduces overfitting and variance\n",
    "   - **Use when:** You have high-variance models (e.g., deep decision trees)\n",
    "\n",
    "### 2. **Random Forests**\n",
    "   - ‚úÖ Advanced bagging with feature randomness\n",
    "   - ‚úÖ Excellent for high-dimensional data\n",
    "   - ‚úÖ Built-in feature importance\n",
    "   - **Use when:** You need robust, accurate predictions with interpretability\n",
    "\n",
    "### 3. **Boosting (AdaBoost)**\n",
    "   - ‚úÖ Sequential training, focus on errors\n",
    "   - ‚úÖ Often higher accuracy than bagging\n",
    "   - ‚ö†Ô∏è More prone to overfitting\n",
    "   - **Use when:** You need maximum accuracy and have clean data\n",
    "\n",
    "### 4. **Voting Ensembles**\n",
    "   - ‚úÖ Combine different algorithm types\n",
    "   - ‚úÖ Leverages diverse model strengths\n",
    "   - **Use when:** You want to combine traditional ML + neural networks\n",
    "\n",
    "**üåü Real-World AI Applications (2024-2025):**\n",
    "- **RAG Systems:** Ensemble classifiers improve retrieval precision\n",
    "- **Agentic AI:** Multiple models vote on which action to take\n",
    "- **Production ML:** Random Forests power real-time ranking systems\n",
    "- **Content Moderation:** Ensembles reduce false positives/negatives\n",
    "- **Fraud Detection:** Boosting catches subtle patterns\n",
    "\n",
    "**When to Use What:**\n",
    "- **Need speed + interpretability?** ‚Üí Random Forest\n",
    "- **Need maximum accuracy?** ‚Üí Boosting (or wait for Day 2: XGBoost!)\n",
    "- **Have noisy data?** ‚Üí Random Forest (more robust)\n",
    "- **Combining models?** ‚Üí Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "**Practice Exercises:**\n",
    "1. Experiment with different `n_estimators` (50, 100, 200) - what happens?\n",
    "2. Try different `max_depth` values in Random Forest\n",
    "3. Create a Voting Classifier with 4-5 different models\n",
    "\n",
    "**Coming Next:**\n",
    "- **Day 2:** Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "- **Day 3:** Advanced ML Techniques (Stacking, Pipelines, Feature Engineering)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You now understand the ensemble methods that power:\n",
    "- Kaggle winning solutions\n",
    "- Production RAG systems\n",
    "- Real-world ML applications at scale\n",
    "\n",
    "**üí¨ Questions?** Review the notebook, experiment with hyperparameters, and see how ensemble methods improve accuracy!\n",
    "\n",
    "---\n",
    "\n",
    "*Remember: Modern AI systems often combine ensemble methods with deep learning. Random Forests for feature selection, then Transformers for final predictions!* üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
